{
  "题库说明": "本题库对应《人工智能导论 (ai1)》知识点，涵盖AI基础概念、搜索算法、知识表示、机器学习基础、专家系统等内容。",
  "题库": [
    {
      "pointId": "ai1",
      "pointTitle": "人工智能导论",
      "quiz": [
        {
          "question": "人工智能（AI）的定义中，图灵测试的核心思想是？",
          "type": "single",
          "options": [
            "如果机器的行为无法与人类区分，则认为机器具有智能",
            "机器必须具有意识",
            "机器必须能感知情感",
            "机器必须有物理身体"
          ],
          "correctAnswer": 0,
          "explanation": "图灵测试（1950年）：通过对话判断对方是人还是机器，若无法区分则通过测试。强调行为主义视角，回避了\"什么是智能\"的哲学问题。批评：只关注行为不关注理解。"
        },
        {
          "question": "人工智能的主要研究领域包括？",
          "type": "multiple",
          "options": [
            "机器学习（Machine Learning）",
            "自然语言处理（NLP）",
            "计算机视觉（Computer Vision）",
            "专家系统（Expert Systems）"
          ],
          "correctAnswer": [0, 1, 2, 3],
          "explanation": "AI研究领域：机器学习（从数据学习）、NLP（理解和生成语言）、计算机视觉（图像识别）、专家系统（知识推理）、机器人学、语音识别等。"
        },
        {
          "question": "弱AI（Weak AI）和强AI（Strong AI）的区别是？",
          "type": "single",
          "options": [
            "弱AI解决特定任务，强AI具有通用智能和意识",
            "弱AI运行更慢",
            "强AI已经实现",
            "弱AI不能学习"
          ],
          "correctAnswer": 0,
          "explanation": "弱AI（窄AI）：专注特定任务（如下棋、语音识别），当前所有AI系统都是弱AI。强AI（通用AI，AGI）：像人一样思考、理解、学习，具有自我意识，目前未实现。"
        },
        {
          "question": "知识表示方法包括？",
          "type": "multiple",
          "options": [
            "谓词逻辑（Predicate Logic）",
            "语义网络（Semantic Network）",
            "框架（Frame）",
            "产生式规则（Production Rules）"
          ],
          "correctAnswer": [0, 1, 2, 3],
          "explanation": "知识表示：谓词逻辑（形式化、严格推理）、语义网络（图结构、节点表示概念）、框架（结构化、继承）、产生式规则（IF-THEN）、本体（Ontology）等。"
        },
        {
          "question": "搜索问题的基本要素包括？",
          "type": "multiple",
          "options": [
            "状态空间（State Space）",
            "初始状态（Initial State）",
            "目标测试（Goal Test）",
            "动作/算子（Actions/Operators）",
            "路径代价（Path Cost）"
          ],
          "correctAnswer": [0, 1, 2, 3, 4],
          "explanation": "搜索问题定义：状态空间（所有可能状态）、初始状态、目标状态（目标测试）、动作（状态转移）、路径代价（解的质量）。求解：找到从初始到目标的动作序列。"
        },
        {
          "question": "广度优先搜索（BFS）的特点是？",
          "type": "multiple",
          "options": [
            "完备的（一定能找到解）",
            "最优的（找到最短路径，当代价相同时）",
            "空间复杂度高",
            "使用队列实现"
          ],
          "correctAnswer": [0, 1, 2, 3],
          "explanation": "BFS：逐层扩展，先发现浅层解。完备性：有限分支因子时能找到解。最优性：代价相同时找到最浅解。时间和空间复杂度：$O(b^d)$（$b$分支因子，$d$深度）。"
        },
        {
          "question": "深度优先搜索（DFS）的特点是？",
          "type": "multiple",
          "options": [
            "空间复杂度低（$O(bm)$）",
            "使用栈实现",
            "不完备（可能陷入无限路径）",
            "不最优"
          ],
          "correctAnswer": [0, 1, 2, 3],
          "explanation": "DFS：沿一条路径深入到底，再回溯。优点：空间效率高（只存当前路径）。缺点：不完备（无限深度）、不最优（先找到的不一定最好）。可用深度限制改进。"
        },
        {
          "question": "启发式搜索（Heuristic Search）中，启发函数$h(n)$的作用是？",
          "type": "single",
          "options": [
            "估计从节点$n$到目标的代价",
            "计算从起点到$n$的代价",
            "统计已访问节点数",
            "随机选择下一个节点"
          ],
          "correctAnswer": 0,
          "explanation": "启发函数$h(n)$：估计从节点$n$到目标的最小代价（剩余距离）。良好的启发函数可大幅减少搜索空间。如：欧几里得距离（路径规划）、曼哈顿距离（滑块问题）。"
        },
        {
          "question": "A*算法的评估函数是？",
          "type": "single",
          "options": [
            "$f(n) = g(n) + h(n)$",
            "$f(n) = g(n) - h(n)$",
            "$f(n) = g(n) \\\\times h(n)$",
            "$f(n) = h(n)$"
          ],
          "correctAnswer": 0,
          "explanation": "A*算法：$f(n) = g(n) + h(n)$，其中$g(n)$是从起点到$n$的实际代价，$h(n)$是从$n$到目标的估计代价。$f(n)$是通过$n$到目标的估计总代价。优先扩展$f(n)$最小的节点。"
        },
        {
          "question": "A*算法的最优性保证需要启发函数满足什么条件？",
          "type": "single",
          "options": [
            "可采纳性（Admissible）：$h(n) \\\\leq h^*(n)$，不高估实际代价",
            "一致性（Consistency）已经足够",
            "$h(n)$越大越好",
            "$h(n)$必须为0"
          ],
          "correctAnswer": 0,
          "explanation": "可采纳性（Admissible）：$h(n) \\\\leq h^*(n)$（$h^*$是实际最优代价），不高估。保证A*找到最优解。一致性（Consistency，单调性）：$h(n) \\\\leq c(n,n') + h(n')$，比可采纳性更强，保证最优且不重复扩展。"
        },
        {
          "question": "博弈树搜索中，Minimax算法的思想是？",
          "type": "single",
          "options": [
            "MAX玩家选择最大值，MIN玩家选择最小值，交替进行",
            "两个玩家都选择最大值",
            "随机选择",
            "只考虑当前步"
          ],
          "correctAnswer": 0,
          "explanation": "Minimax：零和博弈中，MAX玩家最大化收益，MIN玩家最小化MAX收益（即最大化自己收益）。递归计算：MAX层选max，MIN层选min。完全信息博弈（如井字棋、国际象棋）。"
        },
        {
          "question": "Alpha-Beta剪枝的作用是？",
          "type": "single",
          "options": [
            "在不影响Minimax结果的前提下，减少搜索节点",
            "改变Minimax的结果",
            "只适用于深度为2的树",
            "使搜索变得不完备"
          ],
          "correctAnswer": 0,
          "explanation": "Alpha-Beta剪枝：Minimax的优化，维护alpha（MAX的下界）和beta（MIN的上界）。当$\\\\beta \\\\leq \\\\alpha$时剪枝。不改变最终结果，但大幅减少节点数（最好$O(b^{d/2})$）。"
        },
        {
          "question": "机器学习的三种主要类型是？",
          "type": "multiple",
          "options": [
            "监督学习（Supervised Learning）",
            "无监督学习（Unsupervised Learning）",
            "强化学习（Reinforcement Learning）",
            "深度学习"
          ],
          "correctAnswer": [0, 1, 2],
          "explanation": "机器学习分类：监督学习（有标签数据，如分类、回归）、无监督学习（无标签，如聚类、降维）、强化学习（通过奖励学习策略）。深度学习是方法不是分类。"
        },
        {
          "question": "监督学习的任务类型包括？",
          "type": "multiple",
          "options": [
            "分类（Classification）",
            "回归（Regression）",
            "聚类（Clustering）",
            "降维（Dimensionality Reduction）"
          ],
          "correctAnswer": [0, 1],
          "explanation": "监督学习任务：分类（离散输出，如垃圾邮件识别）、回归（连续输出，如房价预测）。需要标注数据$(x, y)$。聚类和降维属于无监督学习。"
        },
        {
          "question": "过拟合（Overfitting）是什么现象？",
          "type": "single",
          "options": [
            "模型在训练集表现好，但在测试集表现差",
            "模型在训练集和测试集都表现差",
            "模型训练时间过长",
            "模型无法收敛"
          ],
          "correctAnswer": 0,
          "explanation": "过拟合：模型过度学习训练数据（包括噪声），泛化能力差。表现：训练误差低，测试误差高。解决：正则化、交叉验证、增加数据、简化模型、Dropout等。"
        },
        {
          "question": "正则化（Regularization）的作用是？",
          "type": "single",
          "options": [
            "防止过拟合，通过惩罚复杂模型",
            "加快训练速度",
            "增加模型复杂度",
            "提高训练集准确率"
          ],
          "correctAnswer": 0,
          "explanation": "正则化：在损失函数中加入惩罚项，限制模型复杂度。L1正则（Lasso，稀疏性）：$\\\\lambda \\\\sum |w_i|$。L2正则（Ridge，平滑性）：$\\\\lambda \\\\sum w_i^2$。权衡训练误差和模型复杂度。"
        },
        {
          "question": "交叉验证（Cross-Validation）的目的是？",
          "type": "single",
          "options": [
            "更可靠地评估模型性能，选择超参数",
            "加速训练",
            "增加训练数据",
            "简化模型"
          ],
          "correctAnswer": 0,
          "explanation": "交叉验证：将数据分成$k$折（k-fold），轮流用$k-1$折训练、1折验证，平均结果。优点：充分利用数据、减少评估偏差。常用于超参数选择、模型比较。"
        },
        {
          "question": "决策树的主要优点包括？",
          "type": "multiple",
          "options": [
            "易于理解和解释",
            "不需要特征缩放",
            "能处理非线性关系",
            "不会过拟合"
          ],
          "correctAnswer": [0, 1, 2],
          "explanation": "决策树优点：直观、白盒模型、不需归一化、处理非线性、自动特征选择。缺点：易过拟合（需剪枝）、不稳定（小变化导致大差异）。算法：ID3、C4.5、CART。"
        },
        {
          "question": "信息增益（Information Gain）用于什么？",
          "type": "single",
          "options": [
            "决策树中选择最优分裂特征",
            "计算模型准确率",
            "神经网络权重更新",
            "聚类中心选择"
          ],
          "correctAnswer": 0,
          "explanation": "信息增益：衡量按某特征分裂后，熵（不确定性）的减少量。$IG(D,A) = H(D) - H(D|A)$。ID3算法使用信息增益，C4.5使用信息增益率（避免偏向多值特征）。"
        },
        {
          "question": "K近邻算法（KNN）的特点是？",
          "type": "multiple",
          "options": [
            "惰性学习（Lazy Learning，无训练过程）",
            "预测时需遍历训练数据",
            "非参数模型",
            "对特征尺度敏感"
          ],
          "correctAnswer": [0, 1, 2, 3],
          "explanation": "KNN：找$k$个最近邻，分类用投票、回归用平均。特点：无训练（实例学习）、非参数、简单。缺点：预测慢（需计算距离）、高维诅咒、需归一化。$k$是超参数。"
        },
        {
          "question": "聚类算法K-Means的步骤是？",
          "type": "single",
          "options": [
            "1) 随机初始化$k$个中心；2) 分配样本到最近中心；3) 更新中心为簇均值；4) 重复2-3直到收敛",
            "随机分配样本到簇",
            "找到全局最优解",
            "不需要指定$k$"
          ],
          "correctAnswer": 0,
          "explanation": "K-Means：迭代算法，最小化簇内平方和。优点：简单、快速。缺点：需指定$k$、对初始化敏感（K-Means++改进）、只能发现凸形簇、对异常值敏感。"
        },
        {
          "question": "神经网络中，激活函数的作用是？",
          "type": "single",
          "options": [
            "引入非线性，使网络能拟合复杂函数",
            "加速收敛",
            "防止过拟合",
            "初始化权重"
          ],
          "correctAnswer": 0,
          "explanation": "激活函数：引入非线性变换。若无激活函数（或线性激活），多层网络等价于单层。常用：Sigmoid（0-1）、Tanh（-1到1）、ReLU（$\\\\max(0,x)$，最常用）、Leaky ReLU、Softmax（输出层）。"
        },
        {
          "question": "反向传播（Backpropagation）算法的作用是？",
          "type": "single",
          "options": [
            "计算损失函数对各层权重的梯度，用于更新权重",
            "前向传播计算输出",
            "初始化权重",
            "评估模型准确率"
          ],
          "correctAnswer": 0,
          "explanation": "反向传播：利用链式法则，从输出层反向计算各层权重的梯度。步骤：前向传播→计算损失→反向传播梯度→更新权重（如梯度下降）。是训练神经网络的核心算法。"
        },
        {
          "question": "梯度下降法（Gradient Descent）的更新公式是？",
          "type": "single",
          "options": [
            "$w := w - \\\\eta \\\\nabla L(w)$（$\\\\eta$是学习率）",
            "$w := w + \\\\eta \\\\nabla L(w)$",
            "$w := \\\\eta \\\\nabla L(w)$",
            "$w := w / \\\\eta$"
          ],
          "correctAnswer": 0,
          "explanation": "梯度下降：沿损失函数梯度的负方向更新参数，$w := w - \\\\eta \\\\nabla L(w)$。学习率$\\\\eta$：太大震荡不收敛，太小收敛慢。变体：批量GD、随机GD（SGD）、Mini-Batch GD。"
        },
        {
          "question": "强化学习的核心概念包括？",
          "type": "multiple",
          "options": [
            "智能体（Agent）",
            "环境（Environment）",
            "状态（State）",
            "动作（Action）",
            "奖励（Reward）"
          ],
          "correctAnswer": [0, 1, 2, 3, 4],
          "explanation": "强化学习：Agent在Environment中采取Action，观察State并获得Reward，目标是最大化累积奖励。核心：探索-利用权衡（Exploration-Exploitation）。应用：游戏、机器人、推荐系统。"
        },
        {
          "question": "Q-Learning算法的更新公式是？",
          "type": "single",
          "options": [
            "$Q(s,a) := Q(s,a) + \\\\alpha [r + \\\\gamma \\\\max_{a'} Q(s',a') - Q(s,a)]$",
            "$Q(s,a) := r$",
            "$Q(s,a) := \\\\max_{a'} Q(s',a')$",
            "$Q(s,a) := Q(s,a) - \\\\alpha r$"
          ],
          "correctAnswer": 0,
          "explanation": "Q-Learning：无模型（model-free）强化学习。更新Q值（状态-动作价值）：$Q(s,a) := Q(s,a) + \\\\alpha [r + \\\\gamma \\\\max Q(s',a') - Q(s,a)]$。$\\\\alpha$学习率，$\\\\gamma$折扣因子。"
        },
        {
          "question": "自然语言处理（NLP）的任务包括？",
          "type": "multiple",
          "options": [
            "机器翻译",
            "情感分析",
            "命名实体识别",
            "图像分类"
          ],
          "correctAnswer": [0, 1, 2],
          "explanation": "NLP任务：机器翻译、情感分析、文本分类、命名实体识别（NER）、问答系统、文本生成、语义理解等。图像分类属于计算机视觉。"
        },
        {
          "question": "词嵌入（Word Embedding）的作用是？",
          "type": "single",
          "options": [
            "将词映射到稠密的低维向量空间，捕捉语义",
            "统计词频",
            "分词",
            "语法分析"
          ],
          "correctAnswer": 0,
          "explanation": "词嵌入：将词表示为实数向量（如Word2Vec、GloVe）。优点：捕捉语义（相似词向量接近）、降维（vs one-hot高维稀疏）。应用：NLP的基础表示。"
        },
        {
          "question": "专家系统的主要组成部分是？",
          "type": "multiple",
          "options": [
            "知识库（Knowledge Base）",
            "推理引擎（Inference Engine）",
            "用户界面",
            "深度神经网络"
          ],
          "correctAnswer": [0, 1, 2],
          "explanation": "专家系统：模拟人类专家决策的AI系统。组成：知识库（领域知识，规则）、推理引擎（推理算法，如前向/后向链接）、解释机制、用户界面。代表：MYCIN（医疗诊断）。"
        }
      ]
    }
  ]
}

