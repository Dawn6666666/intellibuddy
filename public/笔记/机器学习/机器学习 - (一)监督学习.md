![(一)监督学习](https://via.placeholder.com/800x200?text=Supervised+Learning)

# 机器学习 - (一)监督学习

掌握监督学习经典算法。

---

# 机器学习

> 💡 **课程信息**
> - 学习时长：200小时
> - 难度等级：⭐⭐⭐⭐⭐ (极高)
> - **AI核心技术深度学习**

---

## 📚 机器学习流程

```
数据收集 → 数据预处理 → 特征工程 → 模型选择 → 训练 → 评估 → 部署
```

---

## 1. 监督学习

### 1.1 决策树

```python
import numpy as np
from collections import Counter

class DecisionTree:
    def __init__(self, max_depth=10, min_samples_split=2):
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.tree = None
    
    def entropy(self, y):
        """计算熵"""
        counts = Counter(y)
        probs = [count / len(y) for count in counts.values()]
        return -sum(p * np.log2(p) for p in probs if p > 0)
    
    def information_gain(self, X, y, feature_idx, threshold):
        """计算信息增益"""
        left_mask = X[:, feature_idx] <= threshold
        right_mask = ~left_mask
        
        if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:
            return 0
        
        n = len(y)
        left_entropy = self.entropy(y[left_mask])
        right_entropy = self.entropy(y[right_mask])
        
        weighted_entropy = (len(y[left_mask]) / n) * left_entropy + \
                          (len(y[right_mask]) / n) * right_entropy
        
        return self.entropy(y) - weighted_entropy
    
    def best_split(self, X, y):
        """找到最佳分割"""
        best_gain = 0
        best_feature = None
        best_threshold = None
        
        for feature_idx in range(X.shape[1]):
            thresholds = np.unique(X[:, feature_idx])
            
            for threshold in thresholds:
                gain = self.information_gain(X, y, feature_idx, threshold)
                
                if gain > best_gain:
                    best_gain = gain
                    best_feature = feature_idx
                    best_threshold = threshold
        
        return best_feature, best_threshold, best_gain
    
    def build_tree(self, X, y, depth=0):
        """构建决策树"""
        # 停止条件
        if (depth >= self.max_depth or 
            len(y) < self.min_samples_split or 
            len(np.unique(y)) == 1):
            return Counter(y).most_common(1)[0][0]
        
        # 找到最佳分割
        feature, threshold, gain = self.best_split(X, y)
        
        if gain == 0:
            return Counter(y).most_common(1)[0][0]
        
        # 分割数据
        left_mask = X[:, feature] <= threshold
        right_mask = ~left_mask
        
        # 递归构建子树
        left_subtree = self.build_tree(X[left_mask], y[left_mask], depth + 1)
        right_subtree = self.build_tree(X[right_mask], y[right_mask], depth + 1)
        
        return {
            'feature': feature,
            'threshold': threshold,
            'left': left_subtree,
            'right': right_subtree
        }
    
    def fit(self, X, y):
        """训练决策树"""
        self.tree = self.build_tree(X, y)
    
    def predict_sample(self, x, tree):
        """预测单个样本"""
        if not isinstance(tree, dict):
            return tree
        
        if x[tree['feature']] <= tree['threshold']:
            return self.predict_sample(x, tree['left'])
        else:
            return self.predict_sample(x, tree['right'])
    
    def predict(self, X):
        """预测"""
        return [self.predict_sample(x, self.tree) for x in X]

# 示例
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=100, n_features=4, n_classes=2, random_state=42)

dt = DecisionTree(max_depth=5)
dt.fit(X, y)
predictions = dt.predict(X[:5])
print(f"预测结果: {predictions}")
```

### 1.2 支持向量机（SVM）

```python
import numpy as np

class SVM:
    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):
        self.lr = learning_rate
        self.lambda_param = lambda_param
        self.n_iters = n_iters
        self.w = None
        self.b = None
    
    def fit(self, X, y):
        """训练SVM"""
        n_samples, n_features = X.shape
        
        # 将标签转换为-1和1
        y_ = np.where(y <= 0, -1, 1)
        
        # 初始化权重
        self.w = np.zeros(n_features)
        self.b = 0
        
        for i in range(self.n_iters):
            for idx, x_i in enumerate(X):
                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1
                
                if condition:
                    # 正确分类
                    self.w -= self.lr * (2 * self.lambda_param * self.w)
                else:
                    # 错误分类或在边界上
                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))
                    self.b -= self.lr * y_[idx]
    
    def predict(self, X):
        """预测"""
        approximation = np.dot(X, self.w) - self.b
        return np.sign(approximation)

# 示例
X = np.array([[3, 3], [4, 3], [1, 1]])
y = np.array([1, 1, -1])

svm = SVM()
svm.fit(X, y)
predictions = svm.predict(X)
print(f"SVM预测: {predictions}")
```

### 1.3 随机森林

```python
import random

class RandomForest:
    def __init__(self, n_trees=10, max_depth=10, min_samples_split=2, n_features=None):
        self.n_trees = n_trees
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.n_features = n_features
        self.trees = []
    
    def bootstrap_sample(self, X, y):
        """自助采样"""
        n_samples = X.shape[0]
        idxs = np.random.choice(n_samples, n_samples, replace=True)
        return X[idxs], y[idxs]
    
    def fit(self, X, y):
        """训练随机森林"""
        self.trees = []
        
        for _ in range(self.n_trees):
            tree = DecisionTree(
                max_depth=self.max_depth,
                min_samples_split=self.min_samples_split
            )
            
            X_sample, y_sample = self.bootstrap_sample(X, y)
            tree.fit(X_sample, y_sample)
            self.trees.append(tree)
    
    def predict(self, X):
        """预测（投票）"""
        predictions = np.array([tree.predict(X) for tree in self.trees])
        return [Counter(predictions[:, i]).most_common(1)[0][0] for i in range(len(X))]

# 示例
rf = RandomForest(n_trees=5)
rf.fit(X, y)
rf_predictions = rf.predict(X[:3])
print(f"随机森林预测: {rf_predictions}")
```

---

## 2. 无监督学习