![(六)特征工程](https://via.placeholder.com/800x200?text=Feature+Engineering)

# 机器学习 - (六)特征工程

掌握特征提取与选择。

---


### 6.1 特征选择

```python
class FeatureSelector:
    """特征选择器"""
    
    @staticmethod
    def correlation_filter(X, y, threshold=0.1):
        """相关性过滤"""
        correlations = []
        
        for i in range(X.shape[1]):
            corr = np.corrcoef(X[:, i], y)[0, 1]
            correlations.append(abs(corr))
        
        selected_features = [i for i, corr in enumerate(correlations) if corr >= threshold]
        return selected_features, correlations
    
    @staticmethod
    def mutual_information(X, y, bins=10):
        """互信息"""
        mi_scores = []
        
        for i in range(X.shape[1]):
            # 离散化
            x_binned = np.digitize(X[:, i], bins=np.linspace(X[:, i].min(), X[:, i].max(), bins))
            
            # 计算联合分布和边缘分布
            joint_counts = {}
            x_counts = Counter(x_binned)
            y_counts = Counter(y)
            
            for xi, yi in zip(x_binned, y):
                joint_counts[(xi, yi)] = joint_counts.get((xi, yi), 0) + 1
            
            # 计算互信息
            mi = 0
            n = len(y)
            
            for (xi, yi), count in joint_counts.items():
                p_xy = count / n
                p_x = x_counts[xi] / n
                p_y = y_counts[yi] / n
                
                if p_xy > 0:
                    mi += p_xy * np.log(p_xy / (p_x * p_y + 1e-10))
            
            mi_scores.append(mi)
        
        return mi_scores

# 示例
selector = FeatureSelector()
selected, corrs = selector.correlation_filter(X, y, threshold=0.05)
print(f"选择的特征: {selected}")
print(f"相关性分数: {[f'{c:.3f}' for c in corrs]}")

mi_scores = selector.mutual_information(X, y)
print(f"互信息分数: {[f'{s:.3f}' for s in mi_scores]}")
```

### 6.2 特征构造

```python
class FeatureEngineer:
    """特征工程"""
    
    @staticmethod
    def polynomial_features(X, degree=2):
        """多项式特征"""
        n_samples, n_features = X.shape
        features = [X]
        
        # 生成交叉项
        if degree >= 2:
            for i in range(n_features):
                for j in range(i, n_features):
                    features.append((X[:, i] * X[:, j]).reshape(-1, 1))
        
        # 生成高次项
        if degree >= 3:
            for i in range(n_features):
                features.append((X[:, i] ** 2).reshape(-1, 1))
        
        return np.hstack(features)
    
    @staticmethod
    def binning(X, n_bins=5):
        """分箱"""
        X_binned = np.zeros_like(X)
        
        for i in range(X.shape[1]):
            bins = np.linspace(X[:, i].min(), X[:, i].max(), n_bins + 1)
            X_binned[:, i] = np.digitize(X[:, i], bins) - 1
        
        return X_binned
    
    @staticmethod
    def normalize(X, method='minmax'):
        """归一化"""
        if method == 'minmax':
            # Min-Max归一化
            X_min = X.min(axis=0)
            X_max = X.max(axis=0)
            return (X - X_min) / (X_max - X_min + 1e-8)
        
        elif method == 'zscore':
            # Z-score标准化
            mean = X.mean(axis=0)
            std = X.std(axis=0)
            return (X - mean) / (std + 1e-8)

# 示例
engineer = FeatureEngineer()

# 多项式特征
X_poly = engineer.polynomial_features(X[:, :3], degree=2)
print(f"多项式特征: {X.shape} -> {X_poly.shape}")

# 分箱
X_binned = engineer.binning(X, n_bins=5)
print(f"分箱后唯一值: {len(np.unique(X_binned[:, 0]))}")

# 归一化
X_normalized = engineer.normalize(X, method='minmax')
print(f"归一化范围: [{X_normalized.min():.2f}, {X_normalized.max():.2f}]")
```

---

## 7. 超参数优化