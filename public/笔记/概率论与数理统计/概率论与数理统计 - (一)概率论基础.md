![(ä¸€)æ¦‚ç‡è®ºåŸºç¡€](https://via.placeholder.com/800x200?text=Probability+Basics)

# æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ - (ä¸€)æ¦‚ç‡è®ºåŸºç¡€

å­¦ä¹ æ¦‚ç‡çš„åŸºæœ¬æ¦‚å¿µå’Œå…¬ç†ã€‚

---

# æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡

> ğŸ’¡ **è¯¾ç¨‹ä¿¡æ¯**
> - å­¦ä¹ æ—¶é•¿ï¼š120å°æ—¶
> - éš¾åº¦ç­‰çº§ï¼šâ­â­â­â­ (é«˜)
> - å‰ç½®è¯¾ç¨‹ï¼šå¾®ç§¯åˆ†
> - **æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€**

---

## ğŸ“š è¯¾ç¨‹æ¦‚è¿°

### åœ¨è®¡ç®—æœºç§‘å­¦ä¸­çš„åº”ç”¨

| ä¸»é¢˜ | CSåº”ç”¨ |
|------|--------|
| **è´å¶æ–¯å®šç†** | åƒåœ¾é‚®ä»¶è¿‡æ»¤ã€è´å¶æ–¯åˆ†ç±»å™¨ |
| **æ¦‚ç‡åˆ†å¸ƒ** | éšæœºç®—æ³•åˆ†æã€æ€§èƒ½å»ºæ¨¡ |
| **æœŸæœ›ä¸æ–¹å·®** | ç®—æ³•å¤æ‚åº¦åˆ†æ |
| **å¤§æ•°å®šå¾‹** | è’™ç‰¹å¡æ´›æ–¹æ³• |
| **ç»Ÿè®¡æ¨æ–­** | A/Bæµ‹è¯•ã€æœºå™¨å­¦ä¹ è¯„ä¼° |

---

## 1. æ¦‚ç‡è®ºåŸºç¡€

### 1.1 æ¦‚ç‡å…¬ç†

**æ ·æœ¬ç©ºé—´** $\Omega$ï¼šæ‰€æœ‰å¯èƒ½ç»“æœçš„é›†åˆ

**æ¦‚ç‡å…¬ç†ï¼ˆKolmogorovï¼‰ï¼š**

1. $P(A) \geq 0$
2. $P(\Omega) = 1$
3. $P(A \cup B) = P(A) + P(B)$ ï¼ˆ$A, B$ äº’æ–¥ï¼‰

### 1.2 æ¡ä»¶æ¦‚ç‡

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$

**è´å¶æ–¯å®šç†ï¼š**

$$
P(A|B) = \frac{P(B|A) P(A)}{P(B)}
$$

**å…¨æ¦‚ç‡å…¬å¼ï¼š**

$$
P(B) = \sum_{i=1}^{n} P(B|A_i) P(A_i)
$$

**ç¤ºä¾‹ï¼šåƒåœ¾é‚®ä»¶è¿‡æ»¤**

```python
import numpy as np

class NaiveBayesSpamFilter:
    def __init__(self):
        self.word_prob_spam = {}
        self.word_prob_ham = {}
        self.p_spam = 0.5
        self.p_ham = 0.5
    
    def train(self, emails, labels):
        """
        è®­ç»ƒè´å¶æ–¯åˆ†ç±»å™¨
        emails: é‚®ä»¶åˆ—è¡¨ï¼ˆæ¯ä¸ªé‚®ä»¶æ˜¯å•è¯åˆ—è¡¨ï¼‰
        labels: æ ‡ç­¾åˆ—è¡¨ï¼ˆ1=spam, 0=hamï¼‰
        """
        spam_emails = [emails[i] for i in range(len(emails)) if labels[i] == 1]
        ham_emails = [emails[i] for i in range(len(emails)) if labels[i] == 0]
        
        self.p_spam = len(spam_emails) / len(emails)
        self.p_ham = len(ham_emails) / len(emails)
        
        # ç»Ÿè®¡è¯é¢‘
        spam_words = [word for email in spam_emails for word in email]
        ham_words = [word for email in ham_emails for word in email]
        
        vocab = set(spam_words + ham_words)
        
        for word in vocab:
            self.word_prob_spam[word] = (spam_words.count(word) + 1) / (len(spam_words) + len(vocab))
            self.word_prob_ham[word] = (ham_words.count(word) + 1) / (len(ham_words) + len(vocab))
    
    def predict(self, email):
        """é¢„æµ‹é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶"""
        # P(spam|email) âˆ P(email|spam) * P(spam)
        log_p_spam = np.log(self.p_spam)
        log_p_ham = np.log(self.p_ham)
        
        for word in email:
            if word in self.word_prob_spam:
                log_p_spam += np.log(self.word_prob_spam[word])
                log_p_ham += np.log(self.word_prob_ham[word])
        
        return 1 if log_p_spam > log_p_ham else 0

# è®­ç»ƒæ•°æ®
emails = [
    ['free', 'money', 'now'],
    ['meeting', 'schedule', 'tomorrow'],
    ['win', 'prize', 'free'],
    ['project', 'deadline', 'update']
]
labels = [1, 0, 1, 0]  # 1=spam, 0=ham

classifier = NaiveBayesSpamFilter()
classifier.train(emails, labels)

test_email = ['free', 'prize']
print(f"é¢„æµ‹: {'åƒåœ¾é‚®ä»¶' if classifier.predict(test_email) == 1 else 'æ­£å¸¸é‚®ä»¶'}")
```

### 1.3 äº‹ä»¶ç‹¬ç«‹æ€§

**å®šä¹‰ï¼š**

$$
P(A \cap B) = P(A) \cdot P(B)
$$

**åº”ç”¨ï¼šéšæœºç®—æ³•åˆ†æ**

```python
def random_quicksort_analysis():
    """
    å¿«é€Ÿæ’åºçš„æœŸæœ›å¤æ‚åº¦åˆ†æ
    åŸºäºç‹¬ç«‹æ€§å‡è®¾
    """
    import random
    
    def quicksort_comparisons(arr, count=[0]):
        if len(arr) <= 1:
            return arr
        
        pivot = arr[0]
        count[0] += len(arr) - 1  # ä¸pivotæ¯”è¾ƒæ¬¡æ•°
        
        left = [x for x in arr[1:] if x <= pivot]
        right = [x for x in arr[1:] if x > pivot]
        
        return quicksort_comparisons(left, count) + [pivot] + quicksort_comparisons(right, count)
    
    n = 100
    trials = 1000
    total_comparisons = 0
    
    for _ in range(trials):
        arr = list(range(n))
        random.shuffle(arr)
        count = [0]
        quicksort_comparisons(arr, count)
        total_comparisons += count[0]
    
    avg_comparisons = total_comparisons / trials
    theoretical = n * np.log(n) * 1.386  # â‰ˆ 2n ln n
    
    print(f"å¹³å‡æ¯”è¾ƒæ¬¡æ•°: {avg_comparisons:.0f}")
    print(f"ç†è®ºå€¼ (2n ln n): {theoretical:.0f}")

random_quicksort_analysis()
```

---

## 2. éšæœºå˜é‡ä¸åˆ†å¸ƒ