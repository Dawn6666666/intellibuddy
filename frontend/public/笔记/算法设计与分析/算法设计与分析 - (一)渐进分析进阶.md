# 算法设计与分析 - (一)渐进分析进阶

深入理解算法复杂度分析。

---

## 1. 渐进分析进阶

### 1.1 渐进符号族

| 符号 | 定义 | 含义 |
|------|------|------|
| $O$ | $f(n) = O(g(n))$ | 上界（≤） |
| $\Omega$ | $f(n) = \Omega(g(n))$ | 下界（≥） |
| $\Theta$ | $f(n) = \Theta(g(n))$ | 紧界（=） |
| $o$ | $f(n) = o(g(n))$ | 严格上界（<） |
| $\omega$ | $f(n) = \omega(g(n))$ | 严格下界（>） |

**示例：**

$$
3n^2 + 2n + 1 = \Theta(n^2)
$$

```python
# 验证渐进关系
import numpy as np
import matplotlib.pyplot as plt

def plot_asymptotic():
    n = np.arange(1, 100)
    
    f = 3*n**2 + 2*n + 1
    g_upper = 4*n**2  # O(n²)的上界常数
    g_lower = 2*n**2  # Ω(n²)的下界常数
    
    plt.plot(n, f, label='f(n) = 3n² + 2n + 1')
    plt.plot(n, g_upper, '--', label='4n² (上界)')
    plt.plot(n, g_lower, '--', label='2n² (下界)')
    plt.xlabel('n')
    plt.ylabel('运行时间')
    plt.title('渐进符号可视化')
    plt.legend()
    plt.grid()
    plt.show()

plot_asymptotic()
```

### 1.2 主定理（Master Theorem）

**形式：**$T(n) = aT(n/b) + f(n)$

**判别：**

1. 若 $f(n) = O(n^{\log_b a - \epsilon})$ → $T(n) = \Theta(n^{\log_b a})$
2. 若 $f(n) = \Theta(n^{\log_b a})$ → $T(n) = \Theta(n^{\log_b a} \log n)$
3. 若 $f(n) = \Omega(n^{\log_b a + \epsilon})$ → $T(n) = \Theta(f(n))$

**示例：**

```python
def master_theorem_solver(a, b, f_complexity):
    """
    主定理求解器
    a: 子问题个数
    b: 规模缩减因子
    f_complexity: f(n)的复杂度（如 "n", "n^2", "nlogn"）
    """
    import math
    
    log_b_a = math.log(a) / math.log(b)
    print(f"递推式: T(n) = {a}T(n/{b}) + {f_complexity}")
    print(f"log_{b}({a}) = {log_b_a:.2f}")
    
    # 简化分析
    if "n^2" in f_complexity and log_b_a < 2:
        print(f"情况3: T(n) = Θ({f_complexity})")
    elif "nlogn" in f_complexity and abs(log_b_a - 1) < 0.01:
        print(f"情况2: T(n) = Θ(n log² n)")
    elif log_b_a > 1:
        print(f"情况1: T(n) = Θ(n^{log_b_a:.2f})")

# 归并排序
master_theorem_solver(2, 2, "n")  # T(n) = 2T(n/2) + n

# Strassen矩阵乘法
master_theorem_solver(7, 2, "n^2")  # T(n) = 7T(n/2) + n²
```

### 1.3 递归树分析法

**递归树**是一种可视化递归关系的方法，通过树形结构分析算法复杂度。

```python
def visualize_recursion_tree(a, b, depth=3):
    """
    可视化递归树
    T(n) = aT(n/b) + cn
    """
    import math
    
    print(f"递归树分析: T(n) = {a}T(n/{b}) + cn\n")
    
    total_cost = 0
    
    for level in range(depth + 1):
        # 第level层
        num_nodes = a ** level  # 节点数
        problem_size = f"n/{b**level}"  # 问题规模
        cost_per_node = f"c·{problem_size}"  # 每个节点代价
        level_cost = f"{num_nodes} × {cost_per_node}"
        
        print(f"层 {level}:")
        print(f"  节点数: {num_nodes}")
        print(f"  问题规模: {problem_size}")
        print(f"  层代价: {level_cost}")
        
        # 计算数值（假设n=1024, c=1）
        n = 1024
        c = 1
        actual_cost = num_nodes * c * (n / (b ** level))
        total_cost += actual_cost
        print(f"  实际代价(n={n}): {actual_cost:.2f}\n")
    
    print(f"总代价估计: {total_cost:.2f}")
    
    # 理论分析
    log_b_a = math.log(a) / math.log(b)
    print(f"\nlog_{b}({a}) = {log_b_a:.2f}")
    
    if abs(log_b_a - 1) < 0.01:
        print(f"结论: T(n) = Θ(n log n)")
    elif log_b_a > 1:
        print(f"结论: T(n) = Θ(n^{log_b_a:.2f})")
    else:
        print(f"结论: T(n) = Θ(n)")

# 示例：归并排序
print("=" * 60)
print("归并排序递归树")
print("=" * 60)
visualize_recursion_tree(2, 2, depth=4)

print("\n" + "=" * 60)
print("Strassen算法递归树")
print("=" * 60)
visualize_recursion_tree(7, 2, depth=3)
```

### 1.4 摊还分析（Amortized Analysis）

**摊还分析**用于分析一系列操作的平均代价，常用于动态数据结构。

#### 1.4.1 聚合分析

```python
class DynamicArray:
    """
    动态数组 - 聚合分析示例
    """
    def __init__(self):
        self.capacity = 1
        self.size = 0
        self.array = [None] * self.capacity
        self.total_cost = 0  # 总操作代价
    
    def append(self, value):
        """
        追加元素
        """
        # 如果满了，扩容为2倍
        if self.size == self.capacity:
            self._resize(2 * self.capacity)
        
        self.array[self.size] = value
        self.size += 1
        self.total_cost += 1  # 基本操作代价
    
    def _resize(self, new_capacity):
        """
        扩容操作
        """
        new_array = [None] * new_capacity
        for i in range(self.size):
            new_array[i] = self.array[i]
            self.total_cost += 1  # 复制代价
        
        self.array = new_array
        self.capacity = new_capacity
        print(f"扩容到 {new_capacity}, 总代价: {self.total_cost}")
    
    def analyze_amortized_cost(self, n):
        """
        分析n次插入的摊还代价
        """
        print(f"\n插入{n}个元素的摊还分析:")
        print(f"总操作代价: {self.total_cost}")
        print(f"摊还代价: {self.total_cost / n:.2f} per operation")
        print(f"结论: O(1) 摊还时间")

# 测试
arr = DynamicArray()
n = 16

for i in range(n):
    arr.append(i)

arr.analyze_amortized_cost(n)
```

**分析**：
- 插入操作总代价：$n + \sum_{i=0}^{\log n} 2^i = n + (2n - 1) = 3n - 1$
- 摊还代价：$(3n - 1) / n = O(1)$

#### 1.4.2 势能法

```python
class BinaryCounter:
    """
    二进制计数器 - 势能法分析
    """
    def __init__(self, k):
        self.bits = [0] * k  # k位二进制
        self.k = k
    
    def increment(self):
        """
        加1操作
        """
        i = 0
        flips = 0  # 翻转次数
        
        while i < self.k and self.bits[i] == 1:
            self.bits[i] = 0
            flips += 1
            i += 1
        
        if i < self.k:
            self.bits[i] = 1
            flips += 1
        
        return flips
    
    def potential(self):
        """
        势能函数：1的个数
        """
        return sum(self.bits)
    
    def analyze_potential_method(self, n):
        """
        势能法分析n次增量操作
        """
        print(f"\n势能法分析 {n} 次增量操作:\n")
        
        total_actual_cost = 0
        initial_potential = self.potential()
        
        for i in range(n):
            old_potential = self.potential()
            actual_cost = self.increment()
            new_potential = self.potential()
            
            # 摊还代价 = 实际代价 + 势能变化
            amortized_cost = actual_cost + (new_potential - old_potential)
            
            total_actual_cost += actual_cost
            
            if i < 10 or i == n - 1:  # 只打印前10次和最后一次
                print(f"操作 {i+1}:")
                print(f"  实际代价: {actual_cost}")
                print(f"  势能变化: {new_potential - old_potential}")
                print(f"  摊还代价: {amortized_cost}")
                print(f"  当前值: {''.join(map(str, reversed(self.bits)))}")
        
        final_potential = self.potential()
        
        print(f"\n总结:")
        print(f"  总实际代价: {total_actual_cost}")
        print(f"  势能变化: {final_potential - initial_potential}")
        print(f"  平均摊还代价: {(total_actual_cost + final_potential - initial_potential) / n:.2f}")
        print(f"  结论: O(1) 摊还时间")

# 测试
counter = BinaryCounter(8)
counter.analyze_potential_method(16)
```

**势能法关键**：
- 势能函数 $\Phi$：数据结构的"能量"
- 摊还代价：$\hat{c}_i = c_i + \Phi(D_i) - \Phi(D_{i-1})$
- 要求：$\Phi(D_n) \geq \Phi(D_0)$

### 1.5 概率分析与随机算法

#### 1.5.1 期望运行时间

```python
import random

def randomized_quicksort(arr):
    """
    随机化快速排序 - 期望O(n log n)
    """
    comparisons = [0]  # 用列表存储以便在递归中修改
    
    def partition(low, high):
        # 随机选择主元
        pivot_idx = random.randint(low, high)
        arr[pivot_idx], arr[high] = arr[high], arr[pivot_idx]
        
        pivot = arr[high]
        i = low - 1
        
        for j in range(low, high):
            comparisons[0] += 1
            if arr[j] <= pivot:
                i += 1
                arr[i], arr[j] = arr[j], arr[i]
        
        arr[i + 1], arr[high] = arr[high], arr[i + 1]
        return i + 1
    
    def quicksort(low, high):
        if low < high:
            pi = partition(low, high)
            quicksort(low, pi - 1)
            quicksort(pi + 1, high)
    
    quicksort(0, len(arr) - 1)
    return comparisons[0]

# 多次运行分析期望性能
def analyze_expected_performance(n, trials=100):
    """
    分析随机化快速排序的期望性能
    """
    print(f"分析规模n={n}的随机化快速排序\n")
    
    comparison_counts = []
    
    for _ in range(trials):
        arr = list(range(n))
        random.shuffle(arr)
        comparisons = randomized_quicksort(arr)
        comparison_counts.append(comparisons)
    
    avg_comparisons = sum(comparison_counts) / trials
    theoretical = n * (n - 1) / 2  # 最坏情况
    expected_nlogn = 2 * n * (n.bit_length() - 1)  # 近似 2n ln n
    
    print(f"实验结果 ({trials}次试验):")
    print(f"  平均比较次数: {avg_comparisons:.2f}")
    print(f"  最坏情况 O(n²): {theoretical:.2f}")
    print(f"  期望 O(n log n): {expected_nlogn:.2f}")
    print(f"  实际/期望比: {avg_comparisons / expected_nlogn:.2f}")

analyze_expected_performance(100, trials=100)
```

#### 1.5.2 拉斯维加斯 vs 蒙特卡洛算法

```python
import random

def las_vegas_primality(n, max_attempts=100):
    """
    拉斯维加斯算法 - 总是正确，但运行时间随机
    素性测试（简化版）
    """
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    attempts = 0
    
    while attempts < max_attempts:
        a = random.randint(2, n - 1)
        
        # 费马小定理测试
        if pow(a, n - 1, n) != 1:
            return False  # 确定是合数
        
        attempts += 1
    
    return True  # 可能是素数（概率很高）

def monte_carlo_pi(n):
    """
    蒙特卡洛算法 - 运行时间确定，但结果近似
    估算π值
    """
    inside_circle = 0
    
    for _ in range(n):
        x = random.uniform(0, 1)
        y = random.uniform(0, 1)
        
        if x*x + y*y <= 1:
            inside_circle += 1
    
    pi_estimate = 4 * inside_circle / n
    return pi_estimate

# 对比两种算法
print("=" * 60)
print("拉斯维加斯算法 vs 蒙特卡洛算法")
print("=" * 60)

print("\n拉斯维加斯算法（素性测试）:")
test_numbers = [17, 19, 21, 97, 100]
for num in test_numbers:
    is_prime = las_vegas_primality(num)
    print(f"  {num}: {'素数' if is_prime else '合数'}")

print("\n蒙特卡洛算法（估算π）:")
for n in [100, 1000, 10000, 100000]:
    pi_est = monte_carlo_pi(n)
    error = abs(pi_est - 3.14159265359) / 3.14159265359 * 100
    print(f"  n={n:6d}: π ≈ {pi_est:.6f}, 误差: {error:.2f}%")
```

### 1.6 复杂度类对比

```python
import time
import matplotlib.pyplot as plt
import numpy as np

def compare_complexity_classes():
    """
    可视化不同复杂度类的增长
    """
    n_values = np.logspace(0, 3, 50)  # 1 到 1000
    
    complexities = {
        'O(1)': lambda n: np.ones_like(n),
        'O(log n)': lambda n: np.log2(n),
        'O(n)': lambda n: n,
        'O(n log n)': lambda n: n * np.log2(n),
        'O(n²)': lambda n: n**2,
        'O(n³)': lambda n: n**3,
        'O(2ⁿ)': lambda n: 2**n
    }
    
    plt.figure(figsize=(12, 8))
    
    for name, func in complexities.items():
        try:
            y_values = func(n_values)
            # 只绘制合理范围内的值
            if name == 'O(2ⁿ)':
                mask = n_values <= 20
                plt.semilogy(n_values[mask], y_values[mask], label=name, linewidth=2)
            else:
                plt.semilogy(n_values, y_values, label=name, linewidth=2)
        except:
            pass
    
    plt.xlabel('输入规模 n', fontsize=12)
    plt.ylabel('操作次数（对数刻度）', fontsize=12)
    plt.title('算法复杂度类对比', fontsize=14, fontweight='bold')
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # 保存图表
    # plt.savefig('complexity_comparison.png', dpi=300)
    plt.show()
    
    # 打印具体数值对比
    print("\n复杂度对比表（n=1000时）:\n")
    print(f"{'复杂度':<15} {'操作次数':<20} {'相对O(n)的倍数':<15}")
    print("-" * 50)
    
    n = 1000
    base = n  # O(n)作为基准
    
    for name, func in complexities.items():
        if name == 'O(2ⁿ)':
            continue  # 太大了
        ops = func(np.array([n]))[0]
        ratio = ops / base
        print(f"{name:<15} {ops:<20.2e} {ratio:<15.2e}")

# 运行对比
compare_complexity_classes()
```

---

**本章完**
