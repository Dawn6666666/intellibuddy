# 机器学习 - (七)超参数优化

学习超参数优化策略。

---

## 7. 超参数优化

### 7.1 网格搜索

```python
class GridSearchCV:
    """网格搜索交叉验证"""
    def __init__(self, model, param_grid, cv=5):
        self.model = model
        self.param_grid = param_grid
        self.cv = cv
        self.best_params = None
        self.best_score = -np.inf
    
    def generate_combinations(self, param_grid):
        """生成参数组合"""
        import itertools
        
        keys = param_grid.keys()
        values = param_grid.values()
        
        for combination in itertools.product(*values):
            yield dict(zip(keys, combination))
    
    def fit(self, X, y):
        """网格搜索"""
        results = []
        
        for params in self.generate_combinations(self.param_grid):
            # 设置模型参数
            for key, value in params.items():
                setattr(self.model, key, value)
            
            # 交叉验证
            kfold = KFoldCV(k=self.cv)
            scores = kfold.cross_validate(self.model, X, y)
            mean_score = np.mean(scores)
            
            results.append({
                'params': params,
                'score': mean_score
            })
            
            # 更新最佳参数
            if mean_score > self.best_score:
                self.best_score = mean_score
                self.best_params = params
            
            print(f"Params: {params}, Score: {mean_score:.4f}")
        
        return self

# 示例
param_grid = {
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(DecisionTree(), param_grid, cv=3)
grid_search.fit(X, y)

print(f"\n最佳参数: {grid_search.best_params}")
print(f"最佳得分: {grid_search.best_score:.4f}")
```

### 7.2 随机搜索

```python
class RandomizedSearchCV:
    """随机搜索"""
    def __init__(self, model, param_distributions, n_iter=10, cv=5):
        self.model = model
        self.param_distributions = param_distributions
        self.n_iter = n_iter
        self.cv = cv
        self.best_params = None
        self.best_score = -np.inf
    
    def sample_params(self):
        """随机采样参数"""
        params = {}
        
        for key, values in self.param_distributions.items():
            if isinstance(values, list):
                params[key] = np.random.choice(values)
            elif isinstance(values, tuple) and len(values) == 2:
                # 假设是范围(low, high)
                params[key] = np.random.uniform(values[0], values[1])
        
        return params
    
    def fit(self, X, y):
        """随机搜索"""
        for i in range(self.n_iter):
            params = self.sample_params()
            
            # 设置参数
            for key, value in params.items():
                setattr(self.model, key, value)
            
            # 交叉验证
            kfold = KFoldCV(k=self.cv)
            scores = kfold.cross_validate(self.model, X, y)
            mean_score = np.mean(scores)
            
            if mean_score > self.best_score:
                self.best_score = mean_score
                self.best_params = params
            
            print(f"Iteration {i+1}: {params}, Score: {mean_score:.4f}")
        
        return self

# 示例
param_dist = {
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10, 20]
}

random_search = RandomizedSearchCV(DecisionTree(), param_dist, n_iter=10, cv=3)
random_search.fit(X, y)

print(f"\n最佳参数: {random_search.best_params}")
print(f"最佳得分: {random_search.best_score:.4f}")
```

---

**本章完**
