# 概率论与数理统计 - (六)假设检验

掌握假设检验的基本方法。

---

## 6. 假设检验

假设检验是统计推断的另一核心内容，用于判断样本数据是否支持某个关于总体的假设。

### 6.1 基本概念

#### 假设的提出

**原假设（Null Hypothesis）** $H_0$：
- 待检验的假设，通常是"无差异"、"无效果"
- 默认为真，除非有足够证据拒绝

**备择假设（Alternative Hypothesis）** $H_1$ 或 $H_a$：
- 与 $H_0$ 对立的假设
- 研究者希望证明的假设

**例**：检验某药物是否有效
- $H_0$: $\mu = \mu_0$（药物无效）
- $H_1$: $\mu \neq \mu_0$（药物有效）

#### 检验类型

**双侧检验（Two-tailed test）**：
$$
H_0: \theta = \theta_0 \quad \text{vs} \quad H_1: \theta \neq \theta_0
$$

**单侧检验（One-tailed test）**：
$$
H_0: \theta \leq \theta_0 \quad \text{vs} \quad H_1: \theta > \theta_0
$$
或
$$
H_0: \theta \geq \theta_0 \quad \text{vs} \quad H_1: \theta < \theta_0
$$

#### 两类错误

| | $H_0$ 为真 | $H_0$ 为假 |
|---|---|---|
| **拒绝 $H_0$** | <span style="color:red">**I型错误**</span><br>概率 = $\alpha$ | ✅ 正确决策<br>概率 = $1-\beta$（**功效/势**） |
| **接受 $H_0$** | ✅ 正确决策<br>概率 = $1-\alpha$ | <span style="color:red">**II型错误**</span><br>概率 = $\beta$ |

**I型错误（Type I Error）**："弃真"错误
- 概率记为 $\alpha$，称为**显著性水平**
- 通常控制在 0.05 或 0.01

**II型错误（Type II Error）**："取伪"错误
- 概率记为 $\beta$
- $1-\beta$ 称为**检验功效（Power）**

**权衡**：
- 减小 $\alpha$ 会增大 $\beta$（在样本量固定时）
- 增大样本量可以同时减小两类错误

#### 显著性水平与p值

**显著性水平 $\alpha$**：
- 事先设定的I型错误概率上限
- 常用值：0.05, 0.01, 0.001

**p值（p-value）**：
- 在 $H_0$ 为真的前提下，观察到当前样本统计量或更极端值的概率
- **判断准则**：
  - $p < \alpha$：拒绝 $H_0$
  - $p \geq \alpha$：不拒绝 $H_0$

**正确理解**：
- ✅ p值是数据与 $H_0$ 的不相容程度
- ✅ p值越小，拒绝 $H_0$ 的证据越强
- ❌ p值**不是** $H_0$ 为真的概率
- ❌ p值**不是** $H_1$ 为真的概率

#### 检验步骤

1. **建立假设**：提出 $H_0$ 和 $H_1$
2. **选择检验统计量**：如 $t$, $\chi^2$, $F$ 等
3. **确定显著性水平**：通常 $\alpha = 0.05$
4. **计算统计量**：从样本数据计算检验统计量的值
5. **确定临界值或p值**：
   - 方法1：比较统计量与临界值
   - 方法2：计算p值并与 $\alpha$ 比较
6. **做出决策**：拒绝或不拒绝 $H_0$

### 6.2 正态总体的假设检验

#### 单个正态总体

##### (1) 均值的检验（$\sigma^2$ 已知）

**假设**：
$$
H_0: \mu = \mu_0 \quad \text{vs} \quad H_1: \mu \neq \mu_0
$$

**检验统计量**（Z检验）：
$$
Z = \frac{\overline{X} - \mu_0}{\sigma / \sqrt{n}} \sim N(0, 1) \quad (\text{在} H_0 \text{下})
$$

**拒绝域**（双侧，显著性水平 $\alpha$）：
$$
|Z| > z_{\alpha/2}
$$

**p值**：
$$
p = 2P(Z > |z_{\text{obs}}|) = 2[1 - \Phi(|z_{\text{obs}}|)]
$$

##### (2) 均值的检验（$\sigma^2$ 未知）

**检验统计量**（t检验）：
$$
t = \frac{\overline{X} - \mu_0}{S / \sqrt{n}} \sim t(n-1) \quad (\text{在} H_0 \text{下})
$$

**拒绝域**（双侧）：
$$
|t| > t_{\alpha/2}(n-1)
$$

**例1**：某品牌电池声称平均寿命为500小时。抽取25个样本，得 $\overline{x} = 485$，$s = 40$。在 $\alpha = 0.05$ 下检验该声称。

**解**：

1. $H_0: \mu = 500$ vs $H_1: \mu \neq 500$
2. 统计量：$t = \frac{485 - 500}{40/\sqrt{25}} = \frac{-15}{8} = -1.875$
3. 临界值：$t_{0.025}(24) \approx 2.064$
4. $|t| = 1.875 < 2.064$，不拒绝 $H_0$
5. 结论：没有足够证据表明平均寿命不是500小时

##### (3) 方差的检验（$\mu$ 未知）

**假设**：
$$
H_0: \sigma^2 = \sigma_0^2 \quad \text{vs} \quad H_1: \sigma^2 \neq \sigma_0^2
$$

**检验统计量**（$\chi^2$ 检验）：
$$
\chi^2 = \frac{(n-1)S^2}{\sigma_0^2} \sim \chi^2(n-1) \quad (\text{在} H_0 \text{下})
$$

**拒绝域**（双侧）：
$$
\chi^2 < \chi^2_{1-\alpha/2}(n-1) \quad \text{或} \quad \chi^2 > \chi^2_{\alpha/2}(n-1)
$$

#### 两个正态总体

##### (1) 均值差的检验（$\sigma_1^2 = \sigma_2^2$ 未知）

**假设**：
$$
H_0: \mu_1 = \mu_2 \quad \text{vs} \quad H_1: \mu_1 \neq \mu_2
$$

**检验统计量**（独立样本t检验）：
$$
t = \frac{\overline{X} - \overline{Y}}{S_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t(n_1 + n_2 - 2)
$$

其中合并方差：
$$
S_p^2 = \frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 - 2}
$$

##### (2) 配对t检验

当两组数据配对（如同一个体前后测量）时，令 $D_i = X_i - Y_i$

**检验统计量**：
$$
t = \frac{\overline{D} - 0}{S_D / \sqrt{n}} \sim t(n-1)
$$

##### (3) 方差比的检验（F检验）

**假设**：
$$
H_0: \sigma_1^2 = \sigma_2^2 \quad \text{vs} \quad H_1: \sigma_1^2 \neq \sigma_2^2
$$

**检验统计量**：
$$
F = \frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)
$$

**拒绝域**（双侧）：
$$
F < F_{1-\alpha/2}(n_1-1, n_2-1) \quad \text{或} \quad F > F_{\alpha/2}(n_1-1, n_2-1)
$$

### 6.3 检验的功效与样本量

#### 功效函数（Power Function）

**定义**：在参数真值为 $\theta$ 时，拒绝 $H_0$ 的概率

$$
\text{Power}(\theta) = P(\text{拒绝} H_0 | \theta)
$$

**特殊情况**：
- 当 $\theta \in H_0$ 时，$\text{Power}(\theta) = \alpha$（I型错误）
- 当 $\theta \in H_1$ 时，$\text{Power}(\theta) = 1 - \beta$（检验功效）

#### 样本量计算

**问题**：给定 $\alpha$, $\beta$ 和效应量，需要多少样本？

**单样本t检验样本量**（检验 $\mu = \mu_0$ vs $\mu = \mu_1$）：

$$
n \approx \frac{(z_{\alpha/2} + z_\beta)^2 \sigma^2}{(\mu_1 - \mu_0)^2}
$$

**两样本t检验样本量**：

$$
n_1 = n_2 = \frac{2(z_{\alpha/2} + z_\beta)^2 \sigma^2}{(\mu_1 - \mu_2)^2}
$$

**效应量（Effect Size）**：Cohen's d

$$
d = \frac{\mu_1 - \mu_0}{\sigma}
$$

- 小效应：$d = 0.2$
- 中效应：$d = 0.5$
- 大效应：$d = 0.8$

**例2**：设计一个实验检测新药能否降低血压5 mmHg（$\sigma = 10$），要求 $\alpha = 0.05$, $\beta = 0.2$（功效80%），需要多少样本？

**解**：

$$
d = \frac{5}{10} = 0.5 \quad (\text{中等效应})
$$

$$
n \approx \frac{(1.96 + 0.84)^2 \times 10^2}{5^2} = \frac{7.84 \times 100}{25} \approx 31.4
$$

至少需要 32 个样本。

### 6.4 卡方检验

#### 拟合优度检验（Goodness-of-Fit Test）

**目的**：检验样本数据是否来自某个指定分布

**假设**：
$$
H_0: \text{数据服从指定分布} \quad \text{vs} \quad H_1: \text{数据不服从该分布}
$$

**检验统计量**：

$$
\chi^2 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i} \sim \chi^2(k - 1 - r)
$$

- $O_i$：观察频数
- $E_i$：期望频数
- $k$：类别数
- $r$：估计的参数个数

**例3**：掷骰子60次，各面出现次数为 (8, 12, 10, 9, 11, 10)。检验骰子是否均匀。

**解**：

1. $H_0$：骰子均匀，每面概率 $p_i = 1/6$
2. 期望频数：$E_i = 60 \times \frac{1}{6} = 10$（所有$i$）
3. 统计量：
   $$
   \chi^2 = \frac{(8-10)^2}{10} + \frac{(12-10)^2}{10} + \cdots + \frac{(10-10)^2}{10} = \frac{4+4+0+1+1+0}{10} = 1.0
   $$
4. 临界值：$\chi^2_{0.05}(5) = 11.07$
5. $1.0 < 11.07$，不拒绝 $H_0$，骰子可能是均匀的

#### 独立性检验（Test of Independence）

**目的**：检验两个分类变量是否独立

**列联表**（$r \times c$）：

|  | $B_1$ | $B_2$ | $\cdots$ | $B_c$ | 合计 |
|---|---|---|---|---|---|
| $A_1$ | $n_{11}$ | $n_{12}$ | $\cdots$ | $n_{1c}$ | $n_{1\cdot}$ |
| $A_2$ | $n_{21}$ | $n_{22}$ | $\cdots$ | $n_{2c}$ | $n_{2\cdot}$ |
| $\vdots$ | $\vdots$ | $\vdots$ | $\ddots$ | $\vdots$ | $\vdots$ |
| $A_r$ | $n_{r1}$ | $n_{r2}$ | $\cdots$ | $n_{rc}$ | $n_{r\cdot}$ |
| 合计 | $n_{\cdot 1}$ | $n_{\cdot 2}$ | $\cdots$ | $n_{\cdot c}$ | $n$ |

**期望频数**：

$$
E_{ij} = \frac{n_{i\cdot} \times n_{\cdot j}}{n}
$$

**检验统计量**：

$$
\chi^2 = \sum_{i=1}^{r} \sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}} \sim \chi^2((r-1)(c-1))
$$

**例4**：研究性别与产品偏好的关系：

|  | 产品A | 产品B | 产品C |
|---|---|---|---|
| 男性 | 30 | 20 | 10 |
| 女性 | 15 | 25 | 20 |

检验性别与偏好是否独立（$\alpha = 0.05$）。

**解**：

1. 计算期望频数（如 $E_{11} = \frac{60 \times 45}{120} = 22.5$）
2. 计算 $\chi^2$ 统计量
3. 自由度：$(2-1)(3-1) = 2$
4. 临界值：$\chi^2_{0.05}(2) = 5.991$
5. 若 $\chi^2 > 5.991$，拒绝独立性假设

#### 同质性检验（Test of Homogeneity）

检验不同总体的分布是否相同（形式与独立性检验相同，但解释不同）

### 6.5 非参数检验

**非参数检验**：不假设数据服从特定分布的检验方法

**适用场景**：
- 数据不满足正态性假设
- 样本量很小
- 数据为有序分类数据（如：差、中、好）
- 稳健性要求高

#### Wilcoxon符号秩检验（Signed-Rank Test）

**目的**：检验单个样本的中位数（替代单样本t检验）

**步骤**：
1. 计算 $D_i = X_i - \mu_0$
2. 对 $|D_i|$ 排秩，记为 $R_i$
3. 计算正秩和：$W^+ = \sum_{D_i > 0} R_i$
4. 查表或用正态近似

**大样本近似**（$n > 20$）：

$$
Z = \frac{W^+ - n(n+1)/4}{\sqrt{n(n+1)(2n+1)/24}} \sim N(0, 1)
$$

#### Wilcoxon秩和检验（Rank-Sum Test / Mann-Whitney U Test）

**目的**：比较两组独立样本（替代独立样本t检验）

**步骤**：
1. 合并两组数据并排秩
2. 计算第一组的秩和 $W_1$
3. 计算统计量：
   $$
   U = W_1 - \frac{n_1(n_1+1)}{2}
   $$

**大样本近似**（$n_1, n_2 > 10$）：

$$
Z = \frac{U - n_1 n_2 / 2}{\sqrt{n_1 n_2 (n_1 + n_2 + 1) / 12}} \sim N(0, 1)
$$

#### Kruskal-Wallis检验

**目的**：比较三组及以上独立样本（替代单因素方差分析）

**检验统计量**：

$$
H = \frac{12}{N(N+1)} \sum_{i=1}^{k} \frac{R_i^2}{n_i} - 3(N+1)
$$

其中 $R_i$ 是第 $i$ 组的秩和，$N = \sum n_i$

**分布**：$H \sim \chi^2(k-1)$（近似）

#### Kolmogorov-Smirnov检验（K-S检验）

**目的**：检验样本是否来自某个连续分布

**统计量**：

$$
D = \sup_x |F_n(x) - F_0(x)|
$$

- $F_n(x)$：经验分布函数
- $F_0(x)$：理论分布函数

**优点**：
- 适用于连续数据
- 对分布偏离的整体敏感

**缺点**：
- 对尾部偏离不敏感
- 功效低于针对性检验

### 6.6 多重检验校正

#### 多重比较问题

当进行 $m$ 次独立检验时，至少一次I型错误的概率：

$$
P(\text{至少一次I型错误}) = 1 - (1-\alpha)^m
$$

**例**：$m = 20$, $\alpha = 0.05$
$$
1 - 0.95^{20} \approx 0.64
$$

#### Bonferroni校正

**方法**：将显著性水平调整为 $\alpha / m$

**优点**：简单、保守
**缺点**：功效损失大

#### Holm-Bonferroni方法

**步骤**（依序检验法）：
1. 将p值从小到大排序：$p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(m)}$
2. 从 $i=1$ 开始，若 $p_{(i)} \leq \frac{\alpha}{m-i+1}$，拒绝并继续
3. 否则停止，后续全部不拒绝

**优点**：比Bonferroni更有功效

#### FDR（False Discovery Rate）控制

**Benjamini-Hochberg方法**：

1. 排序p值：$p_{(1)} \leq \cdots \leq p_{(m)}$
2. 找最大的 $i$ 使得 $p_{(i)} \leq \frac{i \cdot \alpha}{m}$
3. 拒绝 $H_{(1)}, \ldots, H_{(i)}$

**适用**：基因组学等需要控制错误发现率的场景

### 6.7 应用实例

#### 应用1：完整的t检验流程

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def complete_t_test(data, mu0, alpha=0.05, alternative='two-sided'):
    """
    完整的单样本t检验（含可视化、功效分析）
    
    参数:
    - data: 样本数据
    - mu0: 原假设均值
    - alpha: 显著性水平
    - alternative: 'two-sided', 'greater', 'less'
    """
    n = len(data)
    xbar = np.mean(data)
    s = np.std(data, ddof=1)
    se = s / np.sqrt(n)
    
    # 计算t统计量
    t_stat = (xbar - mu0) / se
    df = n - 1
    
    # 计算p值
    if alternative == 'two-sided':
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))
        critical_t = stats.t.ppf(1 - alpha/2, df)
        reject_region = f"|t| > {critical_t:.4f}"
    elif alternative == 'greater':
        p_value = 1 - stats.t.cdf(t_stat, df)
        critical_t = stats.t.ppf(1 - alpha, df)
        reject_region = f"t > {critical_t:.4f}"
    else:  # less
        p_value = stats.t.cdf(t_stat, df)
        critical_t = stats.t.ppf(alpha, df)
        reject_region = f"t < {critical_t:.4f}"
    
    # 置信区间
    margin = stats.t.ppf(1 - alpha/2, df) * se
    ci = (xbar - margin, xbar + margin)
    
    # 效应量（Cohen's d）
    cohens_d = (xbar - mu0) / s
    
    # 输出结果
    print("=" * 50)
    print("单样本t检验结果")
    print("=" * 50)
    print(f"原假设: μ = {mu0}")
    print(f"备择假设: μ {alternative} {mu0}")
    print(f"显著性水平: α = {alpha}")
    print(f"\n样本统计量:")
    print(f"  样本量: n = {n}")
    print(f"  样本均值: x̄ = {xbar:.4f}")
    print(f"  样本标准差: s = {s:.4f}")
    print(f"  标准误: SE = {se:.4f}")
    print(f"\n检验统计量:")
    print(f"  t统计量: t = {t_stat:.4f}")
    print(f"  自由度: df = {df}")
    print(f"  p值: p = {p_value:.4f}")
    print(f"\n判断:")
    print(f"  拒绝域: {reject_region}")
    
    if p_value < alpha:
        print(f"  ✓ 拒绝原假设 (p = {p_value:.4f} < {alpha})")
        print(f"    结论: 有显著证据表明 μ ≠ {mu0}")
    else:
        print(f"  ✗ 不拒绝原假设 (p = {p_value:.4f} ≥ {alpha})")
        print(f"    结论: 没有充分证据拒绝 μ = {mu0}")
    
    print(f"\n效应量:")
    print(f"  Cohen's d = {cohens_d:.4f}")
    if abs(cohens_d) < 0.2:
        print(f"  (极小效应)")
    elif abs(cohens_d) < 0.5:
        print(f"  (小效应)")
    elif abs(cohens_d) < 0.8:
        print(f"  (中等效应)")
    else:
        print(f"  (大效应)")
    
    print(f"\n{(1-alpha)*100}% 置信区间:")
    print(f"  [{ci[0]:.4f}, {ci[1]:.4f}]")
    
    # 可视化
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # 1. 数据分布 + 原假设
    axes[0].hist(data, bins=20, density=True, alpha=0.7, edgecolor='black')
    axes[0].axvline(xbar, color='red', linestyle='-', linewidth=2, label=f'样本均值 = {xbar:.2f}')
    axes[0].axvline(mu0, color='blue', linestyle='--', linewidth=2, label=f'H₀: μ = {mu0}')
    axes[0].set_xlabel('数据值')
    axes[0].set_ylabel('密度')
    axes[0].set_title('数据分布')
    axes[0].legend()
    axes[0].grid(alpha=0.3)
    
    # 2. t分布 + 检验统计量
    x = np.linspace(-4, 4, 200)
    y = stats.t.pdf(x, df)
    axes[1].plot(x, y, 'k-', linewidth=2, label='t分布')
    axes[1].axvline(t_stat, color='red', linestyle='-', linewidth=2, label=f't = {t_stat:.2f}')
    
    if alternative == 'two-sided':
        axes[1].axvline(-critical_t, color='orange', linestyle='--', linewidth=1.5)
        axes[1].axvline(critical_t, color='orange', linestyle='--', linewidth=1.5, label=f'临界值 = ±{critical_t:.2f}')
        # 填充拒绝域
        x_left = np.linspace(-4, -critical_t, 100)
        x_right = np.linspace(critical_t, 4, 100)
        axes[1].fill_between(x_left, stats.t.pdf(x_left, df), alpha=0.3, color='red')
        axes[1].fill_between(x_right, stats.t.pdf(x_right, df), alpha=0.3, color='red')
    
    axes[1].set_xlabel('t值')
    axes[1].set_ylabel('密度')
    axes[1].set_title('t分布与检验统计量')
    axes[1].legend()
    axes[1].grid(alpha=0.3)
    
    # 3. p值可视化
    p_values = [0.001, 0.01, 0.05, 0.1, p_value]
    labels = ['0.001', '0.01', '0.05', '0.1', f'当前\n{p_value:.4f}']
    colors = ['red' if pv < alpha else 'green' for pv in p_values]
    
    axes[2].barh(range(len(p_values)), p_values, color=colors, alpha=0.7, edgecolor='black')
    axes[2].axvline(alpha, color='black', linestyle='--', linewidth=2, label=f'α = {alpha}')
    axes[2].set_yticks(range(len(p_values)))
    axes[2].set_yticklabels(labels)
    axes[2].set_xlabel('p值')
    axes[2].set_title('p值对比')
    axes[2].legend()
    axes[2].grid(alpha=0.3, axis='x')
    
    plt.tight_layout()
    # plt.show()
    
    return {
        't_statistic': t_stat,
        'p_value': p_value,
        'confidence_interval': ci,
        'cohens_d': cohens_d,
        'reject_h0': p_value < alpha
    }

# # 示例
# np.random.seed(42)
# data = np.random.normal(105, 15, 30)  # 真实均值105
# result = complete_t_test(data, mu0=100, alpha=0.05)
```

#### 应用2：A/B测试完整流程

```python
def ab_test(control_data, treatment_data, alpha=0.05):
    """
    A/B测试完整流程（独立样本t检验 + 可视化 + 样本量分析）
    """
    n_control = len(control_data)
    n_treatment = len(treatment_data)
    mean_control = np.mean(control_data)
    mean_treatment = np.mean(treatment_data)
    std_control = np.std(control_data, ddof=1)
    std_treatment = np.std(treatment_data, ddof=1)
    
    print("=" * 60)
    print("A/B测试结果报告")
    print("=" * 60)
    
    # 1. 描述性统计
    print("\n【1. 描述性统计】")
    print(f"对照组 (Control):")
    print(f"  样本量: n = {n_control}")
    print(f"  均值: μ̂ = {mean_control:.4f}")
    print(f"  标准差: σ̂ = {std_control:.4f}")
    
    print(f"\n实验组 (Treatment):")
    print(f"  样本量: n = {n_treatment}")
    print(f"  均值: μ̂ = {mean_treatment:.4f}")
    print(f"  标准差: σ̂ = {std_treatment:.4f}")
    
    # 2. 方差齐性检验（Levene检验）
    print("\n【2. 方差齐性检验】")
    levene_stat, levene_p = stats.levene(control_data, treatment_data)
    print(f"Levene统计量: {levene_stat:.4f}, p值: {levene_p:.4f}")
    equal_var = levene_p > 0.05
    print(f"结论: 方差{'齐性' if equal_var else '不齐'}")
    
    # 3. t检验
    print("\n【3. 独立样本t检验】")
    t_stat, p_value = stats.ttest_ind(treatment_data, control_data, equal_var=equal_var)
    
    print(f"原假设: μ_treatment = μ_control")
    print(f"备择假设: μ_treatment ≠ μ_control")
    print(f"t统计量: t = {t_stat:.4f}")
    print(f"p值: p = {p_value:.4f}")
    
    # 4. 结论
    print("\n【4. 统计结论】")
    if p_value < alpha:
        print(f"✓ 拒绝原假设 (p = {p_value:.4f} < {alpha})")
        print(f"  实验组与对照组存在显著差异")
    else:
        print(f"✗ 不拒绝原假设 (p = {p_value:.4f} ≥ {alpha})")
        print(f"  无充分证据表明两组有差异")
    
    # 5. 效应量分析
    print("\n【5. 效应量分析】")
    diff = mean_treatment - mean_control
    pooled_std = np.sqrt((std_control**2 + std_treatment**2) / 2)
    cohens_d = diff / pooled_std
    relative_lift = (diff / mean_control) * 100
    
    print(f"绝对差异: Δ = {diff:.4f}")
    print(f"相对提升: {relative_lift:.2f}%")
    print(f"Cohen's d = {cohens_d:.4f}", end="")
    if abs(cohens_d) < 0.2:
        print(" (极小效应)")
    elif abs(cohens_d) < 0.5:
        print(" (小效应)")
    elif abs(cohens_d) < 0.8:
        print(" (中等效应)")
    else:
        print(" (大效应)")
    
    # 6. 置信区间
    print("\n【6. 差异的95%置信区间】")
    se_diff = np.sqrt(std_control**2/n_control + std_treatment**2/n_treatment)
    df = n_control + n_treatment - 2
    t_critical = stats.t.ppf(0.975, df)
    ci_lower = diff - t_critical * se_diff
    ci_upper = diff + t_critical * se_diff
    print(f"[{ci_lower:.4f}, {ci_upper:.4f}]")
    
    # 可视化
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # (1) 箱线图对比
    axes[0, 0].boxplot([control_data, treatment_data], 
                       labels=['对照组', '实验组'],
                       showmeans=True, meanline=True)
    axes[0, 0].set_ylabel('指标值')
    axes[0, 0].set_title('组间对比（箱线图）')
    axes[0, 0].grid(alpha=0.3, axis='y')
    
    # (2) 直方图对比
    axes[0, 1].hist(control_data, bins=30, alpha=0.6, label='对照组', edgecolor='black', density=True)
    axes[0, 1].hist(treatment_data, bins=30, alpha=0.6, label='实验组', edgecolor='black', density=True)
    axes[0, 1].axvline(mean_control, color='blue', linestyle='--', linewidth=2)
    axes[0, 1].axvline(mean_treatment, color='orange', linestyle='--', linewidth=2)
    axes[0, 1].set_xlabel('指标值')
    axes[0, 1].set_ylabel('密度')
    axes[0, 1].set_title('分布对比')
    axes[0, 1].legend()
    axes[0, 1].grid(alpha=0.3)
    
    # (3) 均值对比（带误差棒）
    means = [mean_control, mean_treatment]
    sems = [std_control/np.sqrt(n_control), std_treatment/np.sqrt(n_treatment)]
    x_pos = [0, 1]
    colors = ['steelblue', 'coral']
    
    axes[1, 0].bar(x_pos, means, yerr=[s*1.96 for s in sems], 
                   color=colors, alpha=0.7, capsize=10, edgecolor='black')
    axes[1, 0].set_xticks(x_pos)
    axes[1, 0].set_xticklabels(['对照组', '实验组'])
    axes[1, 0].set_ylabel('均值 (±95% CI)')
    axes[1, 0].set_title('均值对比')
    axes[1, 0].grid(alpha=0.3, axis='y')
    
    # (4) 效应量可视化
    metrics = ['相对提升%', '|Cohen\'s d|', 'p值']
    values = [abs(relative_lift), abs(cohens_d)*100, p_value*100]  # 归一化显示
    colors_bar = ['green' if p_value < alpha else 'gray', 
                  'green' if abs(cohens_d) > 0.5 else 'orange',
                  'green' if p_value < alpha else 'red']
    
    axes[1, 1].barh(metrics, values, color=colors_bar, alpha=0.7, edgecolor='black')
    axes[1, 1].set_xlabel('值')
    axes[1, 1].set_title('关键指标')
    axes[1, 1].grid(alpha=0.3, axis='x')
    
    plt.tight_layout()
    # plt.show()
    
    return {
        'mean_diff': diff,
        'p_value': p_value,
        'cohens_d': cohens_d,
        'relative_lift': relative_lift,
        'significant': p_value < alpha
    }

# # 示例
# np.random.seed(42)
# control = np.random.normal(100, 15, 500)  # 对照组
# treatment = np.random.normal(105, 15, 500)  # 实验组（提升5%）
# ab_test(control, treatment)
```

#### 应用3：卡方检验详解

```python
def chi_square_independence_test(contingency_table, row_labels=None, col_labels=None, alpha=0.05):
    """
    卡方独立性检验（含详细输出和可视化）
    """
    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
    
    print("=" * 60)
    print("卡方独立性检验")
    print("=" * 60)
    
    # 1. 列联表
    print("\n【1. 观察频数】")
    if row_labels and col_labels:
        import pandas as pd
        df_observed = pd.DataFrame(contingency_table, 
                                    index=row_labels, 
                                    columns=col_labels)
        print(df_observed)
    else:
        print(contingency_table)
    
    # 2. 期望频数
    print("\n【2. 期望频数】（假设独立）")
    if row_labels and col_labels:
        df_expected = pd.DataFrame(expected, 
                                    index=row_labels, 
                                    columns=col_labels)
        print(df_expected.round(2))
    else:
        print(expected.round(2))
    
    # 3. 检验统计量
    print("\n【3. 检验统计量】")
    print(f"χ² = {chi2:.4f}")
    print(f"自由度 = {dof}")
    print(f"p值 = {p_value:.4f}")
    critical_value = stats.chi2.ppf(1 - alpha, dof)
    print(f"临界值 (α={alpha}) = {critical_value:.4f}")
    
    # 4. 结论
    print("\n【4. 结论】")
    if p_value < alpha:
        print(f"✓ 拒绝原假设 (p = {p_value:.4f} < {alpha})")
        print("  两变量之间存在显著关联")
    else:
        print(f"✗ 不拒绝原假设 (p = {p_value:.4f} ≥ {alpha})")
        print("  没有充分证据表明两变量关联")
    
    # 5. 残差分析
    print("\n【5. 标准化残差】")
    residuals = (contingency_table - expected) / np.sqrt(expected)
    if row_labels and col_labels:
        df_residuals = pd.DataFrame(residuals, 
                                     index=row_labels, 
                                     columns=col_labels)
        print(df_residuals.round(2))
    else:
        print(residuals.round(2))
    print("(|残差| > 2 表示该单元格对χ²贡献大)")
    
    # 可视化
    fig, axes = plt.subplots(1, 3, figsize=(16, 4))
    
    # (1) 观察频数热图
    im1 = axes[0].imshow(contingency_table, cmap='Blues', aspect='auto')
    axes[0].set_title('观察频数')
    if row_labels:
        axes[0].set_yticks(range(len(row_labels)))
        axes[0].set_yticklabels(row_labels)
    if col_labels:
        axes[0].set_xticks(range(len(col_labels)))
        axes[0].set_xticklabels(col_labels)
    
    for i in range(contingency_table.shape[0]):
        for j in range(contingency_table.shape[1]):
            axes[0].text(j, i, f'{contingency_table[i, j]}',
                        ha='center', va='center', color='white', fontsize=12, weight='bold')
    plt.colorbar(im1, ax=axes[0])
    
    # (2) 期望频数热图
    im2 = axes[1].imshow(expected, cmap='Oranges', aspect='auto')
    axes[1].set_title('期望频数（独立假设下）')
    if row_labels:
        axes[1].set_yticks(range(len(row_labels)))
        axes[1].set_yticklabels(row_labels)
    if col_labels:
        axes[1].set_xticks(range(len(col_labels)))
        axes[1].set_xticklabels(col_labels)
    
    for i in range(expected.shape[0]):
        for j in range(expected.shape[1]):
            axes[1].text(j, i, f'{expected[i, j]:.1f}',
                        ha='center', va='center', color='white', fontsize=12, weight='bold')
    plt.colorbar(im2, ax=axes[1])
    
    # (3) 标准化残差热图
    im3 = axes[2].imshow(residuals, cmap='RdBu_r', aspect='auto', vmin=-3, vmax=3)
    axes[2].set_title('标准化残差')
    if row_labels:
        axes[2].set_yticks(range(len(row_labels)))
        axes[2].set_yticklabels(row_labels)
    if col_labels:
        axes[2].set_xticks(range(len(col_labels)))
        axes[2].set_xticklabels(col_labels)
    
    for i in range(residuals.shape[0]):
        for j in range(residuals.shape[1]):
            color = 'white' if abs(residuals[i, j]) > 1 else 'black'
            axes[2].text(j, i, f'{residuals[i, j]:.2f}',
                        ha='center', va='center', color=color, fontsize=12, weight='bold')
    plt.colorbar(im3, ax=axes[2])
    
    plt.tight_layout()
    # plt.show()

# # 示例：性别与产品偏好
# contingency_table = np.array([
#     [30, 20, 10],  # 男性: 产品A, B, C
#     [15, 25, 20]   # 女性: 产品A, B, C
# ])
# chi_square_independence_test(
#     contingency_table,
#     row_labels=['男性', '女性'],
#     col_labels=['产品A', '产品B', '产品C']
# )
```

#### 应用4：非参数检验比较

```python
def compare_parametric_nonparametric(data1, data2):
    """
    比较参数检验与非参数检验
    """
    print("=" * 60)
    print("参数检验 vs 非参数检验对比")
    print("=" * 60)
    
    # 1. 参数检验：独立样本t检验
    print("\n【参数检验：独立样本t检验】")
    t_stat, t_p = stats.ttest_ind(data1, data2)
    print(f"t统计量: {t_stat:.4f}")
    print(f"p值: {t_p:.4f}")
    
    # 2. 非参数检验：Mann-Whitney U检验
    print("\n【非参数检验：Mann-Whitney U检验】")
    u_stat, u_p = stats.mannwhitneyu(data1, data2, alternative='two-sided')
    print(f"U统计量: {u_stat:.4f}")
    print(f"p值: {u_p:.4f}")
    
    # 3. 正态性检验
    print("\n【正态性检验（Shapiro-Wilk）】")
    _, p_norm1 = stats.shapiro(data1)
    _, p_norm2 = stats.shapiro(data2)
    print(f"数据1 p值: {p_norm1:.4f} {'(正态)' if p_norm1 > 0.05 else '(非正态)'}")
    print(f"数据2 p值: {p_norm2:.4f} {'(正态)' if p_norm2 > 0.05 else '(非正态)'}")
    
    # 4. 建议
    print("\n【检验选择建议】")
    if p_norm1 > 0.05 and p_norm2 > 0.05:
        print("✓ 数据近似正态，t检验更有功效")
        print(f"  推荐使用t检验结果: p = {t_p:.4f}")
    else:
        print("✓ 数据偏离正态，非参数检验更稳健")
        print(f"  推荐使用Mann-Whitney U检验结果: p = {u_p:.4f}")
    
    # 可视化
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    # Q-Q图
    axes[0].scatter(*stats.probplot(data1, dist="norm")[0], alpha=0.6, label='数据1')
    axes[0].scatter(*stats.probplot(data2, dist="norm")[0], alpha=0.6, label='数据2')
    axes[0].plot([-3, 3], [-3, 3], 'r--', linewidth=2)
    axes[0].set_xlabel('理论分位数')
    axes[0].set_ylabel('样本分位数')
    axes[0].set_title('Q-Q图（正态性检验）')
    axes[0].legend()
    axes[0].grid(alpha=0.3)
    
    # 分布对比
    axes[1].hist(data1, bins=20, alpha=0.6, label='数据1', edgecolor='black', density=True)
    axes[1].hist(data2, bins=20, alpha=0.6, label='数据2', edgecolor='black', density=True)
    axes[1].set_xlabel('值')
    axes[1].set_ylabel('密度')
    axes[1].set_title('分布对比')
    axes[1].legend()
    axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    # plt.show()

# # 示例
# np.random.seed(42)
# data1 = np.random.normal(10, 2, 50)  # 正态数据
# data2 = np.random.exponential(2, 50)  # 非正态数据
# compare_parametric_nonparametric(data1, data2)
```

### 6.8 本章小结

#### 核心概念对比

| 概念 | 定义 | 关键点 |
|------|------|-------|
| **I型错误** | 拒绝真的 $H_0$ | 概率 = $\alpha$（显著性水平） |
| **II型错误** | 接受假的 $H_0$ | 概率 = $\beta$ |
| **功效** | 正确拒绝假的 $H_0$ | $1-\beta$，越大越好 |
| **p值** | 数据与 $H_0$ 的不相容程度 | 越小证据越强 |

#### 常用检验方法速查

| 场景 | 参数检验 | 非参数检验 | 样本量要求 |
|------|---------|-----------|-----------|
| 单样本均值 | t检验 | Wilcoxon符号秩 | n ≥ 30 (大样本) |
| 两独立样本 | 独立t检验 | Mann-Whitney U | n₁, n₂ ≥ 30 |
| 两配对样本 | 配对t检验 | Wilcoxon配对 | n ≥ 30 |
| 多组比较 | 方差分析(ANOVA) | Kruskal-Wallis | 每组 n ≥ 30 |
| 分类变量 | — | 卡方检验 | 期望频数 ≥ 5 |
| 分布拟合 | — | K-S检验 | n ≥ 50 |

#### 检验选择流程

```
数据类型？
├─ 连续数据
│  ├─ 正态性？
│  │  ├─ 是 → 参数检验（t检验、ANOVA）
│  │  └─ 否 → 非参数检验（Mann-Whitney、Kruskal-Wallis）
│  └─ 样本量？
│     ├─ 大样本(n≥30) → t检验稳健
│     └─ 小样本 → 检查正态性
└─ 分类数据 → 卡方检验
```

#### 重要公式

**t检验统计量**（单样本）：
$$
t = \frac{\overline{X} - \mu_0}{S / \sqrt{n}} \sim t(n-1)
$$

**卡方统计量**（独立性）：
$$
\chi^2 = \sum_{i,j} \frac{(O_{ij} - E_{ij})^2}{E_{ij}} \sim \chi^2((r-1)(c-1))
$$

**样本量公式**（两样本t检验）：
$$
n = \frac{2(z_{\alpha/2} + z_\beta)^2 \sigma^2}{\delta^2}
$$

#### 易错点

1. **p值误解**：
   - ❌ p值不是 $H_0$ 为真的概率
   - ✅ p值是在 $H_0$ 为真时观察到当前数据的概率

2. **显著性 ≠ 重要性**：
   - p < 0.05 只说明统计显著
   - 还需看效应量（Cohen's d）判断实际意义

3. **多重检验**：
   - 做20次检验，至少1次"显著"的概率约64%
   - 必须进行校正（Bonferroni、FDR）

4. **单侧 vs 双侧**：
   - 事先确定，不能事后选择
   - 双侧更保守，单侧更有功效

5. **假设检验不能"接受 $H_0$"**：
   - 只能说"不拒绝 $H_0$"
   - 不拒绝 ≠ 接受（可能是样本量不足）

#### 实战建议

1. **检验前**：
   - 明确研究问题和假设
   - 计算所需样本量
   - 设定 $\alpha$ 水平（通常0.05）

2. **检验中**：
   - 检查数据假设（正态性、方差齐性）
   - 计算检验统计量和p值
   - 报告置信区间和效应量

3. **检验后**：
   - 结合专业知识解释结果
   - 区分统计显著性与实际意义
   - 报告完整结果（不只是p值）

---

**本章完**
