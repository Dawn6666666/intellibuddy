# æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ - (å)å¸¸ç”¨ç»Ÿè®¡æ£€éªŒé€ŸæŸ¥

ç³»ç»Ÿæ€§é€ŸæŸ¥æ‰‹å†Œï¼Œæ¶µç›–æ£€éªŒé€‰æ‹©å†³ç­–æ ‘ã€å®Œæ•´Pythonå®ç°ã€å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆã€‚

---

## 10. å¸¸ç”¨ç»Ÿè®¡æ£€éªŒé€ŸæŸ¥

### ğŸ“Œ æœ¬ç« å¯¼èˆª

| éƒ¨åˆ† | å†…å®¹ |
|------|------|
| **10.1 æ£€éªŒé€‰æ‹©å†³ç­–æ ‘** | å¯è§†åŒ–æµç¨‹å›¾ï¼Œå¿«é€Ÿé€‰æ‹©æ­£ç¡®æ£€éªŒ |
| **10.2 å‚æ•°æ£€éªŒé€ŸæŸ¥** | tæ£€éªŒã€Fæ£€éªŒã€ANOVAå®Œæ•´ä»£ç  |
| **10.3 éå‚æ•°æ£€éªŒé€ŸæŸ¥** | ç§©æ£€éªŒã€å¡æ–¹æ£€éªŒã€é€‚ç”¨åœºæ™¯ |
| **10.4 Pythonå®Œæ•´å®ç°** | å¤åˆ¶å³ç”¨çš„ä»£ç æ¨¡æ¿ |
| **10.5 å¸¸è§é™·é˜±ä¸å¯¹ç­–** | æ˜“é”™ç‚¹ã€è¯¯åŒºã€æœ€ä½³å®è·µ |

---

## 10.1 æ£€éªŒé€‰æ‹©å†³ç­–æ ‘

### ä¸»å†³ç­–æ ‘

```
ã€ç¬¬ä¸€æ­¥ï¼šç¡®å®šç ”ç©¶ç›®æ ‡ã€‘
    â†“
ç ”ç©¶ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ
â”œâ”€ æ¯”è¾ƒå‡å€¼/ä¸­ä½æ•°
â”‚  â”‚
â”‚  â”œâ”€ ä¸€ä¸ªæ ·æœ¬ vs å·²çŸ¥å€¼
â”‚  â”‚  â”œâ”€ æ•°æ®æ­£æ€ï¼Ÿ â†’ YES â†’ å•æ ·æœ¬tæ£€éªŒ
â”‚  â”‚  â””â”€ æ•°æ®æ­£æ€ï¼Ÿ â†’ NO  â†’ Wilcoxonç¬¦å·ç§©æ£€éªŒ
â”‚  â”‚
â”‚  â”œâ”€ ä¸¤ä¸ªç‹¬ç«‹æ ·æœ¬
â”‚  â”‚  â”œâ”€ æ•°æ®æ­£æ€ + æ–¹å·®é½æ€§ï¼Ÿ â†’ YES â†’ ä¸¤æ ·æœ¬tæ£€éªŒ
â”‚  â”‚  â”œâ”€ æ•°æ®æ­£æ€ + æ–¹å·®ä¸é½ï¼Ÿ â†’ YES â†’ Welch tæ£€éªŒ
â”‚  â”‚  â””â”€ æ•°æ®ä¸æ­£æ€ï¼Ÿ        â†’ NO  â†’ Mann-Whitney Uæ£€éªŒ
â”‚  â”‚
â”‚  â”œâ”€ ä¸¤ä¸ªé…å¯¹æ ·æœ¬
â”‚  â”‚  â”œâ”€ å·®å€¼æ­£æ€ï¼Ÿ â†’ YES â†’ é…å¯¹tæ£€éªŒ
â”‚  â”‚  â””â”€ å·®å€¼ä¸æ­£æ€ï¼Ÿâ†’ NO  â†’ Wilcoxonç¬¦å·ç§©æ£€éªŒ
â”‚  â”‚
â”‚  â””â”€ å¤šç»„ï¼ˆâ‰¥3ï¼‰æ ·æœ¬
â”‚     â”œâ”€ æ•°æ®æ­£æ€ + æ–¹å·®é½æ€§ï¼Ÿ â†’ YES â†’ å•å› ç´ ANOVA
â”‚     â””â”€ æ•°æ®ä¸æ­£æ€ï¼Ÿ        â†’ NO  â†’ Kruskal-Wallisæ£€éªŒ
â”‚
â”œâ”€ æ¯”è¾ƒæ–¹å·®
â”‚  â”œâ”€ ä¸¤ç»„ â†’ Fæ£€éªŒï¼ˆæ­£æ€ï¼‰æˆ–Leveneæ£€éªŒï¼ˆéæ­£æ€ï¼‰
â”‚  â””â”€ å¤šç»„ â†’ Bartlettæ£€éªŒï¼ˆæ­£æ€ï¼‰æˆ–Leveneæ£€éªŒï¼ˆéæ­£æ€ï¼‰
â”‚
â”œâ”€ åˆ†ç±»æ•°æ®ç›¸å…³æ€§
â”‚  â”œâ”€ æ‹Ÿåˆä¼˜åº¦     â†’ Ï‡Â²æ‹Ÿåˆä¼˜åº¦æ£€éªŒ
â”‚  â””â”€ ç‹¬ç«‹æ€§/å…³è”æ€§ â†’ Ï‡Â²ç‹¬ç«‹æ€§æ£€éªŒ æˆ– Fisherç²¾ç¡®æ£€éªŒï¼ˆå°æ ·æœ¬ï¼‰
â”‚
â”œâ”€ ç›¸å…³æ€§åˆ†æ
â”‚  â”œâ”€ çº¿æ€§ç›¸å…³ï¼ˆæ­£æ€ï¼‰ â†’ Pearsonç›¸å…³ç³»æ•°
â”‚  â””â”€ å•è°ƒç›¸å…³ï¼ˆéå‚æ•°ï¼‰â†’ Spearman/Kendallç›¸å…³
â”‚
â””â”€ æ¯”ä¾‹/ç‡
   â”œâ”€ ä¸€ä¸ªæ ·æœ¬ â†’ äºŒé¡¹æ£€éªŒ
   â”œâ”€ ä¸¤ä¸ªæ ·æœ¬ â†’ æ¯”ä¾‹zæ£€éªŒ
   â””â”€ å¤šä¸ªæ ·æœ¬ â†’ Ï‡Â²æ£€éªŒ
```

### è¯¦ç»†æµç¨‹å›¾ï¼šå‡å€¼æ¯”è¾ƒ

```
ã€å‡å€¼æ¯”è¾ƒå®Œæ•´æµç¨‹ã€‘

é—®é¢˜ï¼šæ¯”è¾ƒç»„åˆ«ä¹‹é—´çš„å‡å€¼æ˜¯å¦æœ‰å·®å¼‚ï¼Ÿ
    â†“
Step 1ï¼šç¡®å®šç»„æ•°
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ç»„       â”‚ 2ç»„       â”‚ â‰¥3ç»„      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“           â†“           â†“
ä¸å·²çŸ¥å€¼æ¯”è¾ƒ  ä¸¤ç»„æ¯”è¾ƒ    å¤šç»„æ¯”è¾ƒ
    â†“           â†“           â†“
Step 2ï¼šæ£€æŸ¥é…å¯¹å…³ç³»
                â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚
    ç‹¬ç«‹æ ·æœ¬          é…å¯¹æ ·æœ¬
       â”‚                 â”‚
Step 3ï¼šæ£€æŸ¥æ­£æ€æ€§ï¼ˆShapiro-Wilkæˆ–Q-Qå›¾ï¼‰
       â”‚                 â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚         â”‚       â”‚         â”‚
 æ­£æ€    ä¸æ­£æ€    å·®å€¼æ­£æ€  å·®å€¼ä¸æ­£æ€
  â”‚         â”‚       â”‚         â”‚
Step 4ï¼šï¼ˆå¦‚æœç‹¬ç«‹ï¼‰æ£€æŸ¥æ–¹å·®é½æ€§ï¼ˆLeveneæ£€éªŒï¼‰
  â”‚
â”Œâ”€â”´â”€â”
â”‚   â”‚
é½  ä¸é½

ã€æœ€ç»ˆæ£€éªŒé€‰æ‹©ã€‘
â”œâ”€ å•æ ·æœ¬ + æ­£æ€          â†’ å•æ ·æœ¬tæ£€éªŒ
â”œâ”€ å•æ ·æœ¬ + ä¸æ­£æ€        â†’ Wilcoxonç¬¦å·ç§©æ£€éªŒ
â”œâ”€ ä¸¤ç‹¬ç«‹ + æ­£æ€ + é½     â†’ ä¸¤æ ·æœ¬tæ£€éªŒ
â”œâ”€ ä¸¤ç‹¬ç«‹ + æ­£æ€ + ä¸é½   â†’ Welch tæ£€éªŒ
â”œâ”€ ä¸¤ç‹¬ç«‹ + ä¸æ­£æ€        â†’ Mann-Whitney Uæ£€éªŒ
â”œâ”€ ä¸¤é…å¯¹ + å·®å€¼æ­£æ€      â†’ é…å¯¹tæ£€éªŒ
â”œâ”€ ä¸¤é…å¯¹ + å·®å€¼ä¸æ­£æ€    â†’ Wilcoxonç¬¦å·ç§©æ£€éªŒ
â”œâ”€ å¤šç»„ + æ­£æ€ + é½       â†’ å•å› ç´ ANOVA + äº‹åæ£€éªŒ
â””â”€ å¤šç»„ + ä¸æ­£æ€          â†’ Kruskal-Wallis + äº‹åæ£€éªŒ
```

---

## 10.2 å‚æ•°æ£€éªŒé€ŸæŸ¥è¡¨

### è¡¨1ï¼štæ£€éªŒå®¶æ—

| æ£€éªŒç±»å‹ | é€‚ç”¨åœºæ™¯ | å‡è®¾ | ç»Ÿè®¡é‡ | è‡ªç”±åº¦ | Pythonå®ç° |
|---------|---------|------|--------|--------|-----------|
| **å•æ ·æœ¬tæ£€éªŒ** | å‡å€¼ = æŸå€¼ï¼Ÿ| $H_0: \mu = \mu_0$ | $t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}}$ | $n-1$ | `stats.ttest_1samp(data, mu0)` |
| **ä¸¤æ ·æœ¬tæ£€éªŒ** | ä¸¤ç»„å‡å€¼ç›¸ç­‰ï¼Ÿ| $H_0: \mu_1 = \mu_2$ | $t = \frac{\bar{x}_1-\bar{x}_2}{s_p\sqrt{1/n_1+1/n_2}}$ | $n_1+n_2-2$ | `stats.ttest_ind(group1, group2)` |
| **Welch tæ£€éªŒ** | æ–¹å·®ä¸é½æ—¶ä¸¤ç»„å‡å€¼ | åŒä¸Š | ä¿®æ­£å…¬å¼ | Welch df | `stats.ttest_ind(..., equal_var=False)` |
| **é…å¯¹tæ£€éªŒ** | é…å¯¹æ•°æ®å·®å€¼=0ï¼Ÿ| $H_0: \mu_d = 0$ | $t = \frac{\bar{d}}{s_d/\sqrt{n}}$ | $n-1$ | `stats.ttest_rel(before, after)` |

**åˆå¹¶æ–¹å·®å…¬å¼**ï¼š
$$
s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}
$$

---

### è¡¨2ï¼šæ–¹å·®åˆ†æï¼ˆANOVAï¼‰

| æ£€éªŒç±»å‹ | ç›®çš„ | ç»Ÿè®¡é‡ | å‰æ | Python |
|---------|------|--------|------|--------|
| **å•å› ç´ ANOVA** | æ¯”è¾ƒâ‰¥3ç»„å‡å€¼ | $F = \frac{MS_{between}}{MS_{within}}$ | æ­£æ€ã€æ–¹å·®é½ã€ç‹¬ç«‹ | `stats.f_oneway(g1, g2, g3)` |
| **åŒå› ç´ ANOVA** | ä¸¤ä¸ªå› ç´ çš„æ•ˆåº” | $F_A, F_B, F_{AB}$ | åŒä¸Š | `statsmodels.ols + anova_lm` |
| **é‡å¤æµ‹é‡ANOVA** | åŒä¸€å¯¹è±¡å¤šæ¬¡æµ‹é‡ | $F$ | çƒå½¢å‡è®¾ | `statsmodels` |

**äº‹åæ£€éªŒ**ï¼ˆå½“ANOVAæ˜¾è‘—æ—¶ï¼‰ï¼š

| æ–¹æ³• | ç‰¹ç‚¹ | Python |
|------|------|--------|
| **Tukey HSD** | æ§åˆ¶æ—ç³»è¯¯å·®ç‡ï¼Œæœ€å¸¸ç”¨ | `pairwise_tukeyhsd` |
| **Bonferroni** | ä¿å®ˆï¼Œé€‚åˆå°‘é‡æ¯”è¾ƒ | `multipletests(..., method='bonferroni')` |
| **Dunnett** | ä¸å¯¹ç…§ç»„æ¯”è¾ƒ | `statsmodels.multicomp` |

---

### è¡¨3ï¼šæ–¹å·®æ£€éªŒ

| æ£€éªŒ | å‡è®¾ | ç»Ÿè®¡é‡ | å‰æ | Python |
|------|------|--------|------|--------|
| **Fæ£€éªŒ** | $H_0: \sigma_1^2 = \sigma_2^2$ | $F = \frac{s_1^2}{s_2^2}$ | æ­£æ€ | `stats.f.cdf` (æ‰‹åŠ¨) |
| **Leveneæ£€éªŒ** | å¤šç»„æ–¹å·®é½æ€§ | $W$ | å¯¹éæ­£æ€ç¨³å¥ | `stats.levene(g1, g2, ...)` |
| **Bartlettæ£€éªŒ** | å¤šç»„æ–¹å·®é½æ€§ | $\chi^2$ | å‡è®¾æ­£æ€ | `stats.bartlett(g1, g2, ...)` |

---

## 10.3 éå‚æ•°æ£€éªŒé€ŸæŸ¥è¡¨

### ä½•æ—¶ä½¿ç”¨éå‚æ•°æ£€éªŒï¼Ÿ

âœ… **é€‚ç”¨æƒ…å†µ**ï¼š
1. æ•°æ®**ä¸æ»¡è¶³æ­£æ€æ€§**ï¼ˆShapiro-Wilk p < 0.05ï¼‰
2. **æ ·æœ¬é‡å¤ªå°**ï¼ˆn < 30ï¼‰æ— æ³•éªŒè¯æ­£æ€æ€§
3. **é¡ºåºæ•°æ®**ï¼ˆordinal dataï¼‰ï¼Œå¦‚æ»¡æ„åº¦ç­‰çº§
4. **æç«¯å¼‚å¸¸å€¼**å½±å“å‡å€¼
5. **è¿åå…¶ä»–å‡è®¾**ï¼ˆå¦‚æ–¹å·®é½æ€§ï¼‰

### è¡¨4ï¼šéå‚æ•°æ£€éªŒå¯¹ç…§

| å‚æ•°æ£€éªŒ | å¯¹åº”éå‚æ•°æ£€éªŒ | ç»Ÿè®¡é‡ | Python |
|---------|--------------|--------|--------|
| å•æ ·æœ¬tæ£€éªŒ | **Wilcoxonç¬¦å·ç§©æ£€éªŒ** | $W$ | `stats.wilcoxon(data - mu0)` |
| ä¸¤æ ·æœ¬tæ£€éªŒ | **Mann-Whitney Uæ£€éªŒ** | $U$ | `stats.mannwhitneyu(g1, g2)` |
| é…å¯¹tæ£€éªŒ | **Wilcoxonç¬¦å·ç§©æ£€éªŒ** | $W$ | `stats.wilcoxon(before, after)` |
| å•å› ç´ ANOVA | **Kruskal-Wallis Hæ£€éªŒ** | $H$ | `stats.kruskal(g1, g2, g3)` |
| Pearsonç›¸å…³ | **Spearman/Kendallç›¸å…³** | $\rho, \tau$ | `stats.spearmanr`, `kendalltau` |

**äº‹åæ£€éªŒ**ï¼ˆKruskal-Wallisæ˜¾è‘—åï¼‰ï¼š
- **Dunnæ£€éªŒ**ï¼ˆå¸¦Bonferroniæ ¡æ­£ï¼‰
- **Mann-Whitney with correction**

---

### è¡¨5ï¼šå¡æ–¹æ£€éªŒå®¶æ—

| æ£€éªŒ | ç›®çš„ | æ•°æ®æ ¼å¼ | ç»Ÿè®¡é‡ | Python |
|------|------|---------|--------|--------|
| **Ï‡Â² æ‹Ÿåˆä¼˜åº¦æ£€éªŒ** | è§‚æµ‹é¢‘æ•° = ç†è®ºé¢‘æ•°ï¼Ÿ | ä¸€ç»´é¢‘æ•°è¡¨ | $\chi^2 = \sum \frac{(O-E)^2}{E}$ | `stats.chisquare(observed, expected)` |
| **Ï‡Â² ç‹¬ç«‹æ€§æ£€éªŒ** | ä¸¤åˆ†ç±»å˜é‡ç‹¬ç«‹ï¼Ÿ | åˆ—è”è¡¨ | åŒä¸Š | `stats.chi2_contingency(table)` |
| **Fisherç²¾ç¡®æ£€éªŒ** | 2Ã—2è¡¨ç‹¬ç«‹æ€§ï¼ˆå°æ ·æœ¬ï¼‰ | 2Ã—2åˆ—è”è¡¨ | è¶…å‡ ä½•åˆ†å¸ƒ | `stats.fisher_exact(table)` |
| **McNemaræ£€éªŒ** | é…å¯¹åˆ†ç±»æ•°æ® | 2Ã—2é…å¯¹è¡¨ | $\chi^2$ | `statsmodels.mcnemar` |

**ä½•æ—¶ç”¨Fisherè€ŒéÏ‡Â²ï¼Ÿ**
- ä»»ä¸€æ ¼å­æœŸæœ›é¢‘æ•° < 5
- æ ·æœ¬é‡ < 20

---

## 10.4 Pythonå®Œæ•´å®ç°æ¨¡æ¿

### æ¨¡æ¿1ï¼šå®Œæ•´çš„tæ£€éªŒæµç¨‹

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

def complete_ttest(group1, group2=None, paired=False, mu0=0, alpha=0.05):
    """
    å®Œæ•´çš„tæ£€éªŒæµç¨‹ï¼ˆå«å‡è®¾æ£€éªŒï¼‰
    
    å‚æ•°:
    - group1: æ•°ç»„ï¼Œç¬¬ä¸€ç»„æ•°æ®ï¼ˆæˆ–å”¯ä¸€ç»„æ•°æ®ï¼‰
    - group2: æ•°ç»„ï¼Œç¬¬äºŒç»„æ•°æ®ï¼ˆå¯é€‰ï¼‰
    - paired: boolï¼Œæ˜¯å¦é…å¯¹
    - mu0: floatï¼Œå•æ ·æœ¬æ£€éªŒçš„å‡è®¾å‡å€¼
    - alpha: floatï¼Œæ˜¾è‘—æ€§æ°´å¹³
    
    è¿”å›:
    - dict: åŒ…å«æ‰€æœ‰æ£€éªŒç»“æœ
    """
    results = {}
    
    # æ­¥éª¤1ï¼šæ•°æ®æè¿°
    print("=" * 70)
    print("ã€æ•°æ®æè¿°ã€‘")
    print("=" * 70)
    
    if group2 is None:
        # å•æ ·æœ¬
        print(f"æ ·æœ¬é‡: n = {len(group1)}")
        print(f"å‡å€¼: {np.mean(group1):.4f}")
        print(f"æ ‡å‡†å·®: {np.std(group1, ddof=1):.4f}")
        results['type'] = 'å•æ ·æœ¬tæ£€éªŒ'
    else:
        print(f"ç»„1: n = {len(group1)}, å‡å€¼ = {np.mean(group1):.4f}, SD = {np.std(group1, ddof=1):.4f}")
        print(f"ç»„2: n = {len(group2)}, å‡å€¼ = {np.mean(group2):.4f}, SD = {np.std(group2, ddof=1):.4f}")
        results['type'] = 'é…å¯¹tæ£€éªŒ' if paired else 'ä¸¤æ ·æœ¬tæ£€éªŒ'
    
    # æ­¥éª¤2ï¼šæ­£æ€æ€§æ£€éªŒ
    print("\n" + "=" * 70)
    print("ã€æ­£æ€æ€§æ£€éªŒ (Shapiro-Wilk)ã€‘")
    print("=" * 70)
    
    if group2 is None or not paired:
        stat1, p1 = stats.shapiro(group1)
        print(f"ç»„1: W = {stat1:.4f}, p = {p1:.6f} {'âœ“ æ­£æ€' if p1 > 0.05 else 'âœ— éæ­£æ€'}")
        results['normality_group1'] = {'stat': stat1, 'p': p1}
        
        if group2 is not None:
            stat2, p2 = stats.shapiro(group2)
            print(f"ç»„2: W = {stat2:.4f}, p = {p2:.6f} {'âœ“ æ­£æ€' if p2 > 0.05 else 'âœ— éæ­£æ€'}")
            results['normality_group2'] = {'stat': stat2, 'p': p2}
            
            # æ–¹å·®é½æ€§æ£€éªŒ
            print("\nã€æ–¹å·®é½æ€§æ£€éªŒ (Levene)ã€‘")
            lev_stat, lev_p = stats.levene(group1, group2)
            print(f"F = {lev_stat:.4f}, p = {lev_p:.6f} {'âœ“ æ–¹å·®é½æ€§' if lev_p > 0.05 else 'âœ— æ–¹å·®ä¸é½'}")
            results['levene'] = {'stat': lev_stat, 'p': lev_p}
            equal_var = lev_p > 0.05
    else:
        # é…å¯¹ï¼šæ£€éªŒå·®å€¼æ­£æ€æ€§
        diff = group1 - group2
        stat_d, p_d = stats.shapiro(diff)
        print(f"å·®å€¼: W = {stat_d:.4f}, p = {p_d:.6f} {'âœ“ æ­£æ€' if p_d > 0.05 else 'âœ— éæ­£æ€'}")
        results['normality_diff'] = {'stat': stat_d, 'p': p_d}
    
    # æ­¥éª¤3ï¼štæ£€éªŒ
    print("\n" + "=" * 70)
    print(f"ã€{results['type']}ã€‘")
    print("=" * 70)
    
    if group2 is None:
        # å•æ ·æœ¬
        t_stat, p_val = stats.ttest_1samp(group1, mu0)
        df = len(group1) - 1
        ci = stats.t.interval(1-alpha, df, loc=np.mean(group1), 
                              scale=stats.sem(group1))
    elif paired:
        # é…å¯¹
        t_stat, p_val = stats.ttest_rel(group1, group2)
        df = len(group1) - 1
        diff = group1 - group2
        ci = stats.t.interval(1-alpha, df, loc=np.mean(diff), 
                              scale=stats.sem(diff))
    else:
        # ä¸¤ç‹¬ç«‹æ ·æœ¬
        t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=equal_var)
        if equal_var:
            df = len(group1) + len(group2) - 2
        else:
            # Welch dfï¼ˆè¿‘ä¼¼ï¼‰
            s1, s2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
            n1, n2 = len(group1), len(group2)
            df = (s1/n1 + s2/n2)**2 / ((s1/n1)**2/(n1-1) + (s2/n2)**2/(n2-1))
        diff_mean = np.mean(group1) - np.mean(group2)
        se_diff = np.sqrt(np.var(group1, ddof=1)/len(group1) + 
                         np.var(group2, ddof=1)/len(group2))
        ci = (diff_mean - stats.t.ppf(1-alpha/2, df) * se_diff,
              diff_mean + stats.t.ppf(1-alpha/2, df) * se_diff)
    
    print(f"tç»Ÿè®¡é‡ = {t_stat:.4f}")
    print(f"è‡ªç”±åº¦ = {df:.2f}")
    print(f"på€¼ = {p_val:.6f}")
    print(f"{int((1-alpha)*100)}% ç½®ä¿¡åŒºé—´: [{ci[0]:.4f}, {ci[1]:.4f}]")
    
    if p_val < alpha:
        print(f"\nâœ… æ‹’ç»H0 (p < {alpha})")
        print(f"   ç»“è®º: å­˜åœ¨æ˜¾è‘—å·®å¼‚")
    else:
        print(f"\nâŒ ä¸èƒ½æ‹’ç»H0 (p â‰¥ {alpha})")
        print(f"   ç»“è®º: æ— æ˜¾è‘—å·®å¼‚")
    
    # æ•ˆåº”é‡ï¼ˆCohen's dï¼‰
    if group2 is not None and not paired:
        pooled_std = np.sqrt(((len(group1)-1)*np.var(group1, ddof=1) + 
                             (len(group2)-1)*np.var(group2, ddof=1)) / 
                            (len(group1) + len(group2) - 2))
        cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std
        print(f"\nCohen's d = {cohens_d:.3f}", end=" ")
        if abs(cohens_d) < 0.2:
            print("(å°æ•ˆåº”)")
        elif abs(cohens_d) < 0.5:
            print("(ä¸­æ•ˆåº”)")
        else:
            print("(å¤§æ•ˆåº”)")
        results['cohens_d'] = cohens_d
    
    results.update({
        't_stat': t_stat,
        'p_value': p_val,
        'df': df,
        'ci': ci,
        'significant': p_val < alpha
    })
    
    # æ­¥éª¤4ï¼šå¯è§†åŒ–
    fig, axes = plt.subplots(1, 2 if group2 is not None else 3, figsize=(14, 4))
    
    if group2 is None:
        # å•æ ·æœ¬
        axes[0].hist(group1, bins=20, edgecolor='black', alpha=0.7)
        axes[0].axvline(mu0, color='r', linestyle='--', linewidth=2, label=f'H0: Î¼={mu0}')
        axes[0].axvline(np.mean(group1), color='g', linestyle='--', linewidth=2, 
                       label=f'æ ·æœ¬å‡å€¼={np.mean(group1):.2f}')
        axes[0].set_xlabel('å€¼')
        axes[0].set_ylabel('é¢‘æ•°')
        axes[0].set_title('æ•°æ®åˆ†å¸ƒ')
        axes[0].legend()
        axes[0].grid(alpha=0.3)
        
        axes[1].boxplot(group1)
        axes[1].axhline(mu0, color='r', linestyle='--', linewidth=2)
        axes[1].set_ylabel('å€¼')
        axes[1].set_title('ç®±çº¿å›¾')
        axes[1].grid(alpha=0.3)
        
        stats.probplot(group1, dist="norm", plot=axes[2])
        axes[2].set_title('Q-Qå›¾')
        axes[2].grid(alpha=0.3)
    else:
        # ä¸¤æ ·æœ¬
        if paired:
            diff = group1 - group2
            axes[0].hist(diff, bins=20, edgecolor='black', alpha=0.7)
            axes[0].axvline(0, color='r', linestyle='--', linewidth=2, label='H0: diff=0')
            axes[0].axvline(np.mean(diff), color='g', linestyle='--', linewidth=2,
                           label=f'å‡å·®={np.mean(diff):.2f}')
            axes[0].set_xlabel('å·®å€¼')
            axes[0].set_ylabel('é¢‘æ•°')
            axes[0].set_title('é…å¯¹å·®å€¼åˆ†å¸ƒ')
            axes[0].legend()
            axes[0].grid(alpha=0.3)
        else:
            axes[0].boxplot([group1, group2], labels=['ç»„1', 'ç»„2'])
            axes[0].set_ylabel('å€¼')
            axes[0].set_title('ç»„é—´ç®±çº¿å›¾')
            axes[0].grid(alpha=0.3)
        
        # Q-Qå›¾
        if paired:
            stats.probplot(diff, dist="norm", plot=axes[1])
            axes[1].set_title('å·®å€¼Q-Qå›¾')
        else:
            stats.probplot(group1, dist="norm", plot=axes[1])
            axes[1].set_title('ç»„1 Q-Qå›¾')
        axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return results

# ç¤ºä¾‹ä½¿ç”¨
# å•æ ·æœ¬
# data1 = np.random.normal(105, 15, 30)
# result = complete_ttest(data1, mu0=100)

# ä¸¤ç‹¬ç«‹æ ·æœ¬
# group_a = np.random.normal(100, 15, 30)
# group_b = np.random.normal(105, 15, 30)
# result = complete_ttest(group_a, group_b)

# é…å¯¹æ ·æœ¬
# before = np.random.normal(100, 15, 30)
# after = before + np.random.normal(5, 10, 30)  # æœ‰å…³è”
# result = complete_ttest(before, after, paired=True)
```

---

### æ¨¡æ¿2ï¼šANOVA + äº‹åæ£€éªŒ

```python
def complete_anova(*groups, group_names=None, alpha=0.05):
    """
    å®Œæ•´çš„å•å› ç´ ANOVAæµç¨‹
    
    å‚æ•°:
    - *groups: å¤šä¸ªæ•°ç»„ï¼Œæ¯ä¸ªä»£è¡¨ä¸€ç»„æ•°æ®
    - group_names: ç»„ååˆ—è¡¨
    - alpha: æ˜¾è‘—æ€§æ°´å¹³
    """
    import pandas as pd
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    
    n_groups = len(groups)
    if group_names is None:
        group_names = [f'ç»„{i+1}' for i in range(n_groups)]
    
    print("=" * 70)
    print("ã€å•å› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰ã€‘")
    print("=" * 70)
    
    # æ­¥éª¤1ï¼šæè¿°ç»Ÿè®¡
    print("\nã€æè¿°ç»Ÿè®¡ã€‘")
    for i, (group, name) in enumerate(zip(groups, group_names)):
        print(f"{name}: n={len(group)}, å‡å€¼={np.mean(group):.2f}, SD={np.std(group, ddof=1):.2f}")
    
    # æ­¥éª¤2ï¼šå‡è®¾æ£€éªŒ
    print("\nã€å‡è®¾æ£€éªŒã€‘")
    
    # æ­£æ€æ€§
    print("æ­£æ€æ€§æ£€éªŒ (Shapiro-Wilk):")
    all_normal = True
    for i, (group, name) in enumerate(zip(groups, group_names)):
        stat, p = stats.shapiro(group)
        is_normal = p > 0.05
        all_normal = all_normal and is_normal
        print(f"  {name}: p={p:.4f} {'âœ“' if is_normal else 'âœ—'}")
    
    # æ–¹å·®é½æ€§
    print("\næ–¹å·®é½æ€§æ£€éªŒ (Levene):")
    lev_stat, lev_p = stats.levene(*groups)
    var_equal = lev_p > 0.05
    print(f"  F={lev_stat:.4f}, p={lev_p:.4f} {'âœ“ æ–¹å·®é½æ€§' if var_equal else 'âœ— æ–¹å·®ä¸é½'}")
    
    # æ­¥éª¤3ï¼šANOVAæˆ–Kruskal-Wallis
    if all_normal and var_equal:
        print("\nâœ“ æ»¡è¶³ANOVAå‡è®¾ï¼Œä½¿ç”¨å‚æ•°æ£€éªŒ")
        f_stat, p_val = stats.f_oneway(*groups)
        print(f"\nå•å› ç´ ANOVA:")
        print(f"  Fç»Ÿè®¡é‡ = {f_stat:.4f}")
        print(f"  på€¼ = {p_val:.6f}")
        
        use_parametric = True
    else:
        print("\nâš  è¿åANOVAå‡è®¾ï¼Œä½¿ç”¨éå‚æ•°æ£€éªŒ")
        h_stat, p_val = stats.kruskal(*groups)
        print(f"\nKruskal-Wallis Hæ£€éªŒ:")
        print(f"  Hç»Ÿè®¡é‡ = {h_stat:.4f}")
        print(f"  på€¼ = {p_val:.6f}")
        
        use_parametric = False
    
    if p_val < alpha:
        print(f"\nâœ… æ‹’ç»H0 (p < {alpha})")
        print(f"   ç»“è®º: è‡³å°‘æœ‰ä¸€ç»„å‡å€¼æ˜¾è‘—ä¸åŒ")
        
        # æ­¥éª¤4ï¼šäº‹åæ£€éªŒ
        if use_parametric:
            print("\nã€Tukey HSD äº‹åæ£€éªŒã€‘")
            
            # ç»„åˆæ•°æ®
            all_data = []
            all_labels = []
            for group, name in zip(groups, group_names):
                all_data.extend(group)
                all_labels.extend([name] * len(group))
            
            tukey = pairwise_tukeyhsd(all_data, all_labels, alpha=alpha)
            print(tukey)
            
            # æå–æ˜¾è‘—æ¯”è¾ƒ
            tukey_df = pd.DataFrame(data=tukey.summary().data[1:], 
                                   columns=tukey.summary().data[0])
            sig_comparisons = tukey_df[tukey_df['reject'] == True]
            
            if len(sig_comparisons) > 0:
                print(f"\næ˜¾è‘—å·®å¼‚çš„é…å¯¹ ({len(sig_comparisons)} å¯¹):")
                for idx, row in sig_comparisons.iterrows():
                    print(f"  {row['group1']} vs {row['group2']}: "
                          f"å‡å·®={row['meandiff']:.2f}, p={row['p-adj']:.4f}")
        else:
            print("\nã€Dunn äº‹åæ£€éªŒ (with Bonferroni correction)ã€‘")
            from scipy.stats import mannwhitneyu
            from itertools import combinations
            
            # æ‰‹åŠ¨å®ç°Dunnæ£€éªŒ
            n_comparisons = n_groups * (n_groups - 1) // 2
            bonferroni_alpha = alpha / n_comparisons
            
            print(f"Bonferroniæ ¡æ­£åÎ± = {bonferroni_alpha:.4f}")
            print()
            
            for i, j in combinations(range(n_groups), 2):
                u_stat, p = mannwhitneyu(groups[i], groups[j])
                sig = "***" if p < bonferroni_alpha else ""
                print(f"{group_names[i]} vs {group_names[j]}: "
                      f"U={u_stat:.0f}, p={p:.4f} {sig}")
    else:
        print(f"\nâŒ ä¸èƒ½æ‹’ç»H0 (p â‰¥ {alpha})")
        print(f"   ç»“è®º: å„ç»„å‡å€¼æ— æ˜¾è‘—å·®å¼‚")
    
    # æ­¥éª¤5ï¼šå¯è§†åŒ–
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # ç®±çº¿å›¾
    axes[0].boxplot(groups, labels=group_names)
    axes[0].set_ylabel('å€¼')
    axes[0].set_title('å„ç»„ç®±çº¿å›¾')
    axes[0].grid(alpha=0.3)
    
    # å‡å€¼å›¾ï¼ˆå¸¦è¯¯å·®çº¿ï¼‰
    means = [np.mean(g) for g in groups]
    sems = [stats.sem(g) for g in groups]
    x_pos = np.arange(len(group_names))
    
    axes[1].bar(x_pos, means, yerr=sems, capsize=5, alpha=0.7, edgecolor='black')
    axes[1].set_xticks(x_pos)
    axes[1].set_xticklabels(group_names)
    axes[1].set_ylabel('å‡å€¼ Â± SE')
    axes[1].set_title(f'å„ç»„å‡å€¼æ¯”è¾ƒ (p={p_val:.4f})')
    axes[1].grid(alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.show()

# ç¤ºä¾‹
# group1 = np.random.normal(100, 15, 30)
# group2 = np.random.normal(105, 15, 30)
# group3 = np.random.normal(110, 15, 30)
# complete_anova(group1, group2, group3, group_names=['å¯¹ç…§ç»„', 'å¤„ç†1', 'å¤„ç†2'])
```

## 10.5 å¸¸è§é™·é˜±ä¸æœ€ä½³å®è·µ

### é™·é˜±1ï¼šp-hackingï¼ˆpå€¼é»‘å®¢ï¼‰

**âŒ é”™è¯¯åšæ³•**ï¼š
```python
# é”™è¯¯ï¼šä¸æ–­å°è¯•ä¸åŒæ£€éªŒç›´åˆ°p < 0.05
methods = [
    stats.ttest_ind,
    stats.mannwhitneyu,
    lambda a, b: stats.ks_2samp(a, b),
]

for method in methods:
    _, p = method(group1, group2)
    if p < 0.05:
        print(f"æ‰¾åˆ°äº†ï¼p={p:.4f}")  # âŒ é€‰æ‹©æ€§æŠ¥å‘Š
        break
```

**âœ… æ­£ç¡®åšæ³•**ï¼š
1. **é¢„å…ˆ**é€‰å®šæ£€éªŒæ–¹æ³•ï¼ˆåŸºäºæ•°æ®ç‰¹å¾ï¼‰
2. åªæŠ¥å‘Šé¢„å…ˆè®¡åˆ’çš„æ£€éªŒ
3. å¦‚æœè¿›è¡Œå¤šé‡æ¯”è¾ƒï¼Œä½¿ç”¨Bonferroniæˆ–FDRæ ¡æ­£

---

### é™·é˜±2ï¼šå¿½ç•¥å¤šé‡æ£€éªŒ

**é—®é¢˜**ï¼šè¿›è¡Œ10æ¬¡tæ£€éªŒï¼ŒÎ±=0.05ï¼Œè‡³å°‘æœ‰ä¸€æ¬¡å‡é˜³æ€§çš„æ¦‚ç‡ï¼š
$$
P(\text{è‡³å°‘1ä¸ªå‡é˜³æ€§}) = 1 - (1-0.05)^{10} = 0.40
$$

**âœ… è§£å†³æ–¹æ¡ˆ**ï¼š

| æ–¹æ³• | å…¬å¼ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| **Bonferroni** | $\alpha_{adj} = \alpha / m$ | ä¿å®ˆï¼Œæ§åˆ¶æ—ç³»è¯¯å·®ç‡ |
| **Holm-Bonferroni** | é€æ­¥æ ¡æ­£ | æ¯”Bonferroniç•¥å®½æ¾ |
| **FDR (Benjamini-Hochberg)** | æ§åˆ¶å‡å‘ç°ç‡ | å¤§é‡æ£€éªŒï¼Œå®¹å¿éƒ¨åˆ†å‡é˜³æ€§ |

```python
from statsmodels.stats.multitest import multipletests

# 10æ¬¡æ£€éªŒçš„på€¼
p_values = [0.03, 0.01, 0.08, 0.12, 0.02, 0.45, 0.33, 0.09, 0.006, 0.15]

# Bonferroniæ ¡æ­£
reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')
print("Bonferroni:", reject)  # å“ªäº›æ‹’ç»H0

# FDRæ ¡æ­£
reject_fdr, pvals_fdr, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')
print("FDR:", reject_fdr)
```

---

### é™·é˜±3ï¼šæ ·æœ¬é‡ä¸è¶³

**é—®é¢˜**ï¼šåŠŸæ•ˆ(Power)å¤ªä½ï¼Œæ— æ³•æ£€æµ‹åˆ°çœŸå®æ•ˆåº”

**åéªŒåŠŸæ•ˆåˆ†æ**ï¼š
```python
from statsmodels.stats.power import ttest_power

# å·²çŸ¥æ ·æœ¬é‡ã€æ•ˆåº”é‡ï¼Œè®¡ç®—åŠŸæ•ˆ
effect_size = 0.5  # Cohen's d
n = 30
power = ttest_power(effect_size, n, alpha=0.05, alternative='two-sided')
print(f"åŠŸæ•ˆ = {power:.3f}")  # å¦‚æœ < 0.8ï¼Œæ ·æœ¬é‡ä¸è¶³

# å…ˆéªŒï¼šè®¡ç®—æ‰€éœ€æ ·æœ¬é‡
from statsmodels.stats.power import tt_ind_solve_power
n_required = tt_ind_solve_power(effect_size=0.5, alpha=0.05, power=0.8)
print(f"æ‰€éœ€æ ·æœ¬é‡: {int(np.ceil(n_required))} æ¯ç»„")
```

---

### é™·é˜±4ï¼šè¿åå‡è®¾ä½†ä»ç”¨å‚æ•°æ£€éªŒ

**æ£€æŸ¥æ¸…å•**ï¼š

| å‡è®¾ | æ£€éªŒæ–¹æ³• | è¿ååæœ | è¡¥æ•‘æªæ–½ |
|------|---------|---------|---------|
| **æ­£æ€æ€§** | Shapiro-Wilk, Q-Qå›¾ | Iç±»é”™è¯¯ç‡è†¨èƒ€ | å˜æ¢/éå‚æ•°æ£€éªŒ |
| **æ–¹å·®é½æ€§** | Leveneæ£€éªŒ | tæ£€éªŒä¸å‡†ç¡® | Welch tæ£€éªŒ |
| **ç‹¬ç«‹æ€§** | Durbin-Watson | æ ‡å‡†è¯¯æœ‰å | GLSã€æ··åˆæ¨¡å‹ |

**è‡ªåŠ¨æ£€æŸ¥å‡½æ•°**ï¼š
```python
def check_assumptions(group1, group2=None):
    """è‡ªåŠ¨æ£€æŸ¥tæ£€éªŒå‡è®¾"""
    print("ã€å‡è®¾æ£€éªŒã€‘")
    
    # æ­£æ€æ€§
    _, p1 = stats.shapiro(group1)
    print(f"ç»„1æ­£æ€æ€§: p={p1:.4f} {'âœ“' if p1>0.05 else 'âœ— è¿å'}")
    
    if group2 is not None:
        _, p2 = stats.shapiro(group2)
        print(f"ç»„2æ­£æ€æ€§: p={p2:.4f} {'âœ“' if p2>0.05 else 'âœ— è¿å'}")
        
        # æ–¹å·®é½æ€§
        _, plev = stats.levene(group1, group2)
        print(f"æ–¹å·®é½æ€§: p={plev:.4f} {'âœ“' if plev>0.05 else 'âœ— è¿å'}")
        
        # å»ºè®®
        if p1 > 0.05 and p2 > 0.05:
            if plev > 0.05:
                print("\nâœ… å»ºè®®ï¼šä¸¤æ ·æœ¬tæ£€éªŒ")
            else:
                print("\nâš ï¸  å»ºè®®ï¼šWelch tæ£€éªŒ (æ–¹å·®ä¸é½)")
        else:
            print("\nâš ï¸  å»ºè®®ï¼šMann-Whitney Uæ£€éªŒ (éæ­£æ€)")

# check_assumptions(group_a, group_b)
```

---

### é™·é˜±5ï¼šæ··æ·†æ˜¾è‘—æ€§ä¸é‡è¦æ€§

**âŒ é”™è¯¯æ€ç»´**ï¼š
- "p < 0.05ï¼Œæ‰€ä»¥ç»“æœå¾ˆé‡è¦"
- "p > 0.05ï¼Œæ‰€ä»¥æ²¡æœ‰æ•ˆåº”"

**âœ… æ­£ç¡®ç†è§£**ï¼š

| ç»Ÿè®¡æ˜¾è‘—æ€§ | å®é™…é‡è¦æ€§ | è§£é‡Š |
|-----------|----------|------|
| æ˜¾è‘— + å¤§æ•ˆåº” | âœ… é‡è¦ | ç†æƒ³æƒ…å†µ |
| æ˜¾è‘— + å°æ•ˆåº” | âš ï¸  çœ‹å…·ä½“ | å¤§æ ·æœ¬ä¸‹å°æ•ˆåº”ä¹Ÿæ˜¾è‘— |
| ä¸æ˜¾è‘— + å¤§æ•ˆåº” | âš ï¸  åŠŸæ•ˆä¸è¶³ | å¯èƒ½éœ€è¦æ›´å¤šæ•°æ® |
| ä¸æ˜¾è‘— + å°æ•ˆåº” | âŒ ä¸é‡è¦ | çœŸçš„æ²¡æ•ˆåº” |

**åŒæ—¶æŠ¥å‘Šæ•ˆåº”é‡**ï¼š
```python
# ä¸ä»…æŠ¥å‘Špå€¼
t_stat, p_val = stats.ttest_ind(group1, group2)

# è¿˜è¦æŠ¥å‘ŠCohen's d
pooled_std = np.sqrt((np.var(group1, ddof=1) + np.var(group2, ddof=1)) / 2)
cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std

print(f"på€¼ = {p_val:.4f}")
print(f"Cohen's d = {cohens_d:.3f}")
print(f"95% CI: [{...}, {...}]")  # ä¹ŸæŠ¥å‘Šç½®ä¿¡åŒºé—´
```

---

### é™·é˜±6ï¼šå•ä¾§vsåŒä¾§é€‰æ‹©ä¸å½“

**è§„åˆ™**ï¼š
- **åŒä¾§æ£€éªŒ**ï¼ˆé»˜è®¤ï¼‰ï¼šåªå…³å¿ƒ"æ˜¯å¦ä¸åŒ"
- **å•ä¾§æ£€éªŒ**ï¼šæœ‰ç†è®ºé¢„æµ‹æ–¹å‘ï¼Œä¸”åªå…³å¿ƒå•å‘

**âŒ é”™è¯¯ç”¨æ³•**ï¼š
```python
# å…ˆåšåŒä¾§ï¼Œp=0.08ä¸æ˜¾è‘—
# ç„¶åæ”¹æˆå•ä¾§ï¼Œp=0.04æ˜¾è‘—  â† æ•°æ®é©±åŠ¨ï¼Œp-hacking
```

**âœ… æ­£ç¡®ç”¨æ³•**ï¼š
```python
# é¢„å…ˆå£°æ˜ï¼š
# "æ ¹æ®ç†è®ºï¼Œæˆ‘ä»¬é¢„æœŸå¤„ç†ç»„å‡å€¼**æ›´é«˜**"
stats.ttest_ind(treatment, control, alternative='greater')  # å•ä¾§
```

---

### é™·é˜±7ï¼šè¿‡åº¦ä¾èµ–è‡ªåŠ¨åŒ–

**âŒ é”™è¯¯**ï¼š
```python
# ç›²ç›®ä½¿ç”¨ï¼Œä¸ç†è§£åŸç†
from sklearn import linear_model
model = linear_model.LinearRegression()
model.fit(X, y)
print("å®Œæˆï¼")  # â† æ²¡æ£€æŸ¥å‡è®¾ã€æ®‹å·®ã€å¤šé‡å…±çº¿æ€§
```

**âœ… æœ€ä½³å®è·µ**ï¼š
1. **ç†è§£æ£€éªŒåŸç†**
2. **æ£€æŸ¥å‰æå‡è®¾**
3. **è¯Šæ–­æ¨¡å‹**ï¼ˆå›å½’ï¼šæ®‹å·®ã€VIFã€å½±å“ç‚¹ï¼‰
4. **è§£é‡Šç»“æœ**ï¼ˆä¸åªæ˜¯på€¼ï¼‰
5. **å¯è§†åŒ–**ï¼ˆå›¾å½¢æ¯”æ•°å­—æ›´ç›´è§‚ï¼‰

---

### æœ€ä½³å®è·µæ€»ç»“

#### 1. æŠ¥å‘Šchecklist

âœ… **å¥½çš„ç»Ÿè®¡æŠ¥å‘Šåº”åŒ…å«**ï¼š

```markdown
## æ–¹æ³•
- æ£€éªŒç±»å‹åŠç†ç”±
- æ˜¾è‘—æ€§æ°´å¹³ Î±
- å‡è®¾æ£€æŸ¥ç»“æœï¼ˆæ­£æ€æ€§ã€æ–¹å·®é½æ€§ç­‰ï¼‰
- è½¯ä»¶/åŒ…ç‰ˆæœ¬

## ç»“æœ
- æè¿°ç»Ÿè®¡ï¼ˆM Â± SDï¼‰
- æ£€éªŒç»Ÿè®¡é‡åŠè‡ªç”±åº¦
- på€¼ï¼ˆç²¾ç¡®å€¼æˆ–< 0.001ï¼‰
- æ•ˆåº”é‡ï¼ˆCohen's d, Î·Â², etc.ï¼‰
- 95% ç½®ä¿¡åŒºé—´
- å¯è§†åŒ–å›¾è¡¨

## ç»“è®º
- ç»Ÿè®¡ç»“è®º
- å®é™…æ„ä¹‰è§£é‡Š
- å±€é™æ€§è¯´æ˜
```

#### 2. ä»£ç è§„èŒƒ

```python
# âœ… å¥½çš„ç»Ÿè®¡åˆ†æä»£ç 
def analyze_difference(group1, group2, alpha=0.05):
    """
    å®Œæ•´çš„ä¸¤ç»„æ¯”è¾ƒåˆ†æ
    
    è¿”å›ï¼šç»“æ„åŒ–ç»“æœå­—å…¸
    """
    results = {
        'descriptive': {
            'group1': {'mean': np.mean(group1), 'sd': np.std(group1, ddof=1)},
            'group2': {'mean': np.mean(group2), 'sd': np.std(group2, ddof=1)}
        },
        'assumptions': {},
        'test': {},
        'conclusion': ''
    }
    
    # æ£€æŸ¥å‡è®¾
    _, p_norm1 = stats.shapiro(group1)
    _, p_norm2 = stats.shapiro(group2)
    results['assumptions']['normality'] = {
        'group1_p': p_norm1,
        'group2_p': p_norm2,
        'passed': p_norm1 > 0.05 and p_norm2 > 0.05
    }
    
    # é€‰æ‹©æ£€éªŒ
    if results['assumptions']['normality']['passed']:
        _, p_var = stats.levene(group1, group2)
        equal_var = p_var > 0.05
        t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=equal_var)
        results['test'] = {
            'method': 'Welch t' if not equal_var else 't-test',
            'statistic': t_stat,
            'p_value': p_val
        }
    else:
        u_stat, p_val = stats.mannwhitneyu(group1, group2)
        results['test'] = {
            'method': 'Mann-Whitney U',
            'statistic': u_stat,
            'p_value': p_val
        }
    
    # ç»“è®º
    if p_val < alpha:
        results['conclusion'] = f"æ˜¾è‘—å·®å¼‚ (p={p_val:.4f})"
    else:
        results['conclusion'] = f"æ— æ˜¾è‘—å·®å¼‚ (p={p_val:.4f})"
    
    return results
```

#### 3. å¯é‡å¤æ€§

```python
# è®¾ç½®éšæœºç§å­
np.random.seed(42)

# è®°å½•ç¯å¢ƒ
import scipy
import numpy
print(f"NumPyç‰ˆæœ¬: {numpy.__version__}")
print(f"SciPyç‰ˆæœ¬: {scipy.__version__}")

# ä¿å­˜ç»“æœ
# results_df.to_csv('analysis_results.csv')
```

---

### å¿«é€Ÿå†³ç­–å¡

**æ‰“å°æ­¤è¡¨ï¼Œè´´åœ¨ç”µè„‘æ—ï¼**

| é—®é¢˜ | æ•°æ®ç±»å‹ | ç»„æ•° | æ­£æ€ï¼Ÿ | æ£€éªŒ |
|------|---------|------|-------|------|
| æ¯”è¾ƒå‡å€¼ | è¿ç»­ | 1 vs å›ºå®šå€¼ | âœ“ | å•æ ·æœ¬t |
|   |   |   | âœ— | Wilcoxonç¬¦å·ç§© |
|   |   | 2ç‹¬ç«‹ | âœ“ + æ–¹å·®é½ | ä¸¤æ ·æœ¬t |
|   |   |   | âœ“ + æ–¹å·®ä¸é½ | Welch t |
|   |   |   | âœ— | Mann-Whitney U |
|   |   | 2é…å¯¹ | âœ“ (å·®å€¼) | é…å¯¹t |
|   |   |   | âœ— (å·®å€¼) | Wilcoxonç¬¦å·ç§© |
|   |   | â‰¥3 | âœ“ + æ–¹å·®é½ | ANOVA + Tukey |
|   |   |   | âœ— | Kruskal-Wallis + Dunn |
| æ¯”è¾ƒæ–¹å·® | è¿ç»­ | 2 | âœ“ | Fæ£€éªŒ |
|   |   | â‰¥2 | âœ“ | Bartlett |
|   |   | â‰¥2 | âœ— | Levene |
| åˆ†ç±»å…³è” | åˆ†ç±» | 2Ã—2å°æ ·æœ¬ | - | Fisherç²¾ç¡® |
|   |   | åˆ—è”è¡¨ | - | Ï‡Â² |
|   |   | é…å¯¹2Ã—2 | - | McNemar |
| ç›¸å…³æ€§ | è¿ç»­ | 2å˜é‡ | âœ“ | Pearson |
|   |   |   | âœ— | Spearman |

---

##  ğŸ“š å­¦ä¹ å»ºè®®

### é‡ç‚¹éš¾ç‚¹

1. **è´å¶æ–¯å®šç†** - ç†è§£å…ˆéªŒä¸åéªŒæ¦‚ç‡
2. **æ¦‚ç‡åˆ†å¸ƒ** - æŒæ¡å¸¸è§åˆ†å¸ƒçš„ç‰¹æ€§å’Œåº”ç”¨
3. **ä¸­å¿ƒæé™å®šç†** - ç†è§£å…¶åœ¨ç»Ÿè®¡æ¨æ–­ä¸­çš„å¨åŠ›
4. **å‡è®¾æ£€éªŒ** - æ­£ç¡®ç†è§£på€¼å’Œæ˜¾è‘—æ€§æ°´å¹³

### å¸¸è§é”™è¯¯

âŒ **é”™è¯¯1**ï¼šæ··æ·†$P(A|B)$å’Œ$P(B|A)$

- $P(\text{æ‚£ç—…}|\text{é˜³æ€§}) \neq P(\text{é˜³æ€§}|\text{æ‚£ç—…})$
- å¿…é¡»ä½¿ç”¨è´å¶æ–¯å…¬å¼è½¬æ¢

âŒ **é”™è¯¯2**ï¼šè¯¯è§£på€¼

- på€¼**ä¸æ˜¯**$H_0$ä¸ºçœŸçš„æ¦‚ç‡
- på€¼æ˜¯åœ¨$H_0$ä¸ºçœŸæ—¶ï¼Œè§‚å¯Ÿåˆ°å½“å‰æˆ–æ›´æç«¯ç»“æœçš„æ¦‚ç‡

âŒ **é”™è¯¯3**ï¼šå¿½ç•¥æ£€éªŒå‰æ

- $t$æ£€éªŒè¦æ±‚æ­£æ€åˆ†å¸ƒ
- æ–¹å·®åˆ†æè¦æ±‚æ–¹å·®é½æ€§
- è¿åæ—¶åº”ä½¿ç”¨éå‚æ•°æ–¹æ³•

âŒ **é”™è¯¯4**ï¼šç›¸å…³ä¸ç­‰äºå› æœ

- é«˜ç›¸å…³ç³»æ•°ä¸ä»£è¡¨å› æœå…³ç³»
- å¯èƒ½å­˜åœ¨æ··æ·†å˜é‡

### ç¼–ç¨‹å®è·µ

**å¿…åšé¡¹ç›®ï¼š**

1. **è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ**
   - ä¼°è®¡$\pi$å€¼
   - æœŸæƒå®šä»·

2. **æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**
   - æ–‡æœ¬åˆ†ç±»
   - åƒåœ¾é‚®ä»¶è¿‡æ»¤

3. **A/Bæµ‹è¯•æ¡†æ¶**
   - è½¬åŒ–ç‡æ¯”è¾ƒ
   - åŠŸæ•ˆåˆ†æ

4. **å›å½’åˆ†æå®Œæ•´æµç¨‹**
   - æ•°æ®æ¢ç´¢
   - æ¨¡å‹è¯Šæ–­
   - é¢„æµ‹è¯„ä¼°

### æ¨èèµ„æº

ğŸ“– **æ•™æï¼š**
- ã€Šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ã€‹ï¼ˆç››éª¤ï¼‰
- ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ï¼ˆæèˆªï¼‰
- ã€Šæ·±å…¥æµ…å‡ºç»Ÿè®¡å­¦ã€‹ï¼ˆHead First Statisticsï¼‰
- ã€ŠThink Statsã€‹ï¼ˆAllen B. Downeyï¼‰

ğŸ’» **å·¥å…·åº“ï¼š**
- **NumPy**ï¼šæ•°å€¼è®¡ç®—
- **SciPy.stats**ï¼šç»Ÿè®¡å‡½æ•°
- **Statsmodels**ï¼šç»Ÿè®¡å»ºæ¨¡
- **Seaborn**ï¼šç»Ÿè®¡å¯è§†åŒ–
- **Pandas**ï¼šæ•°æ®å¤„ç†

ğŸ¥ **è§†é¢‘è¯¾ç¨‹ï¼š**
- MIT 18.05: Introduction to Probability and Statistics
- Khan Academy: Statistics and Probability
- Bç«™ï¼šæµ™å¤§ã€Šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ã€‹

### å­¦ä¹ è·¯çº¿

**ç¬¬ä¸€é˜¶æ®µï¼šæ¦‚ç‡è®ºåŸºç¡€ï¼ˆ3å‘¨ï¼‰**
- æ¦‚ç‡å…¬ç†ä¸æ€§è´¨
- æ¡ä»¶æ¦‚ç‡ä¸ç‹¬ç«‹æ€§
- éšæœºå˜é‡åŠåˆ†å¸ƒ

**ç¬¬äºŒé˜¶æ®µï¼šå¸¸ç”¨åˆ†å¸ƒï¼ˆ2å‘¨ï¼‰**
- ç¦»æ•£åˆ†å¸ƒï¼ˆäºŒé¡¹ã€æ³Šæ¾ç­‰ï¼‰
- è¿ç»­åˆ†å¸ƒï¼ˆæ­£æ€ã€æŒ‡æ•°ç­‰ï¼‰
- å¤šç»´åˆ†å¸ƒ

**ç¬¬ä¸‰é˜¶æ®µï¼šæ•°ç†ç»Ÿè®¡ï¼ˆ4å‘¨ï¼‰**
- æŠ½æ ·åˆ†å¸ƒ
- å‚æ•°ä¼°è®¡
- å‡è®¾æ£€éªŒ
- æ–¹å·®åˆ†æã€å›å½’åˆ†æ

**ç¬¬å››é˜¶æ®µï¼šå®æˆ˜åº”ç”¨ï¼ˆ3å‘¨ï¼‰**
- æ•°æ®åˆ†æé¡¹ç›®
- A/Bæµ‹è¯•
- æ—¶é—´åºåˆ—
- æœºå™¨å­¦ä¹ åŸºç¡€

### è€ƒè¯•æŠ€å·§

**é¢˜å‹åˆ†å¸ƒï¼š**
- è®¡ç®—é¢˜ï¼ˆ50%ï¼‰ï¼šæ¦‚ç‡è®¡ç®—ã€åˆ†å¸ƒã€ä¼°è®¡ã€æ£€éªŒ
- è¯æ˜é¢˜ï¼ˆ20%ï¼‰ï¼šå®šç†è¯æ˜ã€æ€§è´¨æ¨å¯¼
- åº”ç”¨é¢˜ï¼ˆ30%ï¼‰ï¼šå®é™…é—®é¢˜å»ºæ¨¡

**é«˜é¢‘è€ƒç‚¹ï¼š**
1. å…¨æ¦‚ç‡å…¬å¼å’Œè´å¶æ–¯å…¬å¼
2. å¸¸è§åˆ†å¸ƒçš„æœŸæœ›å’Œæ–¹å·®
3. ä¸­å¿ƒæé™å®šç†åº”ç”¨
4. ç‚¹ä¼°è®¡ï¼ˆçŸ©ä¼°è®¡ã€æœ€å¤§ä¼¼ç„¶ï¼‰
5. åŒºé—´ä¼°è®¡
6. å‡è®¾æ£€éªŒï¼ˆ$t$æ£€éªŒã€$\chi^2$æ£€éªŒï¼‰

**åšé¢˜æ­¥éª¤ï¼š**
1. **æ˜ç¡®é—®é¢˜**ï¼šæ±‚ä»€ä¹ˆï¼Ÿå·²çŸ¥ä»€ä¹ˆï¼Ÿ
2. **é€‰æ‹©æ–¹æ³•**ï¼šç”¨å“ªä¸ªå…¬å¼/å®šç†ï¼Ÿ
3. **ä»”ç»†è®¡ç®—**ï¼šæ¦‚ç‡è®ºè®¡ç®—æ˜“é”™
4. **æ£€æŸ¥ç»“æœ**ï¼šæ¦‚ç‡æ˜¯å¦åœ¨[0,1]ï¼Ÿæ˜¯å¦åˆç†ï¼Ÿ

---

> **è®°ä½**ï¼šæ¦‚ç‡ç»Ÿè®¡æ˜¯æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„ç†è®ºåŸºçŸ³ï¼æŒæ¡å®ƒï¼Œä½ å°†æ‹¥æœ‰å¼ºå¤§çš„æ•°æ®åˆ†æèƒ½åŠ›ï¼ğŸ“Š
> 
> **å­¦ä¹ å¿ƒå¾—**ï¼š
> - å¤šåšé¢˜ï¼šæ¦‚ç‡è®¡ç®—ç†Ÿèƒ½ç”Ÿå·§
> - å¤šç¼–ç¨‹ï¼šç”¨ä»£ç éªŒè¯ç†è®º
> - å¤šæ€è€ƒï¼šç†è§£ç»Ÿè®¡æ€æƒ³çš„æœ¬è´¨
> - å¤šåº”ç”¨ï¼šå°†ç»Ÿè®¡æ–¹æ³•åº”ç”¨åˆ°å®é™…é—®é¢˜

---

**æœ¬ç« å®Œ**
