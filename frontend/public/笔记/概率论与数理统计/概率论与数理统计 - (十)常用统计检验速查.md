# 概率论与数理统计 - (十)常用统计检验速查

系统性速查手册，涵盖检验选择决策树、完整Python实现、常见陷阱与解决方案。

---

## 10. 常用统计检验速查

### 📌 本章导航

| 部分 | 内容 |
|------|------|
| **10.1 检验选择决策树** | 可视化流程图，快速选择正确检验 |
| **10.2 参数检验速查** | t检验、F检验、ANOVA完整代码 |
| **10.3 非参数检验速查** | 秩检验、卡方检验、适用场景 |
| **10.4 Python完整实现** | 复制即用的代码模板 |
| **10.5 常见陷阱与对策** | 易错点、误区、最佳实践 |

---

## 10.1 检验选择决策树

### 主决策树

```
【第一步：确定研究目标】
    ↓
研究目标是什么？
├─ 比较均值/中位数
│  │
│  ├─ 一个样本 vs 已知值
│  │  ├─ 数据正态？ → YES → 单样本t检验
│  │  └─ 数据正态？ → NO  → Wilcoxon符号秩检验
│  │
│  ├─ 两个独立样本
│  │  ├─ 数据正态 + 方差齐性？ → YES → 两样本t检验
│  │  ├─ 数据正态 + 方差不齐？ → YES → Welch t检验
│  │  └─ 数据不正态？        → NO  → Mann-Whitney U检验
│  │
│  ├─ 两个配对样本
│  │  ├─ 差值正态？ → YES → 配对t检验
│  │  └─ 差值不正态？→ NO  → Wilcoxon符号秩检验
│  │
│  └─ 多组（≥3）样本
│     ├─ 数据正态 + 方差齐性？ → YES → 单因素ANOVA
│     └─ 数据不正态？        → NO  → Kruskal-Wallis检验
│
├─ 比较方差
│  ├─ 两组 → F检验（正态）或Levene检验（非正态）
│  └─ 多组 → Bartlett检验（正态）或Levene检验（非正态）
│
├─ 分类数据相关性
│  ├─ 拟合优度     → χ²拟合优度检验
│  └─ 独立性/关联性 → χ²独立性检验 或 Fisher精确检验（小样本）
│
├─ 相关性分析
│  ├─ 线性相关（正态） → Pearson相关系数
│  └─ 单调相关（非参数）→ Spearman/Kendall相关
│
└─ 比例/率
   ├─ 一个样本 → 二项检验
   ├─ 两个样本 → 比例z检验
   └─ 多个样本 → χ²检验
```

### 详细流程图：均值比较

```
【均值比较完整流程】

问题：比较组别之间的均值是否有差异？
    ↓
Step 1：确定组数
    ↓
┌───────────┬───────────┬───────────┐
│ 1组       │ 2组       │ ≥3组      │
└───────────┴───────────┴───────────┘
    ↓           ↓           ↓
与已知值比较  两组比较    多组比较
    ↓           ↓           ↓
Step 2：检查配对关系
                ↓
       ┌────────┴────────┐
       │                 │
    独立样本          配对样本
       │                 │
Step 3：检查正态性（Shapiro-Wilk或Q-Q图）
       │                 │
  ┌────┴────┐       ┌────┴────┐
  │         │       │         │
 正态    不正态    差值正态  差值不正态
  │         │       │         │
Step 4：（如果独立）检查方差齐性（Levene检验）
  │
┌─┴─┐
│   │
齐  不齐

【最终检验选择】
├─ 单样本 + 正态          → 单样本t检验
├─ 单样本 + 不正态        → Wilcoxon符号秩检验
├─ 两独立 + 正态 + 齐     → 两样本t检验
├─ 两独立 + 正态 + 不齐   → Welch t检验
├─ 两独立 + 不正态        → Mann-Whitney U检验
├─ 两配对 + 差值正态      → 配对t检验
├─ 两配对 + 差值不正态    → Wilcoxon符号秩检验
├─ 多组 + 正态 + 齐       → 单因素ANOVA + 事后检验
└─ 多组 + 不正态          → Kruskal-Wallis + 事后检验
```

---

## 10.2 参数检验速查表

### 表1：t检验家族

| 检验类型 | 适用场景 | 假设 | 统计量 | 自由度 | Python实现 |
|---------|---------|------|--------|--------|-----------|
| **单样本t检验** | 均值 = 某值？| $H_0: \mu = \mu_0$ | $t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}}$ | $n-1$ | `stats.ttest_1samp(data, mu0)` |
| **两样本t检验** | 两组均值相等？| $H_0: \mu_1 = \mu_2$ | $t = \frac{\bar{x}_1-\bar{x}_2}{s_p\sqrt{1/n_1+1/n_2}}$ | $n_1+n_2-2$ | `stats.ttest_ind(group1, group2)` |
| **Welch t检验** | 方差不齐时两组均值 | 同上 | 修正公式 | Welch df | `stats.ttest_ind(..., equal_var=False)` |
| **配对t检验** | 配对数据差值=0？| $H_0: \mu_d = 0$ | $t = \frac{\bar{d}}{s_d/\sqrt{n}}$ | $n-1$ | `stats.ttest_rel(before, after)` |

**合并方差公式**：
$$
s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}
$$

---

### 表2：方差分析（ANOVA）

| 检验类型 | 目的 | 统计量 | 前提 | Python |
|---------|------|--------|------|--------|
| **单因素ANOVA** | 比较≥3组均值 | $F = \frac{MS_{between}}{MS_{within}}$ | 正态、方差齐、独立 | `stats.f_oneway(g1, g2, g3)` |
| **双因素ANOVA** | 两个因素的效应 | $F_A, F_B, F_{AB}$ | 同上 | `statsmodels.ols + anova_lm` |
| **重复测量ANOVA** | 同一对象多次测量 | $F$ | 球形假设 | `statsmodels` |

**事后检验**（当ANOVA显著时）：

| 方法 | 特点 | Python |
|------|------|--------|
| **Tukey HSD** | 控制族系误差率，最常用 | `pairwise_tukeyhsd` |
| **Bonferroni** | 保守，适合少量比较 | `multipletests(..., method='bonferroni')` |
| **Dunnett** | 与对照组比较 | `statsmodels.multicomp` |

---

### 表3：方差检验

| 检验 | 假设 | 统计量 | 前提 | Python |
|------|------|--------|------|--------|
| **F检验** | $H_0: \sigma_1^2 = \sigma_2^2$ | $F = \frac{s_1^2}{s_2^2}$ | 正态 | `stats.f.cdf` (手动) |
| **Levene检验** | 多组方差齐性 | $W$ | 对非正态稳健 | `stats.levene(g1, g2, ...)` |
| **Bartlett检验** | 多组方差齐性 | $\chi^2$ | 假设正态 | `stats.bartlett(g1, g2, ...)` |

---

## 10.3 非参数检验速查表

### 何时使用非参数检验？

✅ **适用情况**：
1. 数据**不满足正态性**（Shapiro-Wilk p < 0.05）
2. **样本量太小**（n < 30）无法验证正态性
3. **顺序数据**（ordinal data），如满意度等级
4. **极端异常值**影响均值
5. **违反其他假设**（如方差齐性）

### 表4：非参数检验对照

| 参数检验 | 对应非参数检验 | 统计量 | Python |
|---------|--------------|--------|--------|
| 单样本t检验 | **Wilcoxon符号秩检验** | $W$ | `stats.wilcoxon(data - mu0)` |
| 两样本t检验 | **Mann-Whitney U检验** | $U$ | `stats.mannwhitneyu(g1, g2)` |
| 配对t检验 | **Wilcoxon符号秩检验** | $W$ | `stats.wilcoxon(before, after)` |
| 单因素ANOVA | **Kruskal-Wallis H检验** | $H$ | `stats.kruskal(g1, g2, g3)` |
| Pearson相关 | **Spearman/Kendall相关** | $\rho, \tau$ | `stats.spearmanr`, `kendalltau` |

**事后检验**（Kruskal-Wallis显著后）：
- **Dunn检验**（带Bonferroni校正）
- **Mann-Whitney with correction**

---

### 表5：卡方检验家族

| 检验 | 目的 | 数据格式 | 统计量 | Python |
|------|------|---------|--------|--------|
| **χ² 拟合优度检验** | 观测频数 = 理论频数？ | 一维频数表 | $\chi^2 = \sum \frac{(O-E)^2}{E}$ | `stats.chisquare(observed, expected)` |
| **χ² 独立性检验** | 两分类变量独立？ | 列联表 | 同上 | `stats.chi2_contingency(table)` |
| **Fisher精确检验** | 2×2表独立性（小样本） | 2×2列联表 | 超几何分布 | `stats.fisher_exact(table)` |
| **McNemar检验** | 配对分类数据 | 2×2配对表 | $\chi^2$ | `statsmodels.mcnemar` |

**何时用Fisher而非χ²？**
- 任一格子期望频数 < 5
- 样本量 < 20

---

## 10.4 Python完整实现模板

### 模板1：完整的t检验流程

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

def complete_ttest(group1, group2=None, paired=False, mu0=0, alpha=0.05):
    """
    完整的t检验流程（含假设检验）
    
    参数:
    - group1: 数组，第一组数据（或唯一组数据）
    - group2: 数组，第二组数据（可选）
    - paired: bool，是否配对
    - mu0: float，单样本检验的假设均值
    - alpha: float，显著性水平
    
    返回:
    - dict: 包含所有检验结果
    """
    results = {}
    
    # 步骤1：数据描述
    print("=" * 70)
    print("【数据描述】")
    print("=" * 70)
    
    if group2 is None:
        # 单样本
        print(f"样本量: n = {len(group1)}")
        print(f"均值: {np.mean(group1):.4f}")
        print(f"标准差: {np.std(group1, ddof=1):.4f}")
        results['type'] = '单样本t检验'
    else:
        print(f"组1: n = {len(group1)}, 均值 = {np.mean(group1):.4f}, SD = {np.std(group1, ddof=1):.4f}")
        print(f"组2: n = {len(group2)}, 均值 = {np.mean(group2):.4f}, SD = {np.std(group2, ddof=1):.4f}")
        results['type'] = '配对t检验' if paired else '两样本t检验'
    
    # 步骤2：正态性检验
    print("\n" + "=" * 70)
    print("【正态性检验 (Shapiro-Wilk)】")
    print("=" * 70)
    
    if group2 is None or not paired:
        stat1, p1 = stats.shapiro(group1)
        print(f"组1: W = {stat1:.4f}, p = {p1:.6f} {'✓ 正态' if p1 > 0.05 else '✗ 非正态'}")
        results['normality_group1'] = {'stat': stat1, 'p': p1}
        
        if group2 is not None:
            stat2, p2 = stats.shapiro(group2)
            print(f"组2: W = {stat2:.4f}, p = {p2:.6f} {'✓ 正态' if p2 > 0.05 else '✗ 非正态'}")
            results['normality_group2'] = {'stat': stat2, 'p': p2}
            
            # 方差齐性检验
            print("\n【方差齐性检验 (Levene)】")
            lev_stat, lev_p = stats.levene(group1, group2)
            print(f"F = {lev_stat:.4f}, p = {lev_p:.6f} {'✓ 方差齐性' if lev_p > 0.05 else '✗ 方差不齐'}")
            results['levene'] = {'stat': lev_stat, 'p': lev_p}
            equal_var = lev_p > 0.05
    else:
        # 配对：检验差值正态性
        diff = group1 - group2
        stat_d, p_d = stats.shapiro(diff)
        print(f"差值: W = {stat_d:.4f}, p = {p_d:.6f} {'✓ 正态' if p_d > 0.05 else '✗ 非正态'}")
        results['normality_diff'] = {'stat': stat_d, 'p': p_d}
    
    # 步骤3：t检验
    print("\n" + "=" * 70)
    print(f"【{results['type']}】")
    print("=" * 70)
    
    if group2 is None:
        # 单样本
        t_stat, p_val = stats.ttest_1samp(group1, mu0)
        df = len(group1) - 1
        ci = stats.t.interval(1-alpha, df, loc=np.mean(group1), 
                              scale=stats.sem(group1))
    elif paired:
        # 配对
        t_stat, p_val = stats.ttest_rel(group1, group2)
        df = len(group1) - 1
        diff = group1 - group2
        ci = stats.t.interval(1-alpha, df, loc=np.mean(diff), 
                              scale=stats.sem(diff))
    else:
        # 两独立样本
        t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=equal_var)
        if equal_var:
            df = len(group1) + len(group2) - 2
        else:
            # Welch df（近似）
            s1, s2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
            n1, n2 = len(group1), len(group2)
            df = (s1/n1 + s2/n2)**2 / ((s1/n1)**2/(n1-1) + (s2/n2)**2/(n2-1))
        diff_mean = np.mean(group1) - np.mean(group2)
        se_diff = np.sqrt(np.var(group1, ddof=1)/len(group1) + 
                         np.var(group2, ddof=1)/len(group2))
        ci = (diff_mean - stats.t.ppf(1-alpha/2, df) * se_diff,
              diff_mean + stats.t.ppf(1-alpha/2, df) * se_diff)
    
    print(f"t统计量 = {t_stat:.4f}")
    print(f"自由度 = {df:.2f}")
    print(f"p值 = {p_val:.6f}")
    print(f"{int((1-alpha)*100)}% 置信区间: [{ci[0]:.4f}, {ci[1]:.4f}]")
    
    if p_val < alpha:
        print(f"\n✅ 拒绝H0 (p < {alpha})")
        print(f"   结论: 存在显著差异")
    else:
        print(f"\n❌ 不能拒绝H0 (p ≥ {alpha})")
        print(f"   结论: 无显著差异")
    
    # 效应量（Cohen's d）
    if group2 is not None and not paired:
        pooled_std = np.sqrt(((len(group1)-1)*np.var(group1, ddof=1) + 
                             (len(group2)-1)*np.var(group2, ddof=1)) / 
                            (len(group1) + len(group2) - 2))
        cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std
        print(f"\nCohen's d = {cohens_d:.3f}", end=" ")
        if abs(cohens_d) < 0.2:
            print("(小效应)")
        elif abs(cohens_d) < 0.5:
            print("(中效应)")
        else:
            print("(大效应)")
        results['cohens_d'] = cohens_d
    
    results.update({
        't_stat': t_stat,
        'p_value': p_val,
        'df': df,
        'ci': ci,
        'significant': p_val < alpha
    })
    
    # 步骤4：可视化
    fig, axes = plt.subplots(1, 2 if group2 is not None else 3, figsize=(14, 4))
    
    if group2 is None:
        # 单样本
        axes[0].hist(group1, bins=20, edgecolor='black', alpha=0.7)
        axes[0].axvline(mu0, color='r', linestyle='--', linewidth=2, label=f'H0: μ={mu0}')
        axes[0].axvline(np.mean(group1), color='g', linestyle='--', linewidth=2, 
                       label=f'样本均值={np.mean(group1):.2f}')
        axes[0].set_xlabel('值')
        axes[0].set_ylabel('频数')
        axes[0].set_title('数据分布')
        axes[0].legend()
        axes[0].grid(alpha=0.3)
        
        axes[1].boxplot(group1)
        axes[1].axhline(mu0, color='r', linestyle='--', linewidth=2)
        axes[1].set_ylabel('值')
        axes[1].set_title('箱线图')
        axes[1].grid(alpha=0.3)
        
        stats.probplot(group1, dist="norm", plot=axes[2])
        axes[2].set_title('Q-Q图')
        axes[2].grid(alpha=0.3)
    else:
        # 两样本
        if paired:
            diff = group1 - group2
            axes[0].hist(diff, bins=20, edgecolor='black', alpha=0.7)
            axes[0].axvline(0, color='r', linestyle='--', linewidth=2, label='H0: diff=0')
            axes[0].axvline(np.mean(diff), color='g', linestyle='--', linewidth=2,
                           label=f'均差={np.mean(diff):.2f}')
            axes[0].set_xlabel('差值')
            axes[0].set_ylabel('频数')
            axes[0].set_title('配对差值分布')
            axes[0].legend()
            axes[0].grid(alpha=0.3)
        else:
            axes[0].boxplot([group1, group2], labels=['组1', '组2'])
            axes[0].set_ylabel('值')
            axes[0].set_title('组间箱线图')
            axes[0].grid(alpha=0.3)
        
        # Q-Q图
        if paired:
            stats.probplot(diff, dist="norm", plot=axes[1])
            axes[1].set_title('差值Q-Q图')
        else:
            stats.probplot(group1, dist="norm", plot=axes[1])
            axes[1].set_title('组1 Q-Q图')
        axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return results

# 示例使用
# 单样本
# data1 = np.random.normal(105, 15, 30)
# result = complete_ttest(data1, mu0=100)

# 两独立样本
# group_a = np.random.normal(100, 15, 30)
# group_b = np.random.normal(105, 15, 30)
# result = complete_ttest(group_a, group_b)

# 配对样本
# before = np.random.normal(100, 15, 30)
# after = before + np.random.normal(5, 10, 30)  # 有关联
# result = complete_ttest(before, after, paired=True)
```

---

### 模板2：ANOVA + 事后检验

```python
def complete_anova(*groups, group_names=None, alpha=0.05):
    """
    完整的单因素ANOVA流程
    
    参数:
    - *groups: 多个数组，每个代表一组数据
    - group_names: 组名列表
    - alpha: 显著性水平
    """
    import pandas as pd
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    
    n_groups = len(groups)
    if group_names is None:
        group_names = [f'组{i+1}' for i in range(n_groups)]
    
    print("=" * 70)
    print("【单因素方差分析（ANOVA）】")
    print("=" * 70)
    
    # 步骤1：描述统计
    print("\n【描述统计】")
    for i, (group, name) in enumerate(zip(groups, group_names)):
        print(f"{name}: n={len(group)}, 均值={np.mean(group):.2f}, SD={np.std(group, ddof=1):.2f}")
    
    # 步骤2：假设检验
    print("\n【假设检验】")
    
    # 正态性
    print("正态性检验 (Shapiro-Wilk):")
    all_normal = True
    for i, (group, name) in enumerate(zip(groups, group_names)):
        stat, p = stats.shapiro(group)
        is_normal = p > 0.05
        all_normal = all_normal and is_normal
        print(f"  {name}: p={p:.4f} {'✓' if is_normal else '✗'}")
    
    # 方差齐性
    print("\n方差齐性检验 (Levene):")
    lev_stat, lev_p = stats.levene(*groups)
    var_equal = lev_p > 0.05
    print(f"  F={lev_stat:.4f}, p={lev_p:.4f} {'✓ 方差齐性' if var_equal else '✗ 方差不齐'}")
    
    # 步骤3：ANOVA或Kruskal-Wallis
    if all_normal and var_equal:
        print("\n✓ 满足ANOVA假设，使用参数检验")
        f_stat, p_val = stats.f_oneway(*groups)
        print(f"\n单因素ANOVA:")
        print(f"  F统计量 = {f_stat:.4f}")
        print(f"  p值 = {p_val:.6f}")
        
        use_parametric = True
    else:
        print("\n⚠ 违反ANOVA假设，使用非参数检验")
        h_stat, p_val = stats.kruskal(*groups)
        print(f"\nKruskal-Wallis H检验:")
        print(f"  H统计量 = {h_stat:.4f}")
        print(f"  p值 = {p_val:.6f}")
        
        use_parametric = False
    
    if p_val < alpha:
        print(f"\n✅ 拒绝H0 (p < {alpha})")
        print(f"   结论: 至少有一组均值显著不同")
        
        # 步骤4：事后检验
        if use_parametric:
            print("\n【Tukey HSD 事后检验】")
            
            # 组合数据
            all_data = []
            all_labels = []
            for group, name in zip(groups, group_names):
                all_data.extend(group)
                all_labels.extend([name] * len(group))
            
            tukey = pairwise_tukeyhsd(all_data, all_labels, alpha=alpha)
            print(tukey)
            
            # 提取显著比较
            tukey_df = pd.DataFrame(data=tukey.summary().data[1:], 
                                   columns=tukey.summary().data[0])
            sig_comparisons = tukey_df[tukey_df['reject'] == True]
            
            if len(sig_comparisons) > 0:
                print(f"\n显著差异的配对 ({len(sig_comparisons)} 对):")
                for idx, row in sig_comparisons.iterrows():
                    print(f"  {row['group1']} vs {row['group2']}: "
                          f"均差={row['meandiff']:.2f}, p={row['p-adj']:.4f}")
        else:
            print("\n【Dunn 事后检验 (with Bonferroni correction)】")
            from scipy.stats import mannwhitneyu
            from itertools import combinations
            
            # 手动实现Dunn检验
            n_comparisons = n_groups * (n_groups - 1) // 2
            bonferroni_alpha = alpha / n_comparisons
            
            print(f"Bonferroni校正后α = {bonferroni_alpha:.4f}")
            print()
            
            for i, j in combinations(range(n_groups), 2):
                u_stat, p = mannwhitneyu(groups[i], groups[j])
                sig = "***" if p < bonferroni_alpha else ""
                print(f"{group_names[i]} vs {group_names[j]}: "
                      f"U={u_stat:.0f}, p={p:.4f} {sig}")
    else:
        print(f"\n❌ 不能拒绝H0 (p ≥ {alpha})")
        print(f"   结论: 各组均值无显著差异")
    
    # 步骤5：可视化
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # 箱线图
    axes[0].boxplot(groups, labels=group_names)
    axes[0].set_ylabel('值')
    axes[0].set_title('各组箱线图')
    axes[0].grid(alpha=0.3)
    
    # 均值图（带误差线）
    means = [np.mean(g) for g in groups]
    sems = [stats.sem(g) for g in groups]
    x_pos = np.arange(len(group_names))
    
    axes[1].bar(x_pos, means, yerr=sems, capsize=5, alpha=0.7, edgecolor='black')
    axes[1].set_xticks(x_pos)
    axes[1].set_xticklabels(group_names)
    axes[1].set_ylabel('均值 ± SE')
    axes[1].set_title(f'各组均值比较 (p={p_val:.4f})')
    axes[1].grid(alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.show()

# 示例
# group1 = np.random.normal(100, 15, 30)
# group2 = np.random.normal(105, 15, 30)
# group3 = np.random.normal(110, 15, 30)
# complete_anova(group1, group2, group3, group_names=['对照组', '处理1', '处理2'])
```

## 10.5 常见陷阱与最佳实践

### 陷阱1：p-hacking（p值黑客）

**❌ 错误做法**：
```python
# 错误：不断尝试不同检验直到p < 0.05
methods = [
    stats.ttest_ind,
    stats.mannwhitneyu,
    lambda a, b: stats.ks_2samp(a, b),
]

for method in methods:
    _, p = method(group1, group2)
    if p < 0.05:
        print(f"找到了！p={p:.4f}")  # ❌ 选择性报告
        break
```

**✅ 正确做法**：
1. **预先**选定检验方法（基于数据特征）
2. 只报告预先计划的检验
3. 如果进行多重比较，使用Bonferroni或FDR校正

---

### 陷阱2：忽略多重检验

**问题**：进行10次t检验，α=0.05，至少有一次假阳性的概率：
$$
P(\text{至少1个假阳性}) = 1 - (1-0.05)^{10} = 0.40
$$

**✅ 解决方案**：

| 方法 | 公式 | 适用场景 |
|------|------|---------|
| **Bonferroni** | $\alpha_{adj} = \alpha / m$ | 保守，控制族系误差率 |
| **Holm-Bonferroni** | 逐步校正 | 比Bonferroni略宽松 |
| **FDR (Benjamini-Hochberg)** | 控制假发现率 | 大量检验，容忍部分假阳性 |

```python
from statsmodels.stats.multitest import multipletests

# 10次检验的p值
p_values = [0.03, 0.01, 0.08, 0.12, 0.02, 0.45, 0.33, 0.09, 0.006, 0.15]

# Bonferroni校正
reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')
print("Bonferroni:", reject)  # 哪些拒绝H0

# FDR校正
reject_fdr, pvals_fdr, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')
print("FDR:", reject_fdr)
```

---

### 陷阱3：样本量不足

**问题**：功效(Power)太低，无法检测到真实效应

**后验功效分析**：
```python
from statsmodels.stats.power import ttest_power

# 已知样本量、效应量，计算功效
effect_size = 0.5  # Cohen's d
n = 30
power = ttest_power(effect_size, n, alpha=0.05, alternative='two-sided')
print(f"功效 = {power:.3f}")  # 如果 < 0.8，样本量不足

# 先验：计算所需样本量
from statsmodels.stats.power import tt_ind_solve_power
n_required = tt_ind_solve_power(effect_size=0.5, alpha=0.05, power=0.8)
print(f"所需样本量: {int(np.ceil(n_required))} 每组")
```

---

### 陷阱4：违反假设但仍用参数检验

**检查清单**：

| 假设 | 检验方法 | 违反后果 | 补救措施 |
|------|---------|---------|---------|
| **正态性** | Shapiro-Wilk, Q-Q图 | I类错误率膨胀 | 变换/非参数检验 |
| **方差齐性** | Levene检验 | t检验不准确 | Welch t检验 |
| **独立性** | Durbin-Watson | 标准误有偏 | GLS、混合模型 |

**自动检查函数**：
```python
def check_assumptions(group1, group2=None):
    """自动检查t检验假设"""
    print("【假设检验】")
    
    # 正态性
    _, p1 = stats.shapiro(group1)
    print(f"组1正态性: p={p1:.4f} {'✓' if p1>0.05 else '✗ 违反'}")
    
    if group2 is not None:
        _, p2 = stats.shapiro(group2)
        print(f"组2正态性: p={p2:.4f} {'✓' if p2>0.05 else '✗ 违反'}")
        
        # 方差齐性
        _, plev = stats.levene(group1, group2)
        print(f"方差齐性: p={plev:.4f} {'✓' if plev>0.05 else '✗ 违反'}")
        
        # 建议
        if p1 > 0.05 and p2 > 0.05:
            if plev > 0.05:
                print("\n✅ 建议：两样本t检验")
            else:
                print("\n⚠️  建议：Welch t检验 (方差不齐)")
        else:
            print("\n⚠️  建议：Mann-Whitney U检验 (非正态)")

# check_assumptions(group_a, group_b)
```

---

### 陷阱5：混淆显著性与重要性

**❌ 错误思维**：
- "p < 0.05，所以结果很重要"
- "p > 0.05，所以没有效应"

**✅ 正确理解**：

| 统计显著性 | 实际重要性 | 解释 |
|-----------|----------|------|
| 显著 + 大效应 | ✅ 重要 | 理想情况 |
| 显著 + 小效应 | ⚠️  看具体 | 大样本下小效应也显著 |
| 不显著 + 大效应 | ⚠️  功效不足 | 可能需要更多数据 |
| 不显著 + 小效应 | ❌ 不重要 | 真的没效应 |

**同时报告效应量**：
```python
# 不仅报告p值
t_stat, p_val = stats.ttest_ind(group1, group2)

# 还要报告Cohen's d
pooled_std = np.sqrt((np.var(group1, ddof=1) + np.var(group2, ddof=1)) / 2)
cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std

print(f"p值 = {p_val:.4f}")
print(f"Cohen's d = {cohens_d:.3f}")
print(f"95% CI: [{...}, {...}]")  # 也报告置信区间
```

---

### 陷阱6：单侧vs双侧选择不当

**规则**：
- **双侧检验**（默认）：只关心"是否不同"
- **单侧检验**：有理论预测方向，且只关心单向

**❌ 错误用法**：
```python
# 先做双侧，p=0.08不显著
# 然后改成单侧，p=0.04显著  ← 数据驱动，p-hacking
```

**✅ 正确用法**：
```python
# 预先声明：
# "根据理论，我们预期处理组均值**更高**"
stats.ttest_ind(treatment, control, alternative='greater')  # 单侧
```

---

### 陷阱7：过度依赖自动化

**❌ 错误**：
```python
# 盲目使用，不理解原理
from sklearn import linear_model
model = linear_model.LinearRegression()
model.fit(X, y)
print("完成！")  # ← 没检查假设、残差、多重共线性
```

**✅ 最佳实践**：
1. **理解检验原理**
2. **检查前提假设**
3. **诊断模型**（回归：残差、VIF、影响点）
4. **解释结果**（不只是p值）
5. **可视化**（图形比数字更直观）

---

### 最佳实践总结

#### 1. 报告checklist

✅ **好的统计报告应包含**：

```markdown
## 方法
- 检验类型及理由
- 显著性水平 α
- 假设检查结果（正态性、方差齐性等）
- 软件/包版本

## 结果
- 描述统计（M ± SD）
- 检验统计量及自由度
- p值（精确值或< 0.001）
- 效应量（Cohen's d, η², etc.）
- 95% 置信区间
- 可视化图表

## 结论
- 统计结论
- 实际意义解释
- 局限性说明
```

#### 2. 代码规范

```python
# ✅ 好的统计分析代码
def analyze_difference(group1, group2, alpha=0.05):
    """
    完整的两组比较分析
    
    返回：结构化结果字典
    """
    results = {
        'descriptive': {
            'group1': {'mean': np.mean(group1), 'sd': np.std(group1, ddof=1)},
            'group2': {'mean': np.mean(group2), 'sd': np.std(group2, ddof=1)}
        },
        'assumptions': {},
        'test': {},
        'conclusion': ''
    }
    
    # 检查假设
    _, p_norm1 = stats.shapiro(group1)
    _, p_norm2 = stats.shapiro(group2)
    results['assumptions']['normality'] = {
        'group1_p': p_norm1,
        'group2_p': p_norm2,
        'passed': p_norm1 > 0.05 and p_norm2 > 0.05
    }
    
    # 选择检验
    if results['assumptions']['normality']['passed']:
        _, p_var = stats.levene(group1, group2)
        equal_var = p_var > 0.05
        t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=equal_var)
        results['test'] = {
            'method': 'Welch t' if not equal_var else 't-test',
            'statistic': t_stat,
            'p_value': p_val
        }
    else:
        u_stat, p_val = stats.mannwhitneyu(group1, group2)
        results['test'] = {
            'method': 'Mann-Whitney U',
            'statistic': u_stat,
            'p_value': p_val
        }
    
    # 结论
    if p_val < alpha:
        results['conclusion'] = f"显著差异 (p={p_val:.4f})"
    else:
        results['conclusion'] = f"无显著差异 (p={p_val:.4f})"
    
    return results
```

#### 3. 可重复性

```python
# 设置随机种子
np.random.seed(42)

# 记录环境
import scipy
import numpy
print(f"NumPy版本: {numpy.__version__}")
print(f"SciPy版本: {scipy.__version__}")

# 保存结果
# results_df.to_csv('analysis_results.csv')
```

---

### 快速决策卡

**打印此表，贴在电脑旁！**

| 问题 | 数据类型 | 组数 | 正态？ | 检验 |
|------|---------|------|-------|------|
| 比较均值 | 连续 | 1 vs 固定值 | ✓ | 单样本t |
|   |   |   | ✗ | Wilcoxon符号秩 |
|   |   | 2独立 | ✓ + 方差齐 | 两样本t |
|   |   |   | ✓ + 方差不齐 | Welch t |
|   |   |   | ✗ | Mann-Whitney U |
|   |   | 2配对 | ✓ (差值) | 配对t |
|   |   |   | ✗ (差值) | Wilcoxon符号秩 |
|   |   | ≥3 | ✓ + 方差齐 | ANOVA + Tukey |
|   |   |   | ✗ | Kruskal-Wallis + Dunn |
| 比较方差 | 连续 | 2 | ✓ | F检验 |
|   |   | ≥2 | ✓ | Bartlett |
|   |   | ≥2 | ✗ | Levene |
| 分类关联 | 分类 | 2×2小样本 | - | Fisher精确 |
|   |   | 列联表 | - | χ² |
|   |   | 配对2×2 | - | McNemar |
| 相关性 | 连续 | 2变量 | ✓ | Pearson |
|   |   |   | ✗ | Spearman |

---

##  📚 学习建议

### 重点难点

1. **贝叶斯定理** - 理解先验与后验概率
2. **概率分布** - 掌握常见分布的特性和应用
3. **中心极限定理** - 理解其在统计推断中的威力
4. **假设检验** - 正确理解p值和显著性水平

### 常见错误

❌ **错误1**：混淆$P(A|B)$和$P(B|A)$

- $P(\text{患病}|\text{阳性}) \neq P(\text{阳性}|\text{患病})$
- 必须使用贝叶斯公式转换

❌ **错误2**：误解p值

- p值**不是**$H_0$为真的概率
- p值是在$H_0$为真时，观察到当前或更极端结果的概率

❌ **错误3**：忽略检验前提

- $t$检验要求正态分布
- 方差分析要求方差齐性
- 违反时应使用非参数方法

❌ **错误4**：相关不等于因果

- 高相关系数不代表因果关系
- 可能存在混淆变量

### 编程实践

**必做项目：**

1. **蒙特卡洛模拟**
   - 估计$\pi$值
   - 期权定价

2. **朴素贝叶斯分类器**
   - 文本分类
   - 垃圾邮件过滤

3. **A/B测试框架**
   - 转化率比较
   - 功效分析

4. **回归分析完整流程**
   - 数据探索
   - 模型诊断
   - 预测评估

### 推荐资源

📖 **教材：**
- 《概率论与数理统计》（盛骤）
- 《统计学习方法》（李航）
- 《深入浅出统计学》（Head First Statistics）
- 《Think Stats》（Allen B. Downey）

💻 **工具库：**
- **NumPy**：数值计算
- **SciPy.stats**：统计函数
- **Statsmodels**：统计建模
- **Seaborn**：统计可视化
- **Pandas**：数据处理

🎥 **视频课程：**
- MIT 18.05: Introduction to Probability and Statistics
- Khan Academy: Statistics and Probability
- B站：浙大《概率论与数理统计》

### 学习路线

**第一阶段：概率论基础（3周）**
- 概率公理与性质
- 条件概率与独立性
- 随机变量及分布

**第二阶段：常用分布（2周）**
- 离散分布（二项、泊松等）
- 连续分布（正态、指数等）
- 多维分布

**第三阶段：数理统计（4周）**
- 抽样分布
- 参数估计
- 假设检验
- 方差分析、回归分析

**第四阶段：实战应用（3周）**
- 数据分析项目
- A/B测试
- 时间序列
- 机器学习基础

### 考试技巧

**题型分布：**
- 计算题（50%）：概率计算、分布、估计、检验
- 证明题（20%）：定理证明、性质推导
- 应用题（30%）：实际问题建模

**高频考点：**
1. 全概率公式和贝叶斯公式
2. 常见分布的期望和方差
3. 中心极限定理应用
4. 点估计（矩估计、最大似然）
5. 区间估计
6. 假设检验（$t$检验、$\chi^2$检验）

**做题步骤：**
1. **明确问题**：求什么？已知什么？
2. **选择方法**：用哪个公式/定理？
3. **仔细计算**：概率论计算易错
4. **检查结果**：概率是否在[0,1]？是否合理？

---

> **记住**：概率统计是数据科学和机器学习的理论基石！掌握它，你将拥有强大的数据分析能力！📊
> 
> **学习心得**：
> - 多做题：概率计算熟能生巧
> - 多编程：用代码验证理论
> - 多思考：理解统计思想的本质
> - 多应用：将统计方法应用到实际问题

---

**本章完**
