# æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ - (ä¹)ç»Ÿè®¡åˆ†æå®æˆ˜

å®Œæ•´çš„ç»Ÿè®¡åˆ†æé¡¹ç›®æ¡ˆä¾‹ï¼Œæ¶µç›–æ•°æ®å¯¼å…¥ã€æ¸…æ´—ã€æ¢ç´¢ã€å»ºæ¨¡ã€è¯Šæ–­ã€å¯è§†åŒ–å’ŒæŠ¥å‘Šæ’°å†™å…¨æµç¨‹ã€‚

---

## 9. ç»Ÿè®¡åˆ†æå®æˆ˜

### ğŸ“Œ æœ¬ç« ç»“æ„

| é¡¹ç›® | å†…å®¹ | æŠ€èƒ½ç‚¹ |
|------|------|--------|
| **9.1 å®Œæ•´æ¡ˆä¾‹ï¼šæˆ¿ä»·é¢„æµ‹** | ä»åŸå§‹æ•°æ®åˆ°æœ€ç»ˆæ¨¡å‹ | å›å½’ã€è¯Šæ–­ã€ç‰¹å¾å·¥ç¨‹ |
| **9.2 æ•°æ®æ¸…æ´—å®æˆ˜** | ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€é‡å¤å€¼å¤„ç† | Pandasé«˜çº§æŠ€å·§ |
| **9.3 æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰** | æè¿°ç»Ÿè®¡ã€å¯è§†åŒ–ã€å…³ç³»æ¢ç´¢ | Matplotlib/Seaborn |
| **9.4 A/Bæµ‹è¯•å®Œæ•´æµç¨‹** | å®éªŒè®¾è®¡åˆ°ç»“è®ºæŠ¥å‘Š | å‡è®¾æ£€éªŒã€æ ·æœ¬é‡è®¡ç®— |
| **9.5 æ—¶é—´åºåˆ—åˆ†æ** | ARIMAå»ºæ¨¡ä¸é¢„æµ‹ | å¹³ç¨³æ€§æ£€éªŒã€ACF/PACF |
| **9.6 åˆ†ç±»é—®é¢˜ï¼šå®¢æˆ·æµå¤±é¢„æµ‹** | Logisticå›å½’ã€æ¨¡å‹è¯„ä¼° | æ··æ·†çŸ©é˜µã€ROCæ›²çº¿ |
| **9.7 åˆ†ææŠ¥å‘Šæ’°å†™** | ä¸“ä¸šæŠ¥å‘Šæ¨¡æ¿ | å•†ä¸šåˆ†æã€å¯è§†åŒ–è®¾è®¡ |

---

## 9.1 å®Œæ•´æ¡ˆä¾‹ï¼šæˆ¿ä»·é¢„æµ‹åˆ†æ

### é¡¹ç›®èƒŒæ™¯

**ç›®æ ‡**ï¼šå»ºç«‹æˆ¿ä»·é¢„æµ‹æ¨¡å‹ï¼Œåˆ†æå½±å“æˆ¿ä»·çš„å…³é”®å› ç´ 

**æ•°æ®é›†**ï¼šåŒ…å«500å¥—æˆ¿äº§çš„13ä¸ªç‰¹å¾
- é¢ç§¯ã€å§å®¤æ•°ã€æµ´å®¤æ•°ã€æ¥¼å±‚ã€è½¦ä½
- å»ºé€ å¹´ä»½ã€å­¦åŒºè¯„åˆ†ã€è·å¸‚ä¸­å¿ƒè·ç¦»ã€çŠ¯ç½ªç‡ç­‰

### Step 1ï¼šæ•°æ®å¯¼å…¥ä¸åˆæ¢

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œé£æ ¼
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆå®é™…é¡¹ç›®ä¸­ç”¨pd.read_csv()ï¼‰
np.random.seed(42)
n = 500

data = pd.DataFrame({
    'é¢ç§¯': np.random.normal(120, 40, n).clip(50, 300),
    'å§å®¤æ•°': np.random.choice([1, 2, 3, 4, 5], n, p=[0.1, 0.3, 0.35, 0.2, 0.05]),
    'æµ´å®¤æ•°': np.random.choice([1, 2, 3], n, p=[0.3, 0.5, 0.2]),
    'æ¥¼å±‚': np.random.choice(range(1, 31), n),
    'è½¦ä½': np.random.choice([0, 1, 2], n, p=[0.2, 0.5, 0.3]),
    'å»ºé€ å¹´ä»½': np.random.choice(range(1980, 2024), n),
    'å­¦åŒºè¯„åˆ†': np.random.normal(7.5, 1.5, n).clip(1, 10),
    'è·å¸‚ä¸­å¿ƒ(km)': np.random.exponential(10, n).clip(0, 50),
    'çŠ¯ç½ªç‡': np.random.gamma(2, 2, n).clip(0, 20),
    'ç»¿åŒ–ç‡': np.random.beta(5, 2, n) * 100
})

# ç”Ÿæˆæˆ¿ä»·ï¼ˆåŸºäºå¤šä¸ªç‰¹å¾çš„çº¿æ€§ç»„åˆ+å™ªå£°ï¼‰
data['æˆ¿ä»·(ä¸‡)'] = (
    50 +
    data['é¢ç§¯'] * 0.5 +
    data['å§å®¤æ•°'] * 15 +
    data['æµ´å®¤æ•°'] * 10 +
    data['æ¥¼å±‚'] * 0.3 +
    data['è½¦ä½'] * 20 +
    (2024 - data['å»ºé€ å¹´ä»½']) * -0.5 +
    data['å­¦åŒºè¯„åˆ†'] * 8 +
    data['è·å¸‚ä¸­å¿ƒ(km)'] * -1.5 +
    data['çŠ¯ç½ªç‡'] * -2 +
    data['ç»¿åŒ–ç‡'] * 0.5 +
    np.random.normal(0, 30, n)
).clip(100, 1000)

# å¼•å…¥ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼ˆæ¨¡æ‹ŸçœŸå®æ•°æ®ï¼‰
missing_idx = np.random.choice(n, 20, replace=False)
data.loc[missing_idx[:10], 'ç»¿åŒ–ç‡'] = np.nan
data.loc[missing_idx[10:], 'å­¦åŒºè¯„åˆ†'] = np.nan

# å¼‚å¸¸å€¼ï¼ˆå½•å…¥é”™è¯¯ï¼‰
data.loc[np.random.choice(n, 3, replace=False), 'æˆ¿ä»·(ä¸‡)'] *= 3

print("=" * 70)
print("ã€1. æ•°æ®æ¦‚è§ˆã€‘")
print("=" * 70)
print(f"\næ•°æ®é›†å½¢çŠ¶: {data.shape[0]} è¡Œ Ã— {data.shape[1]} åˆ—")
print("\nå‰5è¡Œæ•°æ®:")
print(data.head())

print("\næ•°æ®ç±»å‹:")
print(data.dtypes)

print("\nåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
print(data.describe())

print("\nç¼ºå¤±å€¼ç»Ÿè®¡:")
missing = data.isnull().sum()
missing_pct = 100 * missing / len(data)
missing_df = pd.DataFrame({
    'ç¼ºå¤±æ•°': missing[missing > 0],
    'ç¼ºå¤±ç‡(%)': missing_pct[missing > 0]
})
print(missing_df)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
======================================================================
ã€1. æ•°æ®æ¦‚è§ˆã€‘
======================================================================

æ•°æ®é›†å½¢çŠ¶: 500 è¡Œ Ã— 11 åˆ—

å‰5è¡Œæ•°æ®:
          é¢ç§¯  å§å®¤æ•°  æµ´å®¤æ•°  æ¥¼å±‚  è½¦ä½  å»ºé€ å¹´ä»½   å­¦åŒºè¯„åˆ†  è·å¸‚ä¸­å¿ƒ(km)    çŠ¯ç½ªç‡      ç»¿åŒ–ç‡   æˆ¿ä»·(ä¸‡)
0   149.87     3      2     7   1     2003      8.22       8.93      3.45     75.31    312.56
1    99.46     2      2    15   1     1995      6.84      12.45      5.67     68.92    245.78
...

ç¼ºå¤±å€¼ç»Ÿè®¡:
           ç¼ºå¤±æ•°  ç¼ºå¤±ç‡(%)
å­¦åŒºè¯„åˆ†      10      2.00
ç»¿åŒ–ç‡        10      2.00
```

---

### Step 2ï¼šæ•°æ®æ¸…æ´—

```python
print("\n" + "=" * 70)
print("ã€2. æ•°æ®æ¸…æ´—ã€‘")
print("=" * 70)

# 2.1 å¤„ç†ç¼ºå¤±å€¼
print("\n2.1 ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥:")

# ç»¿åŒ–ç‡ï¼šç”¨ä¸­ä½æ•°å¡«å……ï¼ˆç¨³å¥ï¼‰
median_green = data['ç»¿åŒ–ç‡'].median()
data['ç»¿åŒ–ç‡'].fillna(median_green, inplace=True)
print(f"  - ç»¿åŒ–ç‡ï¼šå¡«å……ä¸­ä½æ•° {median_green:.2f}")

# å­¦åŒºè¯„åˆ†ï¼šç”¨å‡å€¼å¡«å……ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
mean_school = data['å­¦åŒºè¯„åˆ†'].mean()
data['å­¦åŒºè¯„åˆ†'].fillna(mean_school, inplace=True)
print(f"  - å­¦åŒºè¯„åˆ†ï¼šå¡«å……å‡å€¼ {mean_school:.2f}")

# 2.2 å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
print("\n2.2 å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆIQRæ–¹æ³•ï¼‰:")

def detect_outliers_iqr(series, name):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = series[(series < lower_bound) | (series > upper_bound)]
    print(f"  - {name}: å‘ç° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
    print(f"    æ­£å¸¸èŒƒå›´: [{lower_bound:.2f}, {upper_bound:.2f}]")
    return lower_bound, upper_bound

# æ£€æµ‹æˆ¿ä»·å¼‚å¸¸å€¼
lower, upper = detect_outliers_iqr(data['æˆ¿ä»·(ä¸‡)'], 'æˆ¿ä»·')

# å¯è§†åŒ–å¼‚å¸¸å€¼
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ç®±çº¿å›¾
axes[0].boxplot(data['æˆ¿ä»·(ä¸‡)'], vert=True, patch_artist=True)
axes[0].set_ylabel('æˆ¿ä»·(ä¸‡)')
axes[0].set_title('æˆ¿ä»·ç®±çº¿å›¾ï¼ˆå¼‚å¸¸å€¼æ£€æµ‹ï¼‰')
axes[0].axhline(upper, color='r', linestyle='--', label=f'ä¸Šç•Œ={upper:.0f}')
axes[0].axhline(lower, color='r', linestyle='--', label=f'ä¸‹ç•Œ={lower:.0f}')
axes[0].legend()
axes[0].grid(alpha=0.3)

# ç›´æ–¹å›¾
axes[1].hist(data['æˆ¿ä»·(ä¸‡)'], bins=30, edgecolor='black', alpha=0.7)
axes[1].axvline(upper, color='r', linestyle='--', linewidth=2, label='ä¸Šç•Œ')
axes[1].set_xlabel('æˆ¿ä»·(ä¸‡)')
axes[1].set_ylabel('é¢‘æ•°')
axes[1].set_title('æˆ¿ä»·åˆ†å¸ƒç›´æ–¹å›¾')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
# plt.savefig('outlier_detection.png', dpi=300, bbox_inches='tight')
plt.show()

# å¤„ç†å¼‚å¸¸å€¼ï¼šæ›¿æ¢ä¸ºä¸Šç•Œï¼ˆWinsorizingï¼‰
outlier_mask = (data['æˆ¿ä»·(ä¸‡)'] < lower) | (data['æˆ¿ä»·(ä¸‡)'] > upper)
n_outliers = outlier_mask.sum()
data.loc[data['æˆ¿ä»·(ä¸‡)'] > upper, 'æˆ¿ä»·(ä¸‡)'] = upper
data.loc[data['æˆ¿ä»·(ä¸‡)'] < lower, 'æˆ¿ä»·(ä¸‡)'] = lower

print(f"\n  âœ“ å¤„ç†æ–¹æ³•ï¼šWinsorizingï¼ˆæˆªå°¾ï¼‰ï¼Œå…±å¤„ç† {n_outliers} ä¸ªå¼‚å¸¸å€¼")

# 2.3 æ•°æ®ç±»å‹ä¼˜åŒ–
print("\n2.3 æ•°æ®ç±»å‹ä¼˜åŒ–:")
data['å§å®¤æ•°'] = data['å§å®¤æ•°'].astype('int8')
data['æµ´å®¤æ•°'] = data['æµ´å®¤æ•°'].astype('int8')
data['è½¦ä½'] = data['è½¦ä½'].astype('int8')
data['æ¥¼å±‚'] = data['æ¥¼å±‚'].astype('int8')
print(f"  âœ“ ç¦»æ•£å˜é‡è½¬æ¢ä¸ºint8ï¼ŒèŠ‚çœå†…å­˜")

print(f"\nâœ… æ¸…æ´—åæ•°æ®é›†: {data.shape[0]} è¡Œ Ã— {data.shape[1]} åˆ—ï¼Œæ— ç¼ºå¤±å€¼")
```

---

### Step 3ï¼šæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰

```python
print("\n" + "=" * 70)
print("ã€3. æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰ã€‘")
print("=" * 70)

# 3.1 ç›®æ ‡å˜é‡åˆ†å¸ƒ
print("\n3.1 ç›®æ ‡å˜é‡ï¼ˆæˆ¿ä»·ï¼‰åˆ†æ:")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ç›´æ–¹å›¾
axes[0, 0].hist(data['æˆ¿ä»·(ä¸‡)'], bins=40, edgecolor='black', alpha=0.7, color='skyblue')
axes[0, 0].set_xlabel('æˆ¿ä»·(ä¸‡)')
axes[0, 0].set_ylabel('é¢‘æ•°')
axes[0, 0].set_title('æˆ¿ä»·åˆ†å¸ƒç›´æ–¹å›¾')
axes[0, 0].axvline(data['æˆ¿ä»·(ä¸‡)'].mean(), color='red', linestyle='--', 
                   label=f'å‡å€¼={data["æˆ¿ä»·(ä¸‡)"].mean():.1f}')
axes[0, 0].axvline(data['æˆ¿ä»·(ä¸‡)'].median(), color='green', linestyle='--', 
                   label=f'ä¸­ä½æ•°={data["æˆ¿ä»·(ä¸‡)"].median():.1f}')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# Q-Qå›¾ï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰
stats.probplot(data['æˆ¿ä»·(ä¸‡)'], dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('Q-Qå›¾ï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰')
axes[0, 1].grid(alpha=0.3)

# æ ¸å¯†åº¦ä¼°è®¡
data['æˆ¿ä»·(ä¸‡)'].plot(kind='kde', ax=axes[1, 0], linewidth=2)
axes[1, 0].set_xlabel('æˆ¿ä»·(ä¸‡)')
axes[1, 0].set_ylabel('å¯†åº¦')
axes[1, 0].set_title('æˆ¿ä»·æ ¸å¯†åº¦ä¼°è®¡')
axes[1, 0].grid(alpha=0.3)

# æè¿°ç»Ÿè®¡
desc_stats = data['æˆ¿ä»·(ä¸‡)'].describe()
table_data = [[k, f'{v:.2f}'] for k, v in desc_stats.items()]
table_data.append(['ååº¦', f'{data["æˆ¿ä»·(ä¸‡)"].skew():.3f}'])
table_data.append(['å³°åº¦', f'{data["æˆ¿ä»·(ä¸‡)"].kurt():.3f}'])

axes[1, 1].axis('off')
table = axes[1, 1].table(cellText=table_data, colLabels=['ç»Ÿè®¡é‡', 'å€¼'],
                        loc='center', cellLoc='center')
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1, 2)
axes[1, 1].set_title('æè¿°ç»Ÿè®¡')

plt.tight_layout()
plt.show()

# Shapiro-Wilkæ­£æ€æ€§æ£€éªŒ
stat, p_value = stats.shapiro(data['æˆ¿ä»·(ä¸‡)'])
print(f"  Shapiro-Wilkæ£€éªŒ: ç»Ÿè®¡é‡={stat:.4f}, på€¼={p_value:.6f}")
if p_value > 0.05:
    print("  âœ“ æˆ¿ä»·è¿‘ä¼¼æœä»æ­£æ€åˆ†å¸ƒï¼ˆp > 0.05ï¼‰")
else:
    print("  âœ— æˆ¿ä»·åç¦»æ­£æ€åˆ†å¸ƒï¼ˆp < 0.05ï¼‰ï¼Œè€ƒè™‘å¯¹æ•°å˜æ¢")

# 3.2 ç‰¹å¾ç›¸å…³æ€§åˆ†æ
print("\n3.2 ç‰¹å¾ç›¸å…³æ€§åˆ†æ:")

# è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
corr_matrix = data.corr()

# çƒ­åŠ›å›¾
plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # ä¸Šä¸‰è§’é®ç½©
sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',
            center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8})
plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# ä¸æˆ¿ä»·ç›¸å…³æ€§æ’åº
price_corr = corr_matrix['æˆ¿ä»·(ä¸‡)'].drop('æˆ¿ä»·(ä¸‡)').sort_values(ascending=False)
print("\nä¸æˆ¿ä»·ç›¸å…³æ€§æ’åº:")
print(price_corr)

# é«˜ç›¸å…³ç‰¹å¾å¯è§†åŒ–
top_features = price_corr.head(4).index.tolist()

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.ravel()

for i, feat in enumerate(top_features):
    axes[i].scatter(data[feat], data['æˆ¿ä»·(ä¸‡)'], alpha=0.5, edgecolors='k', linewidth=0.3)
    
    # æ‹Ÿåˆå›å½’çº¿
    z = np.polyfit(data[feat], data['æˆ¿ä»·(ä¸‡)'], 1)
    p = np.poly1d(z)
    axes[i].plot(data[feat], p(data[feat]), "r--", linewidth=2)
    
    # æ˜¾ç¤ºç›¸å…³ç³»æ•°
    r = price_corr[feat]
    axes[i].text(0.05, 0.95, f'r = {r:.3f}', transform=axes[i].transAxes,
                fontsize=12, verticalalignment='top', 
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    axes[i].set_xlabel(feat)
    axes[i].set_ylabel('æˆ¿ä»·(ä¸‡)')
    axes[i].set_title(f'{feat} vs æˆ¿ä»·')
    axes[i].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 3.3 åˆ†ç±»å˜é‡åˆ†æ
print("\n3.3 åˆ†ç±»å˜é‡åˆ†æ:")

categorical_vars = ['å§å®¤æ•°', 'æµ´å®¤æ•°', 'è½¦ä½']

fig, axes = plt.subplots(1, 3, figsize=(16, 5))

for i, var in enumerate(categorical_vars):
    # æŒ‰ç±»åˆ«ç»Ÿè®¡æˆ¿ä»·å‡å€¼å’Œæ ‡å‡†å·®
    grouped = data.groupby(var)['æˆ¿ä»·(ä¸‡)'].agg(['mean', 'std', 'count'])
    
    # æ¡å½¢å›¾ï¼ˆå¸¦è¯¯å·®çº¿ï¼‰
    x = grouped.index
    y = grouped['mean']
    yerr = grouped['std']
    
    axes[i].bar(x, y, yerr=yerr, capsize=5, alpha=0.7, edgecolor='black')
    axes[i].set_xlabel(var)
    axes[i].set_ylabel('å¹³å‡æˆ¿ä»·(ä¸‡)')
    axes[i].set_title(f'{var}ä¸æˆ¿ä»·å…³ç³»')
    axes[i].grid(axis='y', alpha=0.3)
    
    # æ˜¾ç¤ºæ ·æœ¬é‡
    for j, (idx, row) in enumerate(grouped.iterrows()):
        axes[i].text(idx, row['mean'] + row['std'] + 5, 
                    f"n={int(row['count'])}", 
                    ha='center', fontsize=9)

plt.tight_layout()
plt.show()
```

---

### Step 4ï¼šæ¨¡å‹æ„å»ºä¸è¯„ä¼°

```python
print("\n" + "=" * 70)
print("ã€4. å¤šå…ƒçº¿æ€§å›å½’å»ºæ¨¡ã€‘")
print("=" * 70)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

# 4.1 åˆ’åˆ†æ•°æ®é›†
X = data.drop('æˆ¿ä»·(ä¸‡)', axis=1)
y = data['æˆ¿ä»·(ä¸‡)']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nè®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")

# 4.2 ä½¿ç”¨statsmodelsè¿›è¡Œè¯¦ç»†åˆ†æ
X_train_sm = sm.add_constant(X_train)
model = sm.OLS(y_train, X_train_sm).fit()

print("\n" + "=" * 70)
print("ã€å›å½’æ¨¡å‹æ‘˜è¦ã€‘")
print("=" * 70)
print(model.summary())

# 4.3 VIFæ£€æµ‹å¤šé‡å…±çº¿æ€§
print("\n" + "=" * 70)
print("ã€å¤šé‡å…±çº¿æ€§æ£€æµ‹ï¼ˆVIFï¼‰ã€‘")
print("=" * 70)

vif_data = pd.DataFrame()
vif_data["ç‰¹å¾"] = X_train.columns
vif_data["VIF"] = [variance_inflation_factor(X_train.values, i) 
                   for i in range(X_train.shape[1])]
vif_data = vif_data.sort_values('VIF', ascending=False)

print(vif_data.to_string(index=False))

if vif_data['VIF'].max() > 10:
    print("\nâš ï¸  å­˜åœ¨ä¸¥é‡å¤šé‡å…±çº¿æ€§ (VIF > 10)ï¼Œè€ƒè™‘åˆ é™¤æˆ–åˆå¹¶å˜é‡")
elif vif_data['VIF'].max() > 5:
    print("\nâš ï¸  å­˜åœ¨ä¸­ç­‰å¤šé‡å…±çº¿æ€§ (5 < VIF < 10)")
else:
    print("\nâœ… æ— ä¸¥é‡å¤šé‡å…±çº¿æ€§ (VIF < 5)")

# 4.4 æ¨¡å‹é¢„æµ‹
X_test_sm = sm.add_constant(X_test)
y_pred = model.predict(X_test_sm)

# 4.5 æ€§èƒ½è¯„ä¼°
print("\n" + "=" * 70)
print("ã€æ¨¡å‹æ€§èƒ½è¯„ä¼°ã€‘")
print("=" * 70)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

print(f"\næµ‹è¯•é›†è¡¨ç°:")
print(f"  RÂ²         = {r2:.4f}  ï¼ˆè§£é‡Šäº†{r2*100:.1f}%çš„æ–¹å·®ï¼‰")
print(f"  RMSE       = {rmse:.2f} ä¸‡")
print(f"  MAE        = {mae:.2f} ä¸‡")
print(f"  MAPE       = {mape:.2f}%")

# å¯è§†åŒ–ï¼šå®é™…vsé¢„æµ‹
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# æ•£ç‚¹å›¾
axes[0].scatter(y_test, y_pred, alpha=0.6, edgecolors='k', linewidth=0.5)
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())
axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, 
             label='ç†æƒ³æ‹Ÿåˆçº¿')
axes[0].set_xlabel('å®é™…æˆ¿ä»·(ä¸‡)')
axes[0].set_ylabel('é¢„æµ‹æˆ¿ä»·(ä¸‡)')
axes[0].set_title(f'å®é™… vs é¢„æµ‹ (RÂ²={r2:.3f})')
axes[0].legend()
axes[0].grid(alpha=0.3)

# æ®‹å·®å›¾
residuals = y_test - y_pred
axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)
axes[1].axhline(0, color='red', linestyle='--', linewidth=2)
axes[1].set_xlabel('é¢„æµ‹æˆ¿ä»·(ä¸‡)')
axes[1].set_ylabel('æ®‹å·®')
axes[1].set_title('æ®‹å·®å›¾')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()
```

---

### Step 5ï¼šæ®‹å·®è¯Šæ–­

```python
print("\n" + "=" * 70)
print("ã€5. æ®‹å·®è¯Šæ–­ã€‘")
print("=" * 70)

residuals_train = model.resid
fitted_values = model.fittedvalues

fig = plt.figure(figsize=(16, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# (1) æ®‹å·® vs æ‹Ÿåˆå€¼
ax1 = fig.add_subplot(gs[0, 0])
ax1.scatter(fitted_values, residuals_train, alpha=0.5, edgecolors='k', linewidth=0.3)
ax1.axhline(0, color='red', linestyle='--', linewidth=2)
ax1.set_xlabel('æ‹Ÿåˆå€¼')
ax1.set_ylabel('æ®‹å·®')
ax1.set_title('æ®‹å·® vs æ‹Ÿåˆå€¼')
ax1.grid(alpha=0.3)

# (2) Q-Qå›¾
ax2 = fig.add_subplot(gs[0, 1])
stats.probplot(residuals_train, dist="norm", plot=ax2)
ax2.set_title('æ­£æ€Q-Qå›¾')
ax2.grid(alpha=0.3)

# (3) Scale-Locationå›¾
ax3 = fig.add_subplot(gs[0, 2])
std_resid = residuals_train / np.std(residuals_train)
ax3.scatter(fitted_values, np.sqrt(np.abs(std_resid)), alpha=0.5, 
           edgecolors='k', linewidth=0.3)
ax3.set_xlabel('æ‹Ÿåˆå€¼')
ax3.set_ylabel('âˆš|æ ‡å‡†åŒ–æ®‹å·®|')
ax3.set_title('Scale-Locationå›¾')
ax3.grid(alpha=0.3)

# (4) æ®‹å·®ç›´æ–¹å›¾
ax4 = fig.add_subplot(gs[1, 0])
ax4.hist(residuals_train, bins=30, edgecolor='black', alpha=0.7, density=True)
xmin, xmax = ax4.get_xlim()
x = np.linspace(xmin, xmax, 100)
ax4.plot(x, stats.norm.pdf(x, 0, np.std(residuals_train)), 'r-', 
        linewidth=2, label='ç†è®ºæ­£æ€åˆ†å¸ƒ')
ax4.set_xlabel('æ®‹å·®')
ax4.set_ylabel('å¯†åº¦')
ax4.set_title('æ®‹å·®åˆ†å¸ƒ')
ax4.legend()
ax4.grid(alpha=0.3)

# (5) Cook's Distance
ax5 = fig.add_subplot(gs[1, 1])
influence = model.get_influence()
cooks_d = influence.cooks_distance[0]
ax5.stem(range(len(cooks_d)), cooks_d, basefmt=" ", markerfmt='o')
threshold = 4 / len(X_train)
ax5.axhline(threshold, color='red', linestyle='--', linewidth=2, 
           label=f'é˜ˆå€¼={threshold:.4f}')
ax5.set_xlabel('è§‚æµ‹åºå·')
ax5.set_ylabel("Cook's Distance")
ax5.set_title("å½±å“ç‚¹è¯Šæ–­")
ax5.legend()
ax5.grid(alpha=0.3)

# (6) æ æ†å€¼ vs æ ‡å‡†åŒ–æ®‹å·®
ax6 = fig.add_subplot(gs[1, 2])
leverage = influence.hat_matrix_diag
ax6.scatter(leverage, std_resid, alpha=0.5, edgecolors='k', linewidth=0.3)
ax6.axhline(0, color='gray', linestyle='-', linewidth=1)
ax6.axhline(2, color='red', linestyle='--', linewidth=1.5, label='Â±2Ïƒ')
ax6.axhline(-2, color='red', linestyle='--', linewidth=1.5)
ax6.axvline(2 * (X_train.shape[1] + 1) / len(X_train), color='orange', 
           linestyle='--', linewidth=1.5, label='é«˜æ æ†')
ax6.set_xlabel('æ æ†å€¼')
ax6.set_ylabel('æ ‡å‡†åŒ–æ®‹å·®')
ax6.set_title('æ æ†å€¼ vs æ ‡å‡†åŒ–æ®‹å·®')
ax6.legend()
ax6.grid(alpha=0.3)

# (7) å¼‚æ–¹å·®æ£€éªŒç»“æœ
ax7 = fig.add_subplot(gs[2, :])
ax7.axis('off')

# Breusch-Paganæ£€éªŒ
from statsmodels.stats.diagnostic import het_breuschpagan
bp_stat, bp_pval, _, _ = het_breuschpagan(residuals_train, X_train_sm)

# Shapiro-Wilkæ£€éªŒ
sw_stat, sw_pval = stats.shapiro(residuals_train)

# Durbin-Watsonæ£€éªŒ
from statsmodels.stats.stattools import durbin_watson
dw_stat = durbin_watson(residuals_train)

diagnostic_text = f"""
ã€è¯Šæ–­æ£€éªŒç»“æœã€‘

1. æ­£æ€æ€§æ£€éªŒ (Shapiro-Wilk):
   - ç»Ÿè®¡é‡ = {sw_stat:.4f}
   - på€¼ = {sw_pval:.6f}
   - ç»“è®º: {'âœ“ æ®‹å·®è¿‘ä¼¼æ­£æ€åˆ†å¸ƒ' if sw_pval > 0.05 else 'âœ— æ®‹å·®åç¦»æ­£æ€åˆ†å¸ƒ'}

2. åŒæ–¹å·®æ€§æ£€éªŒ (Breusch-Pagan):
   - ç»Ÿè®¡é‡ = {bp_stat:.4f}
   - på€¼ = {bp_pval:.6f}
   - ç»“è®º: {'âœ“ æ»¡è¶³åŒæ–¹å·®å‡è®¾' if bp_pval > 0.05 else 'âœ— å­˜åœ¨å¼‚æ–¹å·®'}

3. ç‹¬ç«‹æ€§æ£€éªŒ (Durbin-Watson):
   - ç»Ÿè®¡é‡ = {dw_stat:.4f}
   - ç»“è®º: {'âœ“ æ— æ˜æ˜¾è‡ªç›¸å…³' if 1.5 < dw_stat < 2.5 else 'âš  å¯èƒ½å­˜åœ¨è‡ªç›¸å…³'}
   - æ³¨ï¼šDWâ‰ˆ2è¡¨ç¤ºæ— è‡ªç›¸å…³ï¼Œ<2è¡¨ç¤ºæ­£ç›¸å…³ï¼Œ>2è¡¨ç¤ºè´Ÿç›¸å…³

4. å½±å“ç‚¹:
   - é«˜Cook's D (>{threshold:.4f}): {np.sum(cooks_d > threshold)} ä¸ª
   - é«˜æ æ†ç‚¹: {np.sum(leverage > 2*(X_train.shape[1]+1)/len(X_train))} ä¸ª
   - å¼‚å¸¸å€¼ (|std_resid|>2): {np.sum(np.abs(std_resid) > 2)} ä¸ª
"""

ax7.text(0.05, 0.95, diagnostic_text, transform=ax7.transAxes,
        fontsize=11, verticalalignment='top', fontfamily='monospace',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.suptitle('å›å½’è¯Šæ–­å›¾é›†', fontsize=16, fontweight='bold', y=0.995)
plt.show()

print(diagnostic_text)
```

---

### Step 6ï¼šç‰¹å¾é‡è¦æ€§åˆ†æ

```python
print("\n" + "=" * 70)
print("ã€6. ç‰¹å¾é‡è¦æ€§åˆ†æã€‘")
print("=" * 70)

# æå–ç³»æ•°ï¼ˆæ’é™¤å¸¸æ•°é¡¹ï¼‰
coefficients = model.params.drop('const')
p_values = model.pvalues.drop('const')
conf_int = model.conf_int().drop('const')

# åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
feature_importance = pd.DataFrame({
    'ç‰¹å¾': coefficients.index,
    'ç³»æ•°': coefficients.values,
    'på€¼': p_values.values,
    'æ˜¾è‘—': ['***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else '' 
            for p in p_values.values],
    'CIä¸‹é™': conf_int[0].values,
    'CIä¸Šé™': conf_int[1].values
})

# æŒ‰ç³»æ•°ç»å¯¹å€¼æ’åº
feature_importance['|ç³»æ•°|'] = np.abs(feature_importance['ç³»æ•°'])
feature_importance = feature_importance.sort_values('|ç³»æ•°|', ascending=False)

print("\nç‰¹å¾é‡è¦æ€§æ’åºï¼ˆæŒ‰ç³»æ•°ç»å¯¹å€¼ï¼‰:")
print(feature_importance[['ç‰¹å¾', 'ç³»æ•°', 'på€¼', 'æ˜¾è‘—', 'CIä¸‹é™', 'CIä¸Šé™']].to_string(index=False))

# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# ç³»æ•°å›¾ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
y_pos = np.arange(len(feature_importance))
coeffs = feature_importance['ç³»æ•°'].values
errors = feature_importance['CIä¸Šé™'].values - coeffs

colors = ['green' if p < 0.05 else 'gray' for p in feature_importance['på€¼']]

axes[0].barh(y_pos, coeffs, xerr=errors, color=colors, alpha=0.7, 
            capsize=5, edgecolor='black')
axes[0].set_yticks(y_pos)
axes[0].set_yticklabels(feature_importance['ç‰¹å¾'])
axes[0].axvline(0, color='black', linestyle='-', linewidth=1)
axes[0].set_xlabel('å›å½’ç³»æ•°ï¼ˆÂ±95% CIï¼‰')
axes[0].set_title('ç‰¹å¾ç³»æ•°åŠç½®ä¿¡åŒºé—´\nï¼ˆç»¿è‰²=æ˜¾è‘—ï¼Œç°è‰²=ä¸æ˜¾è‘—ï¼‰')
axes[0].grid(alpha=0.3, axis='x')

# på€¼å›¾ï¼ˆ-log10 scaleï¼‰
neg_log_p = -np.log10(feature_importance['på€¼'] + 1e-10)
axes[1].barh(y_pos, neg_log_p, color=colors, alpha=0.7, edgecolor='black')
axes[1].axvline(-np.log10(0.05), color='red', linestyle='--', linewidth=2, 
               label='Î±=0.05')
axes[1].axvline(-np.log10(0.01), color='orange', linestyle='--', linewidth=2, 
               label='Î±=0.01')
axes[1].set_yticks(y_pos)
axes[1].set_yticklabels(feature_importance['ç‰¹å¾'])
axes[1].set_xlabel('-logâ‚â‚€(på€¼)')
axes[1].set_title('ç‰¹å¾æ˜¾è‘—æ€§ï¼ˆå€¼è¶Šå¤§è¶Šæ˜¾è‘—ï¼‰')
axes[1].legend()
axes[1].grid(alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

# å…³é”®å‘ç°
print("\nã€å…³é”®å‘ç°ã€‘:")
significant_features = feature_importance[feature_importance['på€¼'] < 0.05]
print(f"\nâœ… æ˜¾è‘—ç‰¹å¾ ({len(significant_features)} ä¸ª):")
for idx, row in significant_features.iterrows():
    direction = "æ­£å‘" if row['ç³»æ•°'] > 0 else "è´Ÿå‘"
    print(f"  - {row['ç‰¹å¾']}: {direction}å½±å“ï¼Œç³»æ•°={row['ç³»æ•°']:.3f} {row['æ˜¾è‘—']}")

non_significant = feature_importance[feature_importance['på€¼'] >= 0.05]
if len(non_significant) > 0:
    print(f"\nâš ï¸  ä¸æ˜¾è‘—ç‰¹å¾ ({len(non_significant)} ä¸ª):")
    for idx, row in non_significant.iterrows():
        print(f"  - {row['ç‰¹å¾']}: p={row['på€¼']:.4f}")
```

---

### Step 7ï¼šä¸šåŠ¡è§£é‡Šä¸å»ºè®®

```python
print("\n" + "=" * 70)
print("ã€7. ä¸šåŠ¡æ´å¯Ÿä¸å»ºè®®ã€‘")
print("=" * 70)

report = f"""
## æˆ¿ä»·é¢„æµ‹æ¨¡å‹åˆ†ææŠ¥å‘Š

### ä¸€ã€æ¨¡å‹è¡¨ç°æ€»ç»“

- **æ¨¡å‹ç±»å‹**: å¤šå…ƒçº¿æ€§å›å½’
- **æ ·æœ¬é‡**: {len(data)} å¥—æˆ¿äº§ï¼ˆè®­ç»ƒé›†{len(X_train)}ï¼Œæµ‹è¯•é›†{len(X_test)}ï¼‰
- **RÂ²**: {r2:.3f} ï¼ˆè§£é‡Šäº†{r2*100:.1f}%çš„æˆ¿ä»·å˜å¼‚ï¼‰
- **RMSE**: {rmse:.2f}ä¸‡ ï¼ˆå¹³å‡é¢„æµ‹è¯¯å·®ï¼‰
- **MAPE**: {mape:.2f}% ï¼ˆå¹³å‡ç™¾åˆ†æ¯”è¯¯å·®ï¼‰

### äºŒã€å½±å“æˆ¿ä»·çš„å…³é”®å› ç´ ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰

{chr(10).join([f"{i+1}. **{row['ç‰¹å¾']}**: {'+' if row['ç³»æ•°']>0 else ''}{row['ç³»æ•°']:.2f}ä¸‡/å•ä½ {'ï¼ˆæ˜¾è‘—ï¼‰' if row['på€¼']<0.05 else 'ï¼ˆä¸æ˜¾è‘—ï¼‰'}"
              for i, (idx, row) in enumerate(feature_importance.head(5).iterrows())])}

### ä¸‰ã€ä¸šåŠ¡å»ºè®®

#### å¯¹è´­æˆ¿è€…:
1. **é¢ç§¯**æ˜¯æœ€é‡è¦çš„å®šä»·å› ç´ ï¼Œæ¯å¹³ç±³çº¦å¢åŠ {feature_importance[feature_importance['ç‰¹å¾']=='é¢ç§¯']['ç³»æ•°'].values[0]:.2f}ä¸‡
2. **å­¦åŒºè¯„åˆ†**æ˜¾è‘—å½±å“æˆ¿ä»·ï¼Œä¼˜è´¨å­¦åŒºæº¢ä»·æ˜æ˜¾
3. **è·å¸‚ä¸­å¿ƒè·ç¦»**è´Ÿç›¸å…³ï¼Œå¸‚ä¸­å¿ƒæˆ¿äº§å…·æœ‰ä½ç½®æº¢ä»·

#### å¯¹å¼€å‘å•†:
1. é‡ç‚¹æŠ•èµ„å­¦åŒºæˆ¿é¡¹ç›®
2. å¢åŠ è½¦ä½é…å¥—è®¾æ–½å¯æå‡æˆ¿ä»·
3. æ§åˆ¶çŠ¯ç½ªç‡ï¼Œæå‡ç¤¾åŒºå®‰å…¨æ„Ÿ

#### å¯¹æ”¿ç­–åˆ¶å®šè€…:
1. åŠ å¼ºå­¦åŒºèµ„æºå‡è¡¡åŒ–ï¼Œå‡å°‘å­¦åŒºæˆ¿ç‚’ä½œ
2. å®Œå–„å…¬å…±äº¤é€šï¼Œé™ä½è·ç¦»å¯¹æˆ¿ä»·çš„è´Ÿé¢å½±å“
3. æé«˜ç¤¾åŒºç»¿åŒ–ç‡å’Œå®‰å…¨æ°´å¹³

### å››ã€æ¨¡å‹å±€é™æ€§

1. **çº¿æ€§å‡è®¾**: å®é™…å…³ç³»å¯èƒ½éçº¿æ€§ï¼ˆè€ƒè™‘å¤šé¡¹å¼æˆ–äº¤äº’é¡¹ï¼‰
2. **ç¼ºå¤±å˜é‡**: æœªè€ƒè™‘è£…ä¿®ã€æœå‘ã€é…å¥—è®¾æ–½ç­‰å› ç´ 
3. **æ—¶é—´æ•ˆåº”**: æœªçº³å…¥å¸‚åœºå‘¨æœŸã€æ”¿ç­–å˜åŒ–ç­‰æ—¶é—´å› ç´ 
4. **å¼‚æ–¹å·®æ€§**: {
   'æ£€æµ‹åˆ°å¼‚æ–¹å·®ï¼Œå»ºè®®ä½¿ç”¨ç¨³å¥æ ‡å‡†è¯¯' if bp_pval < 0.05 
   else 'æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚æ–¹å·®'
}

### äº”ã€ä¸‹ä¸€æ­¥å·¥ä½œ

1. æ”¶é›†æ›´å¤šç‰¹å¾æ•°æ®ï¼ˆè£…ä¿®ã€æœå‘ã€æ¥¼ç›˜å“ç‰Œç­‰ï¼‰
2. å°è¯•éçº¿æ€§æ¨¡å‹ï¼ˆéšæœºæ£®æ—ã€XGBoostã€ç¥ç»ç½‘ç»œï¼‰
3. è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æï¼Œé¢„æµ‹æˆ¿ä»·è¶‹åŠ¿
4. ç»†åˆ†å¸‚åœºï¼ˆæŒ‰åŒºåŸŸã€æˆ·å‹å»ºç«‹åˆ†å±‚æ¨¡å‹ï¼‰
"""

print(report)

# ä¿å­˜æŠ¥å‘Š
# with open('æˆ¿ä»·é¢„æµ‹åˆ†ææŠ¥å‘Š.txt', 'w', encoding='utf-8') as f:
#     f.write(report)

print("\nâœ… å®Œæ•´åˆ†ææµç¨‹ç»“æŸï¼")
```

---

## 9.2 A/Bæµ‹è¯•å®Œæ•´æµç¨‹

### åœºæ™¯ï¼šç”µå•†æ¨èç®—æ³•ä¼˜åŒ–

**èƒŒæ™¯**ï¼šæŸç”µå•†å¹³å°å¼€å‘äº†æ–°çš„æ¨èç®—æ³•ï¼ˆBç‰ˆæœ¬ï¼‰ï¼Œå¸Œæœ›ä¸å½“å‰ç®—æ³•ï¼ˆAç‰ˆæœ¬ï¼‰å¯¹æ¯”ï¼Œçœ‹æ˜¯å¦èƒ½æé«˜ç‚¹å‡»ç‡ã€‚

### Step 1ï¼šå®éªŒè®¾è®¡

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 70)
print("ã€A/Bæµ‹è¯•å®Œæ•´æµç¨‹ã€‘")
print("=" * 70)

# å®éªŒå‚æ•°
alpha = 0.05  # æ˜¾è‘—æ€§æ°´å¹³
power = 0.8   # ç»Ÿè®¡åŠŸæ•ˆ
p_A = 0.05    # Aç»„åŸºå‡†è½¬åŒ–ç‡
mde = 0.01    # æœ€å°å¯æ£€æµ‹æ•ˆåº”ï¼ˆMinimum Detectable Effectï¼‰

print(f"\nå®éªŒè®¾è®¡:")
print(f"  - æ˜¾è‘—æ€§æ°´å¹³ Î± = {alpha}")
print(f"  - ç»Ÿè®¡åŠŸæ•ˆ 1-Î² = {power}")
print(f"  - Aç»„åŸºå‡†è½¬åŒ–ç‡ = {p_A:.1%}")
print(f"  - æœ€å°å¯æ£€æµ‹æ•ˆåº” = {mde:.1%}")

# æ ·æœ¬é‡è®¡ç®—ï¼ˆåŒæ ·æœ¬æ¯”ä¾‹æ£€éªŒï¼‰
from statsmodels.stats.power import zt_ind_solve_power

effect_size = (p_A + mde - p_A) / np.sqrt(p_A * (1 - p_A))
n_required = zt_ind_solve_power(
    effect_size=effect_size,
    alpha=alpha,
    power=power,
    ratio=1.0,  # 1:1åˆ†é…
    alternative='two-sided'
)

print(f"\næ‰€éœ€æ ·æœ¬é‡: æ¯ç»„è‡³å°‘ {int(np.ceil(n_required))} äºº")
print(f"æ€»æ ·æœ¬é‡: {int(np.ceil(n_required * 2))} äºº")

### Step 2ï¼šæ•°æ®æ”¶é›†ä¸åˆæ­¥åˆ†æ

# æ¨¡æ‹Ÿå®éªŒæ•°æ®
np.random.seed(42)
n_A, n_B = 10000, 10000

# Aç»„ï¼šåŸºå‡†è½¬åŒ–ç‡5%
clicks_A = np.random.binomial(n_A, p_A)

# Bç»„ï¼šè½¬åŒ–ç‡5.5%ï¼ˆçœŸå®æå‡0.5ä¸ªç™¾åˆ†ç‚¹ï¼‰
p_B_true = 0.055
clicks_B = np.random.binomial(n_B, p_B_true)

p_A_obs = clicks_A / n_A
p_B_obs = clicks_B / n_B

print("\n" + "=" * 70)
print("ã€æ•°æ®æ”¶é›†ç»“æœã€‘")
print("=" * 70)

results = pd.DataFrame({
    'ç»„åˆ«': ['Aç»„ï¼ˆå¯¹ç…§ç»„ï¼‰', 'Bç»„ï¼ˆå®éªŒç»„ï¼‰'],
    'æ ·æœ¬é‡': [n_A, n_B],
    'ç‚¹å‡»æ•°': [clicks_A, clicks_B],
    'ç‚¹å‡»ç‡': [p_A_obs, p_B_obs],
    'ç‚¹å‡»ç‡(%)': [p_A_obs * 100, p_B_obs * 100]
})

print("\n" + results.to_string(index=False))

print(f"\næå‡æƒ…å†µ:")
absolute_lift = p_B_obs - p_A_obs
relative_lift = (p_B_obs - p_A_obs) / p_A_obs * 100
print(f"  ç»å¯¹æå‡: {absolute_lift:.4f} ({absolute_lift*100:.2f}ä¸ªç™¾åˆ†ç‚¹)")
print(f"  ç›¸å¯¹æå‡: {relative_lift:.2f}%")

### Step 3ï¼šå‡è®¾æ£€éªŒ

print("\n" + "=" * 70)
print("ã€å‡è®¾æ£€éªŒã€‘")
print("=" * 70)

# H0: p_A = p_B
# H1: p_A â‰  p_B

# åˆå¹¶æ¯”ä¾‹
p_pool = (clicks_A + clicks_B) / (n_A + n_B)

# Zæ£€éªŒç»Ÿè®¡é‡
se = np.sqrt(p_pool * (1 - p_pool) * (1/n_A + 1/n_B))
z = (p_B_obs - p_A_obs) / se

# på€¼ï¼ˆåŒä¾§ï¼‰
p_value = 2 * (1 - stats.norm.cdf(abs(z)))

print(f"\næ£€éªŒç»“æœ:")
print(f"  åˆå¹¶æ¯”ä¾‹ p_pool = {p_pool:.4f}")
print(f"  Zç»Ÿè®¡é‡ = {z:.4f}")
print(f"  på€¼ = {p_value:.6f}")
print(f"  ä¸´ç•Œå€¼ Z_{alpha/2} = {stats.norm.ppf(1-alpha/2):.4f}")

if p_value < alpha:
    print(f"\nâœ… æ‹’ç»H0 (p < {alpha})")
    print(f"   ç»“è®º: Bç»„è½¬åŒ–ç‡**æ˜¾è‘—é«˜äº**Aç»„")
else:
    print(f"\nâŒ ä¸èƒ½æ‹’ç»H0 (p â‰¥ {alpha})")
    print(f"   ç»“è®º: ä¸¤ç»„è½¬åŒ–ç‡**æ— æ˜¾è‘—å·®å¼‚**")

# ç½®ä¿¡åŒºé—´
ci_lower, ci_upper = stats.norm.interval(
    1 - alpha,
    loc=p_B_obs - p_A_obs,
    scale=np.sqrt(p_A_obs*(1-p_A_obs)/n_A + p_B_obs*(1-p_B_obs)/n_B)
)

print(f"\nå·®å¼‚çš„95%ç½®ä¿¡åŒºé—´: [{ci_lower:.4f}, {ci_upper:.4f}]")
print(f"æˆ–: [{ci_lower*100:.2f}%, {ci_upper*100:.2f}%]")

### Step 4ï¼šå¯è§†åŒ–

fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# (1) è½¬åŒ–ç‡å¯¹æ¯”
groups = ['Aç»„\nï¼ˆå¯¹ç…§ç»„ï¼‰', 'Bç»„\nï¼ˆå®éªŒç»„ï¼‰']
rates = [p_A_obs * 100, p_B_obs * 100]
colors = ['#3498db', '#e74c3c']

bars = axes[0].bar(groups, rates, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
axes[0].set_ylabel('ç‚¹å‡»ç‡ (%)')
axes[0].set_title('A/Bç»„ç‚¹å‡»ç‡å¯¹æ¯”', fontweight='bold')
axes[0].grid(axis='y', alpha=0.3)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, rate in zip(bars, rates):
    height = bar.get_height()
    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.05,
                f'{rate:.2f}%\n(n={n_A})',
                ha='center', va='bottom', fontweight='bold', fontsize=11)

# (2) ç½®ä¿¡åŒºé—´å¯è§†åŒ–
diff = p_B_obs - p_A_obs
error = (ci_upper - ci_lower) / 2

axes[1].barh(['å·®å¼‚'], [diff * 100], xerr=[error * 100],
            capsize=10, color='green', alpha=0.7, edgecolor='black', linewidth=2)
axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='æ— å·®å¼‚çº¿')
axes[1].set_xlabel('ç‚¹å‡»ç‡å·®å¼‚ (ç™¾åˆ†ç‚¹)')
axes[1].set_title(f'B-Aå·®å¼‚åŠ95%ç½®ä¿¡åŒºé—´\np={p_value:.4f}', fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3, axis='x')

# (3) ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿
effect_sizes = np.linspace(-0.02, 0.02, 100)
z_stats = effect_sizes / se

# åŒä¾§æ£€éªŒçš„åŠŸæ•ˆ
power_curve = (
    stats.norm.cdf(z_stats - stats.norm.ppf(1-alpha/2)) +
    stats.norm.cdf(-z_stats - stats.norm.ppf(1-alpha/2))
)

axes[2].plot(effect_sizes * 100, power_curve, linewidth=2, label='åŠŸæ•ˆæ›²çº¿')
axes[2].axhline(0.8, color='orange', linestyle='--', linewidth=2, label='ç›®æ ‡åŠŸæ•ˆ=0.8')
axes[2].axvline(0, color='red', linestyle='--', linewidth=1.5, label='H0')
axes[2].axvline(mde * 100, color='green', linestyle='--', linewidth=1.5, label=f'MDE={mde*100:.1f}%')
axes[2].scatter([absolute_lift * 100], [power], s=200, color='red', zorder=5, 
               label=f'è§‚æµ‹å€¼ (åŠŸæ•ˆ={power:.2f})')
axes[2].set_xlabel('çœŸå®æ•ˆåº” (ç™¾åˆ†ç‚¹)')
axes[2].set_ylabel('ç»Ÿè®¡åŠŸæ•ˆ (1-Î²)')
axes[2].set_title('ç»Ÿè®¡åŠŸæ•ˆåˆ†æ', fontweight='bold')
axes[2].legend()
axes[2].grid(alpha=0.3)

plt.tight_layout()
plt.show()

### Step 5ï¼šä¸šåŠ¡å†³ç­–

print("\n" + "=" * 70)
print("ã€ä¸šåŠ¡å†³ç­–å»ºè®®ã€‘")
print("=" * 70)

decision_report = f"""
## A/Bæµ‹è¯•ç»“è®ºæŠ¥å‘Š

### å®éªŒé…ç½®
- å®éªŒæ—¶é—´: [å®é™…å¡«å†™]
- æµé‡åˆ†é…: Aç»„ 50%, Bç»„ 50%
- æ ·æœ¬é‡: æ¯ç»„ {n_A:,} äºº

### å…³é”®æŒ‡æ ‡
- Aç»„ç‚¹å‡»ç‡: {p_A_obs:.2%}
- Bç»„ç‚¹å‡»ç‡: {p_B_obs:.2%}
- ç»å¯¹æå‡: {absolute_lift:.4f} ({absolute_lift*100:+.2f}ä¸ªç™¾åˆ†ç‚¹)
- ç›¸å¯¹æå‡: {relative_lift:+.2f}%

### ç»Ÿè®¡æ£€éªŒ
- Zç»Ÿè®¡é‡: {z:.4f}
- på€¼: {p_value:.6f}
- 95% CI: [{ci_lower*100:.2f}%, {ci_upper*100:.2f}%]
- **ç»“è®º**: {'âœ… æ˜¾è‘—å·®å¼‚' if p_value < alpha else 'âŒ æ— æ˜¾è‘—å·®å¼‚'}

### å†³ç­–å»ºè®®
"""

if p_value < alpha and ci_lower > 0:
    decision_report += f"""
âœ… **å»ºè®®å…¨é‡ä¸Šçº¿Bç‰ˆæœ¬ç®—æ³•**

ç†ç”±:
1. Bç»„ç‚¹å‡»ç‡æ˜¾è‘—é«˜äºAç»„ (p={p_value:.4f} < 0.05)
2. 95%ç½®ä¿¡åŒºé—´ [{ci_lower*100:.2f}%, {ci_upper*100:.2f}%] å®Œå…¨ä¸ºæ­£
3. é¢„æœŸROI:
   - å‡è®¾æ—¥å‡æ›å…‰1000ä¸‡æ¬¡
   - æå‡ç‚¹å‡» = 1000ä¸‡ Ã— {absolute_lift:.4f} = {int(10000000 * absolute_lift):,} æ¬¡
   - è‹¥æ¯æ¬¡ç‚¹å‡»ä»·å€¼10å…ƒï¼Œæ—¥å¢æ”¶ç›Š â‰ˆ {int(10000000 * absolute_lift * 10):,} å…ƒ
"""
elif p_value < alpha:
    decision_report += f"""
âš ï¸  **éœ€è¦è¿›ä¸€æ­¥åˆ†æ**

Bç»„è™½ç„¶æ˜¾è‘—ä¸åŒï¼Œä½†ç½®ä¿¡åŒºé—´è·¨è¶Š0ï¼Œå»ºè®®:
1. å»¶é•¿å®éªŒæ—¶é—´ï¼Œæ”¶é›†æ›´å¤šæ•°æ®
2. åˆ†å±‚åˆ†æï¼ˆæ–°è€ç”¨æˆ·ã€ä¸åŒå“ç±»ç­‰ï¼‰
3. æ£€æŸ¥æ˜¯å¦æœ‰Simpsonæ‚–è®º
"""
else:
    decision_report += f"""
âŒ **ä¸å»ºè®®ä¸Šçº¿Bç‰ˆæœ¬**

ç†ç”±:
1. ç»Ÿè®¡æ£€éªŒæœªå‘ç°æ˜¾è‘—å·®å¼‚ (p={p_value:.4f} â‰¥ 0.05)
2. æå‡ {relative_lift:.2f}% å¯èƒ½åªæ˜¯éšæœºæ³¢åŠ¨
3. è€ƒè™‘:
   - æ˜¯å¦éœ€è¦æ›´é•¿å®éªŒå‘¨æœŸï¼Ÿ
   - æ˜¯å¦å¯¹ç‰¹å®šç»†åˆ†ç¾¤ä½“æœ‰æ•ˆï¼Ÿ
   - Bç‰ˆæœ¬æ˜¯å¦æœ‰å…¶ä»–ä¼˜åŠ¿ï¼ˆå¦‚æˆæœ¬ã€å»¶è¿Ÿï¼‰ï¼Ÿ
"""

print(decision_report)
```

---

## 9.3 æ—¶é—´åºåˆ—åˆ†æï¼šé”€å”®é¢„æµ‹

### 9.2 æ–¹å·®åˆ†æï¼ˆANOVAï¼‰

**åœºæ™¯**ï¼šæ¯”è¾ƒ3ç§æ•™å­¦æ–¹æ³•çš„æ•ˆæœã€‚

```python
from scipy import stats

# 3ç»„å­¦ç”Ÿæˆç»©
method_A = [85, 88, 90, 87, 86]
method_B = [78, 80, 82, 79, 81]
method_C = [92, 94, 91, 93, 95]

# å•å› ç´ æ–¹å·®åˆ†æ
f_stat, p_value = stats.f_oneway(method_A, method_B, method_C)

print(f"Fç»Ÿè®¡é‡: {f_stat:.4f}")
print(f"på€¼: {p_value:.6f}")

if p_value < 0.05:
    print("ç»“è®ºï¼šä¸åŒæ•™å­¦æ–¹æ³•æ•ˆæœæœ‰æ˜¾è‘—å·®å¼‚")
    
    # äº‹åæ£€éªŒï¼ˆTukey HSDï¼‰
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    
    data = method_A + method_B + method_C
    groups = ['A']*5 + ['B']*5 + ['C']*5
    
    tukey = pairwise_tukeyhsd(data, groups, alpha=0.05)
    print("\nTukeyäº‹åæ£€éªŒ:")
    print(tukey)
```

### 9.3 å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ

**åœºæ™¯**ï¼šæ£€éªŒæ€§åˆ«ä¸è´­ä¹°åå¥½æ˜¯å¦ç‹¬ç«‹ã€‚

```python
import numpy as np
from scipy.stats import chi2_contingency

# åˆ—è”è¡¨
#        äº§å“A  äº§å“B  äº§å“C
# ç”·æ€§     30     20     10
# å¥³æ€§     10     25     35

observed = np.array([
    [30, 20, 10],
    [10, 25, 35]
])

chi2, p_value, dof, expected = chi2_contingency(observed)

print("è§‚æµ‹é¢‘æ•°:")
print(observed)
print("\næœŸæœ›é¢‘æ•°:")
print(expected)
print(f"\nÏ‡Â²ç»Ÿè®¡é‡: {chi2:.4f}")
print(f"è‡ªç”±åº¦: {dof}")
print(f"på€¼: {p_value:.6f}")

if p_value < 0.05:
    print("ç»“è®ºï¼šæ€§åˆ«ä¸è´­ä¹°åå¥½æ˜¾è‘—ç›¸å…³")
else:
    print("ç»“è®ºï¼šæ€§åˆ«ä¸è´­ä¹°åå¥½ç‹¬ç«‹")
```

### 9.4 æ—¶é—´åºåˆ—åˆ†æ

**åœºæ™¯**ï¼šé”€å”®æ•°æ®é¢„æµ‹ã€‚

```python
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# æœˆåº¦é”€å”®æ•°æ®ï¼ˆ24ä¸ªæœˆï¼‰
sales = [120, 135, 158, 171, 196, 210, 188, 165, 
         142, 125, 130, 145, 165, 180, 201, 225, 
         245, 268, 242, 215, 189, 165, 155, 170]

# ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘ï¼ˆè€ƒè™‘è¶‹åŠ¿å’Œå­£èŠ‚æ€§ï¼‰
model = ExponentialSmoothing(
    sales, 
    seasonal_periods=12,  # 12ä¸ªæœˆå­£èŠ‚å‘¨æœŸ
    trend='add',          # åŠ æ³•è¶‹åŠ¿
    seasonal='add'        # åŠ æ³•å­£èŠ‚æ€§
)
fitted = model.fit()

# é¢„æµ‹æœªæ¥6ä¸ªæœˆ
forecast = fitted.forecast(steps=6)

# å¯è§†åŒ–
plt.figure(figsize=(12, 6))
plt.plot(sales, label='å†å²æ•°æ®', marker='o')
plt.plot(range(24, 30), forecast, label='é¢„æµ‹', marker='s', color='red')
plt.xlabel('æœˆä»½')
plt.ylabel('é”€å”®é¢')
plt.title('é”€å”®é¢„æµ‹')
plt.legend()
plt.grid()
plt.show()

print("æœªæ¥6ä¸ªæœˆé¢„æµ‹:")
for i, val in enumerate(forecast, 1):
    print(f"ç¬¬{i}ä¸ªæœˆ: {val:.2f}")
```

### 9.5 ç›¸å…³æ€§åˆ†æ

**åœºæ™¯**ï¼šåˆ†æå¤šä¸ªå˜é‡ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(42)
n = 100

data = pd.DataFrame({
    'å­¦ä¹ æ—¶é—´': np.random.normal(5, 1.5, n),
    'ç¡çœ æ—¶é—´': np.random.normal(7, 1, n),
    'è¿åŠ¨æ—¶é—´': np.random.normal(1.5, 0.5, n)
})

# ç”Ÿæˆæˆç»©ï¼ˆä¸å­¦ä¹ æ—¶é—´æ­£ç›¸å…³ï¼Œä¸å…¶ä»–è´Ÿç›¸å…³ï¼‰
data['æˆç»©'] = (
    60 + 
    data['å­¦ä¹ æ—¶é—´'] * 5 + 
    data['ç¡çœ æ—¶é—´'] * 2 + 
    data['è¿åŠ¨æ—¶é—´'] * 1.5 + 
    np.random.normal(0, 5, n)
)

# è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
corr_matrix = data.corr()

print("ç›¸å…³ç³»æ•°çŸ©é˜µ:")
print(corr_matrix)

# å¯è§†åŒ–
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', 
            center=0, square=True, linewidths=1)
plt.title('å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾')
plt.tight_layout()
plt.show()

# æ˜¾è‘—æ€§æ£€éªŒ
from scipy.stats import pearsonr

for col in ['å­¦ä¹ æ—¶é—´', 'ç¡çœ æ—¶é—´', 'è¿åŠ¨æ—¶é—´']:
    r, p = pearsonr(data[col], data['æˆç»©'])
    print(f"\n{col}ä¸æˆç»©çš„ç›¸å…³æ€§:")
    print(f"  ç›¸å…³ç³»æ•° r = {r:.4f}")
    print(f"  på€¼ = {p:.6f}")
    if p < 0.05:
        print(f"  ç»“è®ºï¼šæ˜¾è‘—ç›¸å…³")
    else:
        print(f"  ç»“è®ºï¼šä¸æ˜¾è‘—")
```

---

**æœ¬ç« å®Œ**
