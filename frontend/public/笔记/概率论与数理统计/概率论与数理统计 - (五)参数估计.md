# 概率论与数理统计 - (五)参数估计

学习点估计和区间估计方法。

---

## 5. 参数估计

参数估计是统计推断的核心任务之一，目标是用样本数据推断总体参数。

### 5.1 点估计概述

#### 基本概念

**总体与样本**：
- **总体**：所研究对象的全体，分布 $F(x; \theta)$ 含未知参数 $\theta$
- **样本**：从总体中抽取的观测值 $X_1, X_2, \ldots, X_n$（独立同分布）
- **统计量**：样本的函数 $T(X_1, \ldots, X_n)$，不含未知参数

**点估计**：用统计量 $\hat{\theta} = \hat{\theta}(X_1, \ldots, X_n)$ 估计参数 $\theta$

#### 估计量的评价准则

##### (1) 无偏性（Unbiasedness）

**定义**：若 $E[\hat{\theta}] = \theta$，则称 $\hat{\theta}$ 是 $\theta$ 的**无偏估计**。

**例**：
- 样本均值 $\overline{X}$ 是总体均值 $\mu$ 的无偏估计
- 样本方差 $S^2 = \frac{1}{n-1}\sum(X_i - \overline{X})^2$ 是总体方差 $\sigma^2$ 的无偏估计
- 但 $\frac{1}{n}\sum(X_i - \overline{X})^2$ 是**有偏的**（偏差为 $-\sigma^2/n$）

**偏差**：$\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta$

##### (2) 有效性（Efficiency）

**定义**：设 $\hat{\theta}_1$ 和 $\hat{\theta}_2$ 都是 $\theta$ 的无偏估计，若

$$
\text{Var}(\hat{\theta}_1) < \text{Var}(\hat{\theta}_2)
$$

则称 $\hat{\theta}_1$ 比 $\hat{\theta}_2$ **更有效**。

**相对效率**：

$$
\text{eff}(\hat{\theta}_1, \hat{\theta}_2) = \frac{\text{Var}(\hat{\theta}_2)}{\text{Var}(\hat{\theta}_1)}
$$

##### (3) 一致性（Consistency）

**定义**：若 $\hat{\theta}_n \xrightarrow{P} \theta$（依概率收敛），则称 $\hat{\theta}_n$ 是 $\theta$ 的**一致估计**。

**意义**：样本量越大，估计越接近真值。

**例**：样本均值 $\overline{X}_n$ 是总体均值 $\mu$ 的一致估计（由大数定律）

##### (4) 均方误差（Mean Squared Error, MSE）

**定义**：

$$
\text{MSE}(\hat{\theta}) = E[(\hat{\theta} - \theta)^2] = \text{Var}(\hat{\theta}) + [\text{Bias}(\hat{\theta})]^2
$$

**权衡**：无偏性 vs 方差（bias-variance tradeoff）

### 5.2 矩估计法

#### 原理

用**样本矩**估计**总体矩**，再解出参数。

**步骤**：
1. 计算总体矩（用参数表示）：$\mu_k = E[X^k]$
2. 计算样本矩：$\hat{\mu}_k = \frac{1}{n}\sum_{i=1}^{n} X_i^k$
3. 令 $\hat{\mu}_k = \mu_k$，解出参数估计

#### 常见分布的矩估计

| 分布 | 参数 | 矩估计 |
|------|------|--------|
| $N(\mu, \sigma^2)$ | $\mu, \sigma^2$ | $\hat{\mu} = \overline{X}$，$\hat{\sigma}^2 = \frac{1}{n}\sum(X_i - \overline{X})^2$ |
| $\text{Exp}(\lambda)$ | $\lambda$ | $\hat{\lambda} = 1/\overline{X}$ |
| $U(a, b)$ | $a, b$ | $\hat{a} = \overline{X} - \sqrt{3}S$，$\hat{b} = \overline{X} + \sqrt{3}S$ |
| $\Gamma(\alpha, \beta)$ | $\alpha, \beta$ | $\hat{\alpha} = \overline{X}^2/S^2$，$\hat{\beta} = S^2/\overline{X}$ |

**例1**：设 $X_1, \ldots, X_n \sim U(a, b)$，求 $a, b$ 的矩估计。

**解**：

$$
E[X] = \frac{a+b}{2}, \quad E[X^2] = \frac{a^2 + ab + b^2}{3}
$$

$$
\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{(b-a)^2}{12}
$$

令：

$$
\overline{X} = \frac{a+b}{2}, \quad S^2 = \frac{(b-a)^2}{12}
$$

解得：

$$
\hat{a} = \overline{X} - \sqrt{3}S, \quad \hat{b} = \overline{X} + \sqrt{3}S
$$

### 5.3 最大似然估计（MLE）

#### 原理

选择使得观测样本出现概率最大的参数值。

**似然函数**：

$$
L(\theta) = L(\theta; x_1, \ldots, x_n) = \prod_{i=1}^{n} f(x_i; \theta)
$$

**最大似然估计**：

$$
\hat{\theta}_{MLE} = \arg\max_{\theta} L(\theta)
$$

**对数似然函数**（便于计算）：

$$
\ell(\theta) = \log L(\theta) = \sum_{i=1}^{n} \log f(x_i; \theta)
$$

**求解方法**：
1. 求导：$\frac{d\ell(\theta)}{d\theta} = 0$（似然方程）
2. 验证二阶导数 $< 0$（确保是最大值）

#### MLE的性质

1. **函数不变性**：若 $\hat{\theta}$ 是 $\theta$ 的MLE，则对任意函数 $g$，$g(\hat{\theta})$ 是 $g(\theta)$ 的MLE
2. **渐近正态性**：$\hat{\theta}_n \sim N\left(\theta, \frac{1}{nI(\theta)}\right)$（$n$ 大时）
   - 其中 $I(\theta)$ 是Fisher信息量
3. **渐近有效性**：在所有一致估计中，MLE的渐近方差最小（达到Cramér-Rao下界）

#### Fisher信息量

**定义**：

$$
I(\theta) = E\left[\left(\frac{\partial \log f(X; \theta)}{\partial \theta}\right)^2\right] = -E\left[\frac{\partial^2 \log f(X; \theta)}{\partial \theta^2}\right]
$$

**意义**：度量样本包含的关于参数 $\theta$ 的信息量

**Cramér-Rao下界**：任何无偏估计 $\hat{\theta}$ 的方差满足

$$
\text{Var}(\hat{\theta}) \geq \frac{1}{nI(\theta)}
$$

#### 常见分布的MLE

**例2**：正态分布 $N(\mu, \sigma^2)$ 的MLE

**解**：

似然函数：

$$
L(\mu, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

对数似然：

$$
\ell(\mu, \sigma^2) = -\frac{n}{2}\log(2\pi) - \frac{n}{2}\log\sigma^2 - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i - \mu)^2
$$

求偏导并令其为0：

$$
\frac{\partial \ell}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^{n}(x_i - \mu) = 0 \Rightarrow \hat{\mu} = \overline{X}
$$

$$
\frac{\partial \ell}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^{n}(x_i - \mu)^2 = 0 \Rightarrow \hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \overline{X})^2
$$

**注意**：$\hat{\sigma}^2$ 是有偏的（偏差为 $-\sigma^2/n$）

**例3**：指数分布 $\text{Exp}(\lambda)$ 的MLE

**解**：

$$
L(\lambda) = \prod_{i=1}^{n} \lambda e^{-\lambda x_i} = \lambda^n e^{-\lambda \sum x_i}
$$

$$
\ell(\lambda) = n\log\lambda - \lambda\sum_{i=1}^{n} x_i
$$

$$
\frac{d\ell}{d\lambda} = \frac{n}{\lambda} - \sum_{i=1}^{n} x_i = 0 \Rightarrow \hat{\lambda} = \frac{n}{\sum x_i} = \frac{1}{\overline{X}}
$$

**例4**：均匀分布 $U(0, \theta)$ 的MLE

**解**：

似然函数：

$$
L(\theta) = \begin{cases}
\frac{1}{\theta^n} & \text{if } \theta \geq \max\{x_1, \ldots, x_n\} \\
0 & \text{otherwise}
\end{cases}
$$

要最大化 $L(\theta) = \frac{1}{\theta^n}$，应使 $\theta$ 尽可能小，但约束为 $\theta \geq \max\{x_i\}$

因此：

$$
\hat{\theta}_{MLE} = X_{(n)} = \max\{X_1, \ldots, X_n\}
$$

**注意**：此例无法用求导法，因为 $L(\theta)$ 不可导。

### 5.4 充分统计量

#### 定义

**充分统计量**（Sufficient Statistic）：统计量 $T(X_1, \ldots, X_n)$ 包含了样本关于参数 $\theta$ 的**全部信息**。

**严格定义**：若给定 $T$ 的值后，样本 $(X_1, \ldots, X_n)$ 的条件分布与 $\theta$ 无关，则 $T$ 是充分统计量。

#### 因子分解定理（Factorization Theorem）

**定理**：$T(X)$ 是 $\theta$ 的充分统计量 $\Leftrightarrow$ 似然函数可以分解为

$$
L(\theta; x) = g(T(x), \theta) \cdot h(x)
$$

其中 $h(x)$ 不依赖于 $\theta$

**例5**：证明 $\overline{X}$ 是正态分布 $N(\mu, \sigma^2)$（$\sigma^2$ 已知）均值 $\mu$ 的充分统计量。

**证明**：

$$
L(\mu) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
$$

$$
= \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n \exp\left(-\frac{\sum x_i^2 - 2\mu\sum x_i + n\mu^2}{2\sigma^2}\right)
$$

$$
= \underbrace{\exp\left(\frac{n\overline{x}\mu - n\mu^2/2}{\sigma^2}\right)}_{g(\overline{x}, \mu)} \cdot \underbrace{\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n \exp\left(-\frac{\sum x_i^2}{2\sigma^2}\right)}_{h(x)}
$$

因此 $\overline{X}$ 是充分统计量。$\square$

#### Rao-Blackwell定理

**定理**：若 $\hat{\theta}$ 是 $\theta$ 的无偏估计，$T$ 是充分统计量，则

$$
\tilde{\theta} = E[\hat{\theta} | T]
$$

也是无偏估计，且 $\text{Var}(\tilde{\theta}) \leq \text{Var}(\hat{\theta})$

**意义**：利用充分统计量可以改进估计量

### 5.5 区间估计

#### 基本概念

**置信区间**：由样本构造的随机区间 $[L, U]$，使得

$$
P(\theta \in [L, U]) = 1 - \alpha
$$

其中 $1-\alpha$ 称为**置信水平**（confidence level），$\alpha$ 称为**显著性水平**

**正确理解**：
- ✅ 区间是随机的，参数是固定的（频率学派）
- ✅ 做100次实验，约有95次区间包含真实参数
- ❌ 不能说"参数落在区间内的概率是95%"

#### 正态总体的置信区间

##### 情况1：$\sigma^2$ 已知，估计 $\mu$

**枢轴量**：

$$
\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \sim N(0, 1)
$$

**$(1-\alpha)$ 置信区间**：

$$
\left[ \overline{X} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \overline{X} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \right]
$$

其中 $z_{\alpha/2}$ 是标准正态分布的上 $\alpha/2$ 分位数（如 $z_{0.025} = 1.96$）

##### 情况2：$\sigma^2$ 未知，估计 $\mu$

**枢轴量**：

$$
\frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t(n-1)
$$

其中 $S^2 = \frac{1}{n-1}\sum(X_i - \overline{X})^2$

**$(1-\alpha)$ 置信区间**：

$$
\left[ \overline{X} - t_{\alpha/2}(n-1) \frac{S}{\sqrt{n}}, \overline{X} + t_{\alpha/2}(n-1) \frac{S}{\sqrt{n}} \right]
$$

##### 情况3：$\mu$ 未知，估计 $\sigma^2$

**枢轴量**：

$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$

**$(1-\alpha)$ 置信区间**：

$$
\left[ \frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)}, \frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)} \right]
$$

#### 两个正态总体的置信区间

##### 均值差 $\mu_1 - \mu_2$ 的置信区间

假设 $X_i \sim N(\mu_1, \sigma_1^2)$，$Y_j \sim N(\mu_2, \sigma_2^2)$ 独立

**情况A**：$\sigma_1^2 = \sigma_2^2 = \sigma^2$ 已知

$$
\overline{X} - \overline{Y} \pm z_{\alpha/2} \sigma\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}
$$

**情况B**：$\sigma_1^2 = \sigma_2^2 = \sigma^2$ 未知（合并方差）

$$
S_p^2 = \frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 - 2}
$$

$$
\overline{X} - \overline{Y} \pm t_{\alpha/2}(n_1+n_2-2) \cdot S_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}
$$

##### 方差比 $\sigma_1^2 / \sigma_2^2$ 的置信区间

**枢轴量**：

$$
\frac{S_1^2 / \sigma_1^2}{S_2^2 / \sigma_2^2} \sim F(n_1-1, n_2-1)
$$

**$(1-\alpha)$ 置信区间**：

$$
\left[ \frac{S_1^2}{S_2^2} \cdot \frac{1}{F_{\alpha/2}(n_1-1, n_2-1)}, \frac{S_1^2}{S_2^2} \cdot F_{\alpha/2}(n_2-1, n_1-1) \right]
$$

#### 大样本置信区间

当 $n$ 很大时，由中心极限定理，对于一般总体：

$$
\frac{\overline{X} - \mu}{S/\sqrt{n}} \approx N(0, 1)
$$

**95%置信区间**：

$$
\overline{X} \pm 1.96 \frac{S}{\sqrt{n}}
$$

#### 单侧置信区间

**单侧置信上限**：

$$
P(\mu \leq U) = 1 - \alpha \Rightarrow U = \overline{X} + z_\alpha \frac{\sigma}{\sqrt{n}}
$$

**单侧置信下限**：

$$
P(\mu \geq L) = 1 - \alpha \Rightarrow L = \overline{X} - z_\alpha \frac{\sigma}{\sqrt{n}}
$$

### 5.6 应用实例

#### 应用1：MLE参数估计与可视化

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def mle_normal_distribution(data, true_mu=None, true_sigma=None):
    """
    正态分布的最大似然估计
    """
    n = len(data)
    
    # MLE估计
    mu_mle = np.mean(data)
    sigma2_mle = np.var(data, ddof=0)  # 总体方差（MLE）
    sigma_mle = np.sqrt(sigma2_mle)
    
    # 无偏估计
    mu_unbiased = np.mean(data)
    sigma2_unbiased = np.var(data, ddof=1)  # 样本方差（无偏）
    sigma_unbiased = np.sqrt(sigma2_unbiased)
    
    print("=== 正态分布参数估计 ===")
    print(f"样本量: n = {n}")
    print(f"\nMLE估计:")
    print(f"  μ̂ = {mu_mle:.4f}")
    print(f"  σ̂² = {sigma2_mle:.4f}")
    print(f"  σ̂ = {sigma_mle:.4f}")
    
    print(f"\n无偏估计:")
    print(f"  μ̂ = {mu_unbiased:.4f}")
    print(f"  σ̂² (无偏) = {sigma2_unbiased:.4f}")
    print(f"  σ̂ (无偏) = {sigma_unbiased:.4f}")
    
    if true_mu is not None and true_sigma is not None:
        print(f"\n真实值:")
        print(f"  μ = {true_mu:.4f}")
        print(f"  σ = {true_sigma:.4f}")
        print(f"\n误差:")
        print(f"  μ误差 = {abs(mu_mle - true_mu):.4f}")
        print(f"  σ误差 = {abs(sigma_mle - true_sigma):.4f}")
    
    # 可视化
    plt.figure(figsize=(12, 5))
    
    # 直方图 + 拟合
    plt.subplot(1, 2, 1)
    plt.hist(data, bins=30, density=True, alpha=0.7, edgecolor='black', label='数据直方图')
    
    x = np.linspace(data.min(), data.max(), 200)
    plt.plot(x, stats.norm.pdf(x, mu_mle, sigma_mle), 
             'r-', linewidth=2, label=f'MLE拟合 N({mu_mle:.2f}, {sigma_mle:.2f}²)')
    
    if true_mu is not None and true_sigma is not None:
        plt.plot(x, stats.norm.pdf(x, true_mu, true_sigma),
                 'g--', linewidth=2, label=f'真实分布 N({true_mu}, {true_sigma}²)')
    
    plt.xlabel('x')
    plt.ylabel('密度')
    plt.title('正态分布参数估计')
    plt.legend()
    plt.grid(alpha=0.3)
    
    # Q-Q图
    plt.subplot(1, 2, 2)
    stats.probplot(data, dist="norm", plot=plt)
    plt.title('Q-Q图（正态性检验）')
    plt.grid(alpha=0.3)
    
    plt.tight_layout()
    # plt.show()
    
    return mu_mle, sigma_mle

# # 测试
# np.random.seed(42)
# true_mu, true_sigma = 5, 2
# data = np.random.normal(true_mu, true_sigma, 1000)
# mle_normal_distribution(data, true_mu, true_sigma)
```

#### 应用2：置信区间计算

```python
def confidence_interval_normal(data, confidence=0.95, sigma_known=None):
    """
    正态分布均值的置信区间
    
    参数:
    - data: 样本数据
    - confidence: 置信水平
    - sigma_known: 总体标准差（如果已知）
    """
    n = len(data)
    mean = np.mean(data)
    alpha = 1 - confidence
    
    print(f"=== {confidence*100}% 置信区间 ===")
    print(f"样本量: n = {n}")
    print(f"样本均值: {mean:.4f}")
    
    if sigma_known is not None:
        # 方差已知，用Z分布
        print(f"总体标准差（已知）: σ = {sigma_known:.4f}")
        z_critical = stats.norm.ppf(1 - alpha/2)
        margin_of_error = z_critical * sigma_known / np.sqrt(n)
        
        print(f"使用Z分布，z_{{{alpha/2:.3f}}} = {z_critical:.4f}")
    else:
        # 方差未知，用t分布
        std = np.std(data, ddof=1)
        print(f"样本标准差: s = {std:.4f}")
        t_critical = stats.t.ppf(1 - alpha/2, n - 1)
        margin_of_error = t_critical * std / np.sqrt(n)
        
        print(f"使用t分布（df={n-1}），t_{{{alpha/2:.3f}}} = {t_critical:.4f}")
    
    ci_lower = mean - margin_of_error
    ci_upper = mean + margin_of_error
    
    print(f"\n置信区间: [{ci_lower:.4f}, {ci_upper:.4f}]")
    print(f"点估计: {mean:.4f} ± {margin_of_error:.4f}")
    print(f"区间宽度: {ci_upper - ci_lower:.4f}")
    
    return ci_lower, ci_upper

# # 示例
# data = np.random.normal(10, 2, 50)
# confidence_interval_normal(data, confidence=0.95)
```

#### 应用3：比较矩估计和MLE

```python
def compare_estimators(true_lambda, n_samples, n_simulations=1000):
    """
    比较指数分布的矩估计和MLE（模拟研究）
    """
    mle_estimates = []
    moment_estimates = []
    
    for _ in range(n_simulations):
        # 生成样本
        data = np.random.exponential(1/true_lambda, n_samples)
        
        # MLE: λ̂ = 1/X̄
        mle = 1 / np.mean(data)
        mle_estimates.append(mle)
        
        # 矩估计: λ̂ = 1/X̄ (对于指数分布，矩估计和MLE相同)
        moment = 1 / np.mean(data)
        moment_estimates.append(moment)
    
    mle_estimates = np.array(mle_estimates)
    moment_estimates = np.array(moment_estimates)
    
    print(f"=== 估计量比较（真实λ = {true_lambda}）===")
    print(f"模拟次数: {n_simulations}, 每次样本量: {n_samples}")
    
    print(f"\nMLE:")
    print(f"  均值: {np.mean(mle_estimates):.4f}")
    print(f"  偏差: {np.mean(mle_estimates) - true_lambda:.4f}")
    print(f"  方差: {np.var(mle_estimates):.6f}")
    print(f"  MSE: {np.mean((mle_estimates - true_lambda)**2):.6f}")
    
    # 可视化
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.hist(mle_estimates, bins=50, density=True, alpha=0.7, edgecolor='black')
    plt.axvline(true_lambda, color='r', linestyle='--', linewidth=2, label=f'真实值 λ={true_lambda}')
    plt.axvline(np.mean(mle_estimates), color='g', linestyle='-', linewidth=2, label=f'估计均值={np.mean(mle_estimates):.3f}')
    plt.xlabel('估计值')
    plt.ylabel('密度')
    plt.title(f'MLE分布 (n={n_samples})')
    plt.legend()
    plt.grid(alpha=0.3)
    
    # MSE vs 样本量
    plt.subplot(1, 2, 2)
    sample_sizes = [10, 20, 50, 100, 200, 500, 1000]
    mses = []
    
    for n in sample_sizes:
        estimates = []
        for _ in range(500):
            data = np.random.exponential(1/true_lambda, n)
            estimates.append(1 / np.mean(data))
        mses.append(np.mean((np.array(estimates) - true_lambda)**2))
    
    plt.plot(sample_sizes, mses, 'o-', linewidth=2, markersize=8)
    plt.xlabel('样本量 n')
    plt.ylabel('MSE')
    plt.title('MSE vs 样本量')
    plt.xscale('log')
    plt.yscale('log')
    plt.grid(alpha=0.3)
    
    plt.tight_layout()
    # plt.show()

# # compare_estimators(true_lambda=2.0, n_samples=50)
```

### 5.7 本章小结

#### 核心概念

| 概念 | 定义 | 关键性质 |
|------|------|---------|
| **无偏性** | $E[\hat{\theta}] = \theta$ | 平均来说估计正确 |
| **有效性** | $\text{Var}(\hat{\theta}_1) < \text{Var}(\hat{\theta}_2)$ | 方差更小更好 |
| **一致性** | $\hat{\theta}_n \xrightarrow{P} \theta$ | 大样本下收敛到真值 |
| **MSE** | $E[(\hat{\theta}-\theta)^2] = \text{Var} + \text{Bias}^2$ | 综合评价标准 |

#### 估计方法对比

| 方法 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **矩估计** | 简单直观，易计算 | 不一定有效，可能有偏 | 快速估计、初值选择 |
| **MLE** | 渐近有效、函数不变性 | 可能有偏、计算复杂 | 大样本、精确推断 |

#### 重要公式速查

**正态分布均值置信区间**（$\sigma$ 未知）：

$$
\overline{X} \pm t_{\alpha/2}(n-1) \frac{S}{\sqrt{n}}
$$

**样本量计算**（给定误差界 $E$）：

$$
n = \left(\frac{z_{\alpha/2} \sigma}{E}\right)^2
$$

**Fisher信息量**：

$$
I(\theta) = -E\left[\frac{\partial^2 \log f(X; \theta)}{\partial \theta^2}\right]
$$

#### 易错点

1. **样本方差**：MLE用 $\frac{1}{n}$（有偏），无偏估计用 $\frac{1}{n-1}$
2. **置信区间理解**：区间是随机的，参数是固定的
3. **t vs Z**：小样本用t分布，大样本或 $\sigma$ 已知用Z
4. **MLE不一定无偏**：如正态分布的 $\hat{\sigma}^2_{MLE}$

---

**本章完**
