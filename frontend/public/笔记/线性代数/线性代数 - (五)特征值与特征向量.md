# 线性代数 - (五)特征值与特征向量

掌握特征值和特征向量的计算及应用。

---

## 5. 特征值与特征向量

### 5.1 定义

对于方阵 $A$，若存在非零向量 $\mathbf{v}$ 和标量 $\lambda$ 使得

$$
A\mathbf{v} = \lambda \mathbf{v}
$$

则 $\lambda$ 称为特征值，$\mathbf{v}$ 称为特征向量。

### 5.2 特征值的计算

**特征方程：**

$$
\det(A - \lambda I) = 0
$$

**示例：**

$$
A = \begin{bmatrix} 4 & 2 \\ 1 & 3 \end{bmatrix}
$$

$$
\det \begin{bmatrix} 4-\lambda & 2 \\ 1 & 3-\lambda \end{bmatrix} = (4-\lambda)(3-\lambda) - 2 = \lambda^2 - 7\lambda + 10 = 0
$$

$$
(\lambda - 5)(\lambda - 2) = 0 \Rightarrow \lambda_1 = 5, \lambda_2 = 2
$$

**求特征向量：**

对于 $\lambda_1 = 5$：

$$
(A - 5I)\mathbf{v} = \mathbf{0}
$$

$$
\begin{bmatrix} -1 & 2 \\ 1 & -2 \end{bmatrix} \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}
$$

$$
\mathbf{v}_1 = \begin{bmatrix} 2 \\ 1 \end{bmatrix}
$$

**NumPy实现：**

```python
A = np.array([[4, 2], [1, 3]])

# 计算特征值和特征向量
eigenvalues, eigenvectors = np.linalg.eig(A)

print("特征值:", eigenvalues)  # [5. 2.]
print("特征向量:\n", eigenvectors)
# [[0.89442719 0.70710678]
#  [0.4472136  0.70710678]]

# 验证
lambda1 = eigenvalues[0]
v1 = eigenvectors[:, 0]
print(np.allclose(A @ v1, lambda1 * v1))  # True
```

### 5.3 矩阵对角化

若 $A$ 有 $n$ 个线性无关的特征向量，则 $A$ 可对角化：

$$
A = P D P^{-1}
$$

其中 $P$ 的列是特征向量，$D$ 是特征值对角矩阵。

**应用：快速计算矩阵幂**

$$
A^k = P D^k P^{-1}
$$

```python
# 计算 A^100
P = eigenvectors
D = np.diag(eigenvalues)

A_100 = P @ (D ** 100) @ np.linalg.inv(P)
print(A_100)
```

### 5.4 PageRank算法

**原理**：网页的重要性由指向它的网页决定。

$$
\mathbf{r} = M \mathbf{r}
$$

其中 $M$ 是转移矩阵，$\mathbf{r}$ 是特征值为1的特征向量（PageRank值）。

**示例：**

```python
# 简化的PageRank
def pagerank(M, iterations=100):
    n = len(M)
    r = np.ones(n) / n  # 初始等概率
    
    for _ in range(iterations):
        r = M @ r
        r = r / np.sum(r)  # 归一化
    
    return r

# 转移矩阵（列归一化）
M = np.array([
    [0, 1/2, 1/3],
    [1/2, 0, 1/3],
    [1/2, 1/2, 1/3]
])

ranks = pagerank(M)
print("PageRank:", ranks)
```

---

**本章完**
